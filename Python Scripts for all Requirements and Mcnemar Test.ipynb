{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8734de3f-2951-41f7-9501-2005576178c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pan ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pan Fold-0: 100%|██████████| 139/139 [00:44<00:00,  3.14it/s]\n",
      "Pan Fold-1: 100%|██████████| 139/139 [00:44<00:00,  3.13it/s]\n",
      "Pan Fold-2: 100%|██████████| 139/139 [00:44<00:00,  3.12it/s]\n",
      "Pan Fold-3: 100%|██████████| 139/139 [00:44<00:00,  3.10it/s]\n",
      "Pan Fold-4: 100%|██████████| 139/139 [00:44<00:00,  3.12it/s]\n",
      "Pan Fold-5: 100%|██████████| 139/139 [00:44<00:00,  3.15it/s]\n",
      "Pan Fold-6: 100%|██████████| 139/139 [00:44<00:00,  3.15it/s]\n",
      "Pan Fold-7: 100%|██████████| 139/139 [00:44<00:00,  3.15it/s]\n",
      "Pan Fold-8: 100%|██████████| 139/139 [00:44<00:00,  3.12it/s]\n",
      "Pan Fold-9: 100%|██████████| 139/139 [00:44<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Maalej ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maalej Fold-0: 100%|██████████| 370/370 [01:52<00:00,  3.29it/s]\n",
      "Maalej Fold-1: 100%|██████████| 370/370 [01:53<00:00,  3.27it/s]\n",
      "Maalej Fold-2: 100%|██████████| 370/370 [01:53<00:00,  3.27it/s]\n",
      "Maalej Fold-3: 100%|██████████| 370/370 [01:54<00:00,  3.24it/s]\n",
      "Maalej Fold-4: 100%|██████████| 370/370 [01:54<00:00,  3.23it/s]\n",
      "Maalej Fold-5: 100%|██████████| 370/370 [01:53<00:00,  3.25it/s]\n",
      "Maalej Fold-6: 100%|██████████| 370/370 [01:53<00:00,  3.27it/s]\n",
      "Maalej Fold-7: 100%|██████████| 370/370 [01:53<00:00,  3.26it/s]\n",
      "Maalej Fold-8: 100%|██████████| 370/370 [01:52<00:00,  3.29it/s]\n",
      "Maalej Fold-9: 100%|██████████| 370/370 [01:54<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Scalabrino ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scalabrino Fold-0: 100%|██████████| 300/300 [01:36<00:00,  3.10it/s]\n",
      "Scalabrino Fold-1: 100%|██████████| 300/300 [01:40<00:00,  2.98it/s]\n",
      "Scalabrino Fold-2: 100%|██████████| 300/300 [01:36<00:00,  3.10it/s]\n",
      "Scalabrino Fold-3: 100%|██████████| 300/300 [01:40<00:00,  2.99it/s]\n",
      "Scalabrino Fold-4: 100%|██████████| 300/300 [01:38<00:00,  3.04it/s]\n",
      "Scalabrino Fold-5: 100%|██████████| 300/300 [01:38<00:00,  3.06it/s]\n",
      "Scalabrino Fold-6: 100%|██████████| 300/300 [01:36<00:00,  3.10it/s]\n",
      "Scalabrino Fold-7: 100%|██████████| 300/300 [01:40<00:00,  3.00it/s]\n",
      "Scalabrino Fold-8: 100%|██████████| 300/300 [01:38<00:00,  3.05it/s]\n",
      "Scalabrino Fold-9: 100%|██████████| 300/300 [01:36<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Saved per-fold macro/micro results.\n",
      "\n",
      "📊 Computing final combined weighted metrics...\n",
      "✅ Pan: macro-F1=0.738, weighted-F1=0.796\n",
      "✅ Maalej: macro-F1=0.466, weighted-F1=0.655\n",
      "✅ Scalabrino: macro-F1=0.545, weighted-F1=0.433\n",
      "\n",
      "🎯 Done!\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# ─── CONFIG ───\n",
    "DATASET_DIRS = {\n",
    "    \"pan\": \"stratified_splits_80_10_10/pan\",\n",
    "    \"maalej\": \"stratified_splits_80_10_10/maalej\",\n",
    "    \"scalabrino\": \"stratified_splits_80_10_10/scalabrino\",\n",
    "}\n",
    "\n",
    "OLLAMA_MODEL = \"llama3:70b\"\n",
    "# Sanitize model name to make it a valid folder name\n",
    "MODEL_NAME_CLEAN = OLLAMA_MODEL.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "OUT_DIR = f\"zero_shot_folds_{MODEL_NAME_CLEAN}\"\n",
    "PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "os.makedirs(PRED_DIR, exist_ok=True)\n",
    "\n",
    "llm = OllamaLLM(model=OLLAMA_MODEL)\n",
    "\n",
    "# ─── PROMPT TEMPLATES ───\n",
    "LLAMA3_TEMPLATES = {\n",
    "    \"Pan\": (\n",
    "        \"You are a requirement classification assistant.\\n\"\n",
    "        \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "        \"Information Giving: factual descriptions, app details, or user opinions.\\n\"\n",
    "        \"Problem Discovery: issues, bugs, crashes, or errors.\\n\"\n",
    "        \"Feature Request: suggestions or desired improvements.\\n\"\n",
    "        \"Information Seeking: questions or asking for help.\\n\\n\"\n",
    "        \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    ),\n",
    "    \"Maalej\": (\n",
    "        \"You are a requirement classification assistant.\\n\"\n",
    "        \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "        \"Feature Request: suggestions or desires for new features, functionality, or improvements.\\n\"\n",
    "        \"Rating: numeric scores or general feedback like 'great app' or 'bad service'.\\n\"\n",
    "        \"User Experience: opinions about usability, UI, speed, or ease of use.\\n\"\n",
    "        \"Problem Discovery: reports of bugs, crashes, or errors.\\n\\n\"\n",
    "        \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    ),\n",
    "    \"Scalab\": (\n",
    "        \"You are a strict classification assistant.\\n\"\n",
    "        \"Classify the following app review into ONE and ONLY ONE of these categories:\\n\\n\"\n",
    "        \"BUG\\nFEATURE\\nPERFORMANCE\\nENERGY\\nSECURITY\\nUSABILITY\\nOTHER\\n\\n\"\n",
    "        \"- If unclear, choose OTHER.\\n\"\n",
    "        \"- Output the label name exactly as written above.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# ─── EVALUATION ───\n",
    "all_results = []\n",
    "\n",
    "def run_fold_zero_shot(df, labels, template, dataset_name, fold_id):\n",
    "    y_true = df[\"class\"].tolist()\n",
    "    req_ids = df[\"id\"].tolist()\n",
    "    texts = df[\"review\"].tolist() if \"review\" in df.columns else df[\"text\"].tolist()\n",
    "\n",
    "    preds = []\n",
    "    for txt in tqdm(texts, desc=f\"{dataset_name} Fold-{fold_id}\"):\n",
    "        prompt = template.format(req_text=txt)\n",
    "        pred = llm.invoke(prompt).strip()\n",
    "        pred = next((lab for lab in labels if lab.lower() in pred.lower()), labels[0])\n",
    "        preds.append(pred)\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"id\": req_ids,\n",
    "        \"text\": texts,\n",
    "        \"gold\": y_true,\n",
    "        \"pred\": preds\n",
    "    }).to_csv(os.path.join(PRED_DIR, f\"{dataset_name}_fold{fold_id}_preds.csv\"), index=False)\n",
    "\n",
    "    macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(y_true, preds, average=\"macro\", zero_division=0)\n",
    "    micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(y_true, preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_name, \"fold\": fold_id,\n",
    "        \"macro_precision\": macro_p, \"macro_recall\": macro_r, \"macro_f1\": macro_f1,\n",
    "        \"micro_precision\": micro_p, \"micro_recall\": micro_r, \"micro_f1\": micro_f1\n",
    "    }\n",
    "\n",
    "# ─── MAIN FOLD LOOP ───\n",
    "for dataset_name, folder in DATASET_DIRS.items():\n",
    "    print(f\"\\n=== {dataset_name} ===\")\n",
    "    labels = sorted(pd.read_csv(os.path.join(folder, \"test_fold_0.csv\"))[\"class\"].unique())\n",
    "    template = LLAMA3_TEMPLATES[dataset_name if dataset_name != \"Scalabrino\" else \"Scalab\"]\n",
    "\n",
    "    for i in range(10):\n",
    "        path = os.path.join(folder, f\"test_fold_{i}.csv\")\n",
    "        df = pd.read_csv(path)\n",
    "        metrics = run_fold_zero_shot(df, labels, template, dataset_name, i)\n",
    "        all_results.append(metrics)\n",
    "\n",
    "summary_df = pd.DataFrame(all_results)\n",
    "summary_df.to_csv(os.path.join(OUT_DIR, \"zero_shot_folded_summary.csv\"), index=False)\n",
    "print(\"\\n📁 Saved per-fold macro/micro results.\")\n",
    "# ─── FINAL FULL SET EVALUATION ───\n",
    "print(\"\\n📊 Computing final combined weighted metrics...\")\n",
    "\n",
    "def safe_metric(report, key, metric):\n",
    "    return report.get(key, {}).get(metric, 0.0)\n",
    "\n",
    "for dataset_name in DATASET_DIRS:\n",
    "    fold_preds = []\n",
    "    for i in range(10):\n",
    "        fold_path = os.path.join(PRED_DIR, f\"{dataset_name}_fold{i}_preds.csv\")\n",
    "        fold_df = pd.read_csv(fold_path)\n",
    "        fold_preds.append(fold_df)\n",
    "\n",
    "    all_df = pd.concat(fold_preds, ignore_index=True)\n",
    "    y_true = all_df[\"gold\"].str.lower()\n",
    "    y_pred = all_df[\"pred\"].str.lower()\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    final_metrics = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"macro_precision\":   safe_metric(report, \"macro avg\", \"precision\"),\n",
    "        \"macro_recall\":      safe_metric(report, \"macro avg\", \"recall\"),\n",
    "        \"macro_f1\":          safe_metric(report, \"macro avg\", \"f1-score\"),\n",
    "        \"micro_precision\":   safe_metric(report, \"micro avg\", \"precision\"),\n",
    "        \"micro_recall\":      safe_metric(report, \"micro avg\", \"recall\"),\n",
    "        \"micro_f1\":          safe_metric(report, \"micro avg\", \"f1-score\"),\n",
    "        \"weighted_precision\": safe_metric(report, \"weighted avg\", \"precision\"),\n",
    "        \"weighted_recall\":    safe_metric(report, \"weighted avg\", \"recall\"),\n",
    "        \"weighted_f1\":        safe_metric(report, \"weighted avg\", \"f1-score\")\n",
    "    }\n",
    "\n",
    "    pd.DataFrame([final_metrics]).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{dataset_name}_final_combined_metrics.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"✅ {dataset_name}: macro-F1={final_metrics['macro_f1']:.3f}, weighted-F1={final_metrics['weighted_f1']:.3f}\")\n",
    "\n",
    "print(\"\\n🎯 Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "751be0cd-e988-4bc6-8c61-158e35aa08f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pan ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pan Fold-0: 100%|██████████| 139/139 [00:28<00:00,  4.83it/s]\n",
      "Pan Fold-1: 100%|██████████| 139/139 [00:25<00:00,  5.48it/s]\n",
      "Pan Fold-2: 100%|██████████| 139/139 [00:25<00:00,  5.39it/s]\n",
      "Pan Fold-3: 100%|██████████| 139/139 [00:25<00:00,  5.35it/s]\n",
      "Pan Fold-4: 100%|██████████| 139/139 [00:25<00:00,  5.46it/s]\n",
      "Pan Fold-5: 100%|██████████| 139/139 [00:25<00:00,  5.49it/s]\n",
      "Pan Fold-6: 100%|██████████| 139/139 [00:25<00:00,  5.48it/s]\n",
      "Pan Fold-7: 100%|██████████| 139/139 [00:25<00:00,  5.43it/s]\n",
      "Pan Fold-8: 100%|██████████| 139/139 [00:25<00:00,  5.46it/s]\n",
      "Pan Fold-9: 100%|██████████| 139/139 [00:25<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Maalej ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maalej Fold-0: 100%|██████████| 370/370 [01:07<00:00,  5.46it/s]\n",
      "Maalej Fold-1: 100%|██████████| 370/370 [01:07<00:00,  5.49it/s]\n",
      "Maalej Fold-2: 100%|██████████| 370/370 [01:07<00:00,  5.48it/s]\n",
      "Maalej Fold-3: 100%|██████████| 370/370 [01:07<00:00,  5.49it/s]\n",
      "Maalej Fold-4: 100%|██████████| 370/370 [01:07<00:00,  5.45it/s]\n",
      "Maalej Fold-5: 100%|██████████| 370/370 [01:07<00:00,  5.44it/s]\n",
      "Maalej Fold-6: 100%|██████████| 370/370 [01:07<00:00,  5.44it/s]\n",
      "Maalej Fold-7: 100%|██████████| 370/370 [01:08<00:00,  5.43it/s]\n",
      "Maalej Fold-8: 100%|██████████| 370/370 [01:06<00:00,  5.53it/s]\n",
      "Maalej Fold-9: 100%|██████████| 370/370 [01:08<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Scalabrino ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scalabrino Fold-0: 100%|██████████| 300/300 [00:52<00:00,  5.68it/s]\n",
      "Scalabrino Fold-1: 100%|██████████| 300/300 [00:53<00:00,  5.62it/s]\n",
      "Scalabrino Fold-2: 100%|██████████| 300/300 [00:53<00:00,  5.59it/s]\n",
      "Scalabrino Fold-3: 100%|██████████| 300/300 [00:53<00:00,  5.61it/s]\n",
      "Scalabrino Fold-4: 100%|██████████| 300/300 [00:53<00:00,  5.65it/s]\n",
      "Scalabrino Fold-5: 100%|██████████| 300/300 [00:53<00:00,  5.64it/s]\n",
      "Scalabrino Fold-6: 100%|██████████| 300/300 [00:53<00:00,  5.61it/s]\n",
      "Scalabrino Fold-7: 100%|██████████| 300/300 [00:53<00:00,  5.60it/s]\n",
      "Scalabrino Fold-8: 100%|██████████| 300/300 [00:53<00:00,  5.61it/s]\n",
      "Scalabrino Fold-9: 100%|██████████| 300/300 [00:53<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Saved per-fold macro/micro results.\n",
      "\n",
      "📊 Computing final combined weighted metrics...\n",
      "✅ Pan: macro-F1=0.673, weighted-F1=0.762\n",
      "✅ Maalej: macro-F1=0.340, weighted-F1=0.233\n",
      "✅ Scalabrino: macro-F1=0.555, weighted-F1=0.539\n",
      "\n",
      "🎯 Done!\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# ─── CONFIG ───\n",
    "DATASET_DIRS = {\n",
    "    \"pan\": \"stratified_splits_80_10_10/pan\",\n",
    "    \"maalej\": \"stratified_splits_80_10_10/maalej\",\n",
    "    \"scalabrino\": \"stratified_splits_80_10_10/scalabrino\",\n",
    "}\n",
    "\n",
    "OLLAMA_MODEL = \"llama3:8b\"\n",
    "# Sanitize model name to make it a valid folder name\n",
    "MODEL_NAME_CLEAN = OLLAMA_MODEL.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "OUT_DIR = f\"zero_shot_folds_{MODEL_NAME_CLEAN}\"\n",
    "PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "os.makedirs(PRED_DIR, exist_ok=True)\n",
    "\n",
    "llm = OllamaLLM(model=OLLAMA_MODEL)\n",
    "\n",
    "# ─── PROMPT TEMPLATES ───\n",
    "LLAMA3_TEMPLATES = {\n",
    "    \"Pan\": (\n",
    "        \"You are a requirement classification assistant.\\n\"\n",
    "        \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "        \"Information Giving: factual descriptions, app details, or user opinions.\\n\"\n",
    "        \"Problem Discovery: issues, bugs, crashes, or errors.\\n\"\n",
    "        \"Feature Request: suggestions or desired improvements.\\n\"\n",
    "        \"Information Seeking: questions or asking for help.\\n\\n\"\n",
    "        \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    ),\n",
    "    \"Maalej\": (\n",
    "        \"You are a requirement classification assistant.\\n\"\n",
    "        \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "        \"Feature Request: suggestions or desires for new features, functionality, or improvements.\\n\"\n",
    "        \"Rating: numeric scores or general feedback like 'great app' or 'bad service'.\\n\"\n",
    "        \"User Experience: opinions about usability, UI, speed, or ease of use.\\n\"\n",
    "        \"Problem Discovery: reports of bugs, crashes, or errors.\\n\\n\"\n",
    "        \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    ),\n",
    "    \"Scalab\": (\n",
    "        \"You are a strict classification assistant.\\n\"\n",
    "        \"Classify the following app review into ONE and ONLY ONE of these categories:\\n\\n\"\n",
    "        \"BUG\\nFEATURE\\nPERFORMANCE\\nENERGY\\nSECURITY\\nUSABILITY\\nOTHER\\n\\n\"\n",
    "        \"- If unclear, choose OTHER.\\n\"\n",
    "        \"- Output the label name exactly as written above.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# ─── EVALUATION ───\n",
    "all_results = []\n",
    "\n",
    "def run_fold_zero_shot(df, labels, template, dataset_name, fold_id):\n",
    "    y_true = df[\"class\"].tolist()\n",
    "    req_ids = df[\"id\"].tolist()\n",
    "    texts = df[\"review\"].tolist() if \"review\" in df.columns else df[\"text\"].tolist()\n",
    "\n",
    "    preds = []\n",
    "    for txt in tqdm(texts, desc=f\"{dataset_name} Fold-{fold_id}\"):\n",
    "        prompt = template.format(req_text=txt)\n",
    "        pred = llm.invoke(prompt).strip()\n",
    "        pred = next((lab for lab in labels if lab.lower() in pred.lower()), labels[0])\n",
    "        preds.append(pred)\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"id\": req_ids,\n",
    "        \"text\": texts,\n",
    "        \"gold\": y_true,\n",
    "        \"pred\": preds\n",
    "    }).to_csv(os.path.join(PRED_DIR, f\"{dataset_name}_fold{fold_id}_preds.csv\"), index=False)\n",
    "\n",
    "    macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(y_true, preds, average=\"macro\", zero_division=0)\n",
    "    micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(y_true, preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_name, \"fold\": fold_id,\n",
    "        \"macro_precision\": macro_p, \"macro_recall\": macro_r, \"macro_f1\": macro_f1,\n",
    "        \"micro_precision\": micro_p, \"micro_recall\": micro_r, \"micro_f1\": micro_f1\n",
    "    }\n",
    "\n",
    "# ─── MAIN FOLD LOOP ───\n",
    "for dataset_name, folder in DATASET_DIRS.items():\n",
    "    print(f\"\\n=== {dataset_name} ===\")\n",
    "    labels = sorted(pd.read_csv(os.path.join(folder, \"test_fold_0.csv\"))[\"class\"].unique())\n",
    "    template = LLAMA3_TEMPLATES[dataset_name if dataset_name != \"Scalabrino\" else \"Scalab\"]\n",
    "\n",
    "    for i in range(10):\n",
    "        path = os.path.join(folder, f\"test_fold_{i}.csv\")\n",
    "        df = pd.read_csv(path)\n",
    "        metrics = run_fold_zero_shot(df, labels, template, dataset_name, i)\n",
    "        all_results.append(metrics)\n",
    "\n",
    "summary_df = pd.DataFrame(all_results)\n",
    "summary_df.to_csv(os.path.join(OUT_DIR, \"zero_shot_folded_summary.csv\"), index=False)\n",
    "print(\"\\n📁 Saved per-fold macro/micro results.\")\n",
    "# ─── FINAL FULL SET EVALUATION ───\n",
    "print(\"\\n📊 Computing final combined weighted metrics...\")\n",
    "\n",
    "def safe_metric(report, key, metric):\n",
    "    return report.get(key, {}).get(metric, 0.0)\n",
    "\n",
    "for dataset_name in DATASET_DIRS:\n",
    "    fold_preds = []\n",
    "    for i in range(10):\n",
    "        fold_path = os.path.join(PRED_DIR, f\"{dataset_name}_fold{i}_preds.csv\")\n",
    "        fold_df = pd.read_csv(fold_path)\n",
    "        fold_preds.append(fold_df)\n",
    "\n",
    "    all_df = pd.concat(fold_preds, ignore_index=True)\n",
    "    y_true = all_df[\"gold\"].str.lower()\n",
    "    y_pred = all_df[\"pred\"].str.lower()\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    final_metrics = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"macro_precision\":   safe_metric(report, \"macro avg\", \"precision\"),\n",
    "        \"macro_recall\":      safe_metric(report, \"macro avg\", \"recall\"),\n",
    "        \"macro_f1\":          safe_metric(report, \"macro avg\", \"f1-score\"),\n",
    "        \"micro_precision\":   safe_metric(report, \"micro avg\", \"precision\"),\n",
    "        \"micro_recall\":      safe_metric(report, \"micro avg\", \"recall\"),\n",
    "        \"micro_f1\":          safe_metric(report, \"micro avg\", \"f1-score\"),\n",
    "        \"weighted_precision\": safe_metric(report, \"weighted avg\", \"precision\"),\n",
    "        \"weighted_recall\":    safe_metric(report, \"weighted avg\", \"recall\"),\n",
    "        \"weighted_f1\":        safe_metric(report, \"weighted avg\", \"f1-score\")\n",
    "    }\n",
    "\n",
    "    pd.DataFrame([final_metrics]).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{dataset_name}_final_combined_metrics.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"✅ {dataset_name}: macro-F1={final_metrics['macro_f1']:.3f}, weighted-F1={final_metrics['weighted_f1']:.3f}\")\n",
    "\n",
    "print(\"\\n🎯 Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a8d422e-1785-405d-a1e3-b201b95ff5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pan ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pan Fold-0: 100%|██████████| 139/139 [00:14<00:00,  9.81it/s]\n",
      "Pan Fold-1: 100%|██████████| 139/139 [00:11<00:00, 11.83it/s]\n",
      "Pan Fold-2: 100%|██████████| 139/139 [00:11<00:00, 12.13it/s]\n",
      "Pan Fold-3: 100%|██████████| 139/139 [00:11<00:00, 11.87it/s]\n",
      "Pan Fold-4: 100%|██████████| 139/139 [00:11<00:00, 12.12it/s]\n",
      "Pan Fold-5: 100%|██████████| 139/139 [00:11<00:00, 12.24it/s]\n",
      "Pan Fold-6: 100%|██████████| 139/139 [00:11<00:00, 12.02it/s]\n",
      "Pan Fold-7: 100%|██████████| 139/139 [00:11<00:00, 12.42it/s]\n",
      "Pan Fold-8: 100%|██████████| 139/139 [00:11<00:00, 12.14it/s]\n",
      "Pan Fold-9: 100%|██████████| 139/139 [00:11<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Maalej ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maalej Fold-0: 100%|██████████| 370/370 [00:28<00:00, 13.07it/s]\n",
      "Maalej Fold-1: 100%|██████████| 370/370 [00:28<00:00, 12.95it/s]\n",
      "Maalej Fold-2: 100%|██████████| 370/370 [00:28<00:00, 12.87it/s]\n",
      "Maalej Fold-3: 100%|██████████| 370/370 [00:28<00:00, 13.18it/s]\n",
      "Maalej Fold-4: 100%|██████████| 370/370 [00:28<00:00, 13.05it/s]\n",
      "Maalej Fold-5: 100%|██████████| 370/370 [00:28<00:00, 12.81it/s]\n",
      "Maalej Fold-6: 100%|██████████| 370/370 [00:28<00:00, 13.10it/s]\n",
      "Maalej Fold-7: 100%|██████████| 370/370 [00:28<00:00, 13.13it/s]\n",
      "Maalej Fold-8: 100%|██████████| 370/370 [00:28<00:00, 13.04it/s]\n",
      "Maalej Fold-9: 100%|██████████| 370/370 [00:28<00:00, 13.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Scalabrino ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scalabrino Fold-0: 100%|██████████| 300/300 [00:26<00:00, 11.47it/s]\n",
      "Scalabrino Fold-1: 100%|██████████| 300/300 [00:26<00:00, 11.18it/s]\n",
      "Scalabrino Fold-2: 100%|██████████| 300/300 [00:27<00:00, 10.82it/s]\n",
      "Scalabrino Fold-3: 100%|██████████| 300/300 [00:29<00:00, 10.20it/s]\n",
      "Scalabrino Fold-4: 100%|██████████| 300/300 [00:27<00:00, 10.83it/s]\n",
      "Scalabrino Fold-5: 100%|██████████| 300/300 [00:27<00:00, 10.99it/s]\n",
      "Scalabrino Fold-6: 100%|██████████| 300/300 [00:27<00:00, 10.73it/s]\n",
      "Scalabrino Fold-7: 100%|██████████| 300/300 [00:28<00:00, 10.56it/s]\n",
      "Scalabrino Fold-8: 100%|██████████| 300/300 [00:28<00:00, 10.67it/s]\n",
      "Scalabrino Fold-9: 100%|██████████| 300/300 [00:26<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Saved per-fold macro/micro results.\n",
      "\n",
      "📊 Computing final combined weighted metrics...\n",
      "✅ Pan: macro-F1=0.721, weighted-F1=0.792\n",
      "✅ Maalej: macro-F1=0.450, weighted-F1=0.515\n",
      "✅ Scalabrino: macro-F1=0.401, weighted-F1=0.275\n",
      "\n",
      "🎯 Done!\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# ─── CONFIG ───\n",
    "DATASET_DIRS = {\n",
    "    \"Pan\": \"stratified_splits_80_10_10/pan\",\n",
    "    \"Maalej\": \"stratified_splits_80_10_10/maalej\",\n",
    "    \"Scalabrino\": \"stratified_splits_80_10_10/scalabrino\",\n",
    "}\n",
    "\n",
    "OLLAMA_MODEL = \"mistral:7b\"\n",
    "# Sanitize model name to make it a valid folder name\n",
    "MODEL_NAME_CLEAN = OLLAMA_MODEL.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "OUT_DIR = f\"zero_shot_folds_{MODEL_NAME_CLEAN}\"\n",
    "PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "os.makedirs(PRED_DIR, exist_ok=True)\n",
    "\n",
    "llm = OllamaLLM(model=OLLAMA_MODEL)\n",
    "\n",
    "# ─── PROMPT TEMPLATES ───\n",
    "LLAMA3_TEMPLATES = {\n",
    "    \"Pan\": (\n",
    "        \"You are a requirement classification assistant.\\n\"\n",
    "        \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "        \"Information Giving: factual descriptions, app details, or user opinions.\\n\"\n",
    "        \"Problem Discovery: issues, bugs, crashes, or errors.\\n\"\n",
    "        \"Feature Request: suggestions or desired improvements.\\n\"\n",
    "        \"Information Seeking: questions or asking for help.\\n\\n\"\n",
    "        \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    ),\n",
    "    \"Maalej\": (\n",
    "        \"You are a requirement classification assistant.\\n\"\n",
    "        \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "        \"Feature Request: suggestions or desires for new features, functionality, or improvements.\\n\"\n",
    "        \"Rating: numeric scores or general feedback like 'great app' or 'bad service'.\\n\"\n",
    "        \"User Experience: opinions about usability, UI, speed, or ease of use.\\n\"\n",
    "        \"Problem Discovery: reports of bugs, crashes, or errors.\\n\\n\"\n",
    "        \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    ),\n",
    "    \"Scalab\": (\n",
    "        \"You are a strict classification assistant.\\n\"\n",
    "        \"Classify the following app review into ONE and ONLY ONE of these categories:\\n\\n\"\n",
    "        \"BUG\\nFEATURE\\nPERFORMANCE\\nENERGY\\nSECURITY\\nUSABILITY\\nOTHER\\n\\n\"\n",
    "        \"- If unclear, choose OTHER.\\n\"\n",
    "        \"- Output the label name exactly as written above.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# ─── EVALUATION ───\n",
    "all_results = []\n",
    "\n",
    "def run_fold_zero_shot(df, labels, template, dataset_name, fold_id):\n",
    "    y_true = df[\"class\"].tolist()\n",
    "    req_ids = df[\"id\"].tolist()\n",
    "    texts = df[\"review\"].tolist() if \"review\" in df.columns else df[\"text\"].tolist()\n",
    "\n",
    "    preds = []\n",
    "    for txt in tqdm(texts, desc=f\"{dataset_name} Fold-{fold_id}\"):\n",
    "        prompt = template.format(req_text=txt)\n",
    "        pred = llm.invoke(prompt).strip()\n",
    "        pred = next((lab for lab in labels if lab.lower() in pred.lower()), labels[0])\n",
    "        preds.append(pred)\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"id\": req_ids,\n",
    "        \"text\": texts,\n",
    "        \"gold\": y_true,\n",
    "        \"pred\": preds\n",
    "    }).to_csv(os.path.join(PRED_DIR, f\"{dataset_name}_fold{fold_id}_preds.csv\"), index=False)\n",
    "\n",
    "    macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(y_true, preds, average=\"macro\", zero_division=0)\n",
    "    micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(y_true, preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_name, \"fold\": fold_id,\n",
    "        \"macro_precision\": macro_p, \"macro_recall\": macro_r, \"macro_f1\": macro_f1,\n",
    "        \"micro_precision\": micro_p, \"micro_recall\": micro_r, \"micro_f1\": micro_f1\n",
    "    }\n",
    "\n",
    "# ─── MAIN FOLD LOOP ───\n",
    "for dataset_name, folder in DATASET_DIRS.items():\n",
    "    print(f\"\\n=== {dataset_name} ===\")\n",
    "    labels = sorted(pd.read_csv(os.path.join(folder, \"test_fold_0.csv\"))[\"class\"].unique())\n",
    "    template = LLAMA3_TEMPLATES[dataset_name if dataset_name != \"Scalabrino\" else \"Scalab\"]\n",
    "\n",
    "    for i in range(10):\n",
    "        path = os.path.join(folder, f\"test_fold_{i}.csv\")\n",
    "        df = pd.read_csv(path)\n",
    "        metrics = run_fold_zero_shot(df, labels, template, dataset_name, i)\n",
    "        all_results.append(metrics)\n",
    "\n",
    "summary_df = pd.DataFrame(all_results)\n",
    "summary_df.to_csv(os.path.join(OUT_DIR, \"zero_shot_folded_summary.csv\"), index=False)\n",
    "print(\"\\n📁 Saved per-fold macro/micro results.\")\n",
    "# ─── FINAL FULL SET EVALUATION ───\n",
    "print(\"\\n📊 Computing final combined weighted metrics...\")\n",
    "\n",
    "def safe_metric(report, key, metric):\n",
    "    return report.get(key, {}).get(metric, 0.0)\n",
    "\n",
    "for dataset_name in DATASET_DIRS:\n",
    "    fold_preds = []\n",
    "    for i in range(10):\n",
    "        fold_path = os.path.join(PRED_DIR, f\"{dataset_name}_fold{i}_preds.csv\")\n",
    "        fold_df = pd.read_csv(fold_path)\n",
    "        fold_preds.append(fold_df)\n",
    "\n",
    "    all_df = pd.concat(fold_preds, ignore_index=True)\n",
    "    y_true = all_df[\"gold\"].str.lower()\n",
    "    y_pred = all_df[\"pred\"].str.lower()\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    final_metrics = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"macro_precision\":   safe_metric(report, \"macro avg\", \"precision\"),\n",
    "        \"macro_recall\":      safe_metric(report, \"macro avg\", \"recall\"),\n",
    "        \"macro_f1\":          safe_metric(report, \"macro avg\", \"f1-score\"),\n",
    "        \"micro_precision\":   safe_metric(report, \"micro avg\", \"precision\"),\n",
    "        \"micro_recall\":      safe_metric(report, \"micro avg\", \"recall\"),\n",
    "        \"micro_f1\":          safe_metric(report, \"micro avg\", \"f1-score\"),\n",
    "        \"weighted_precision\": safe_metric(report, \"weighted avg\", \"precision\"),\n",
    "        \"weighted_recall\":    safe_metric(report, \"weighted avg\", \"recall\"),\n",
    "        \"weighted_f1\":        safe_metric(report, \"weighted avg\", \"f1-score\")\n",
    "    }\n",
    "\n",
    "    pd.DataFrame([final_metrics]).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{dataset_name}_final_combined_metrics.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"✅ {dataset_name}: macro-F1={final_metrics['macro_f1']:.3f}, weighted-F1={final_metrics['weighted_f1']:.3f}\")\n",
    "\n",
    "print(\"\\n🎯 Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba618c3d-f96d-40e6-9269-7602c6ba49d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pan ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pan Fold-0: 100%|██████████| 139/139 [00:38<00:00,  3.60it/s]\n",
      "Pan Fold-1: 100%|██████████| 139/139 [00:32<00:00,  4.27it/s]\n",
      "Pan Fold-2: 100%|██████████| 139/139 [00:32<00:00,  4.24it/s]\n",
      "Pan Fold-3: 100%|██████████| 139/139 [00:33<00:00,  4.16it/s]\n",
      "Pan Fold-4: 100%|██████████| 139/139 [00:32<00:00,  4.30it/s]\n",
      "Pan Fold-5: 100%|██████████| 139/139 [00:33<00:00,  4.20it/s]\n",
      "Pan Fold-6: 100%|██████████| 139/139 [00:32<00:00,  4.29it/s]\n",
      "Pan Fold-7: 100%|██████████| 139/139 [00:33<00:00,  4.19it/s]\n",
      "Pan Fold-8: 100%|██████████| 139/139 [00:29<00:00,  4.67it/s]\n",
      "Pan Fold-9: 100%|██████████| 139/139 [00:33<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Maalej ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maalej Fold-0: 100%|██████████| 370/370 [01:25<00:00,  4.34it/s]\n",
      "Maalej Fold-1: 100%|██████████| 370/370 [01:25<00:00,  4.31it/s]\n",
      "Maalej Fold-2: 100%|██████████| 370/370 [01:25<00:00,  4.33it/s]\n",
      "Maalej Fold-3: 100%|██████████| 370/370 [01:26<00:00,  4.27it/s]\n",
      "Maalej Fold-4: 100%|██████████| 370/370 [01:24<00:00,  4.39it/s]\n",
      "Maalej Fold-5: 100%|██████████| 370/370 [01:24<00:00,  4.36it/s]\n",
      "Maalej Fold-6: 100%|██████████| 370/370 [01:25<00:00,  4.34it/s]\n",
      "Maalej Fold-7: 100%|██████████| 370/370 [01:24<00:00,  4.37it/s]\n",
      "Maalej Fold-8: 100%|██████████| 370/370 [01:27<00:00,  4.21it/s]\n",
      "Maalej Fold-9: 100%|██████████| 370/370 [01:25<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Scalabrino ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scalabrino Fold-0: 100%|██████████| 300/300 [01:10<00:00,  4.24it/s]\n",
      "Scalabrino Fold-1: 100%|██████████| 300/300 [01:11<00:00,  4.21it/s]\n",
      "Scalabrino Fold-2: 100%|██████████| 300/300 [01:11<00:00,  4.22it/s]\n",
      "Scalabrino Fold-3: 100%|██████████| 300/300 [01:10<00:00,  4.27it/s]\n",
      "Scalabrino Fold-4: 100%|██████████| 300/300 [01:09<00:00,  4.29it/s]\n",
      "Scalabrino Fold-5: 100%|██████████| 300/300 [01:11<00:00,  4.22it/s]\n",
      "Scalabrino Fold-6: 100%|██████████| 300/300 [01:09<00:00,  4.29it/s]\n",
      "Scalabrino Fold-7: 100%|██████████| 300/300 [01:10<00:00,  4.27it/s]\n",
      "Scalabrino Fold-8: 100%|██████████| 300/300 [01:10<00:00,  4.24it/s]\n",
      "Scalabrino Fold-9: 100%|██████████| 300/300 [01:09<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Saved per-fold macro/micro results.\n",
      "\n",
      "📊 Computing final combined weighted metrics...\n",
      "✅ Pan: macro-F1=0.660, weighted-F1=0.746\n",
      "✅ Maalej: macro-F1=0.445, weighted-F1=0.638\n",
      "✅ Scalabrino: macro-F1=0.516, weighted-F1=0.585\n",
      "\n",
      "🎯 Done!\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# ─── CONFIG ───\n",
    "DATASET_DIRS = {\n",
    "    \"Pan\": \"stratified_splits_80_10_10/pan\",\n",
    "    \"Maalej\": \"stratified_splits_80_10_10/maalej\",\n",
    "    \"Scalabrino\": \"stratified_splits_80_10_10/scalabrino\",\n",
    "}\n",
    "\n",
    "OLLAMA_MODEL = \"gemma3:4b\"\n",
    "# Sanitize model name to make it a valid folder name\n",
    "MODEL_NAME_CLEAN = OLLAMA_MODEL.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "OUT_DIR = f\"zero_shot_folds_{MODEL_NAME_CLEAN}\"\n",
    "PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "os.makedirs(PRED_DIR, exist_ok=True)\n",
    "\n",
    "llm = OllamaLLM(model=OLLAMA_MODEL)\n",
    "\n",
    "# ─── PROMPT TEMPLATES ───\n",
    "LLAMA3_TEMPLATES = {\n",
    "    \"Pan\": (\n",
    "        \"You are a requirement classification assistant.\\n\"\n",
    "        \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "        \"Information Giving: factual descriptions, app details, or user opinions.\\n\"\n",
    "        \"Problem Discovery: issues, bugs, crashes, or errors.\\n\"\n",
    "        \"Feature Request: suggestions or desired improvements.\\n\"\n",
    "        \"Information Seeking: questions or asking for help.\\n\\n\"\n",
    "        \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    ),\n",
    "    \"Maalej\": (\n",
    "        \"You are a requirement classification assistant.\\n\"\n",
    "        \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "        \"Feature Request: suggestions or desires for new features, functionality, or improvements.\\n\"\n",
    "        \"Rating: numeric scores or general feedback like 'great app' or 'bad service'.\\n\"\n",
    "        \"User Experience: opinions about usability, UI, speed, or ease of use.\\n\"\n",
    "        \"Problem Discovery: reports of bugs, crashes, or errors.\\n\\n\"\n",
    "        \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    ),\n",
    "    \"Scalab\": (\n",
    "        \"You are a strict classification assistant.\\n\"\n",
    "        \"Classify the following app review into ONE and ONLY ONE of these categories:\\n\\n\"\n",
    "        \"BUG\\nFEATURE\\nPERFORMANCE\\nENERGY\\nSECURITY\\nUSABILITY\\nOTHER\\n\\n\"\n",
    "        \"- If unclear, choose OTHER.\\n\"\n",
    "        \"- Output the label name exactly as written above.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# ─── EVALUATION ───\n",
    "all_results = []\n",
    "\n",
    "def run_fold_zero_shot(df, labels, template, dataset_name, fold_id):\n",
    "    y_true = df[\"class\"].tolist()\n",
    "    req_ids = df[\"id\"].tolist()\n",
    "    texts = df[\"review\"].tolist() if \"review\" in df.columns else df[\"text\"].tolist()\n",
    "\n",
    "    preds = []\n",
    "    for txt in tqdm(texts, desc=f\"{dataset_name} Fold-{fold_id}\"):\n",
    "        prompt = template.format(req_text=txt)\n",
    "        pred = llm.invoke(prompt).strip()\n",
    "        pred = next((lab for lab in labels if lab.lower() in pred.lower()), labels[0])\n",
    "        preds.append(pred)\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"id\": req_ids,\n",
    "        \"text\": texts,\n",
    "        \"gold\": y_true,\n",
    "        \"pred\": preds\n",
    "    }).to_csv(os.path.join(PRED_DIR, f\"{dataset_name}_fold{fold_id}_preds.csv\"), index=False)\n",
    "\n",
    "    macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(y_true, preds, average=\"macro\", zero_division=0)\n",
    "    micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(y_true, preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_name, \"fold\": fold_id,\n",
    "        \"macro_precision\": macro_p, \"macro_recall\": macro_r, \"macro_f1\": macro_f1,\n",
    "        \"micro_precision\": micro_p, \"micro_recall\": micro_r, \"micro_f1\": micro_f1\n",
    "    }\n",
    "\n",
    "# ─── MAIN FOLD LOOP ───\n",
    "for dataset_name, folder in DATASET_DIRS.items():\n",
    "    print(f\"\\n=== {dataset_name} ===\")\n",
    "    labels = sorted(pd.read_csv(os.path.join(folder, \"test_fold_0.csv\"))[\"class\"].unique())\n",
    "    template = LLAMA3_TEMPLATES[dataset_name if dataset_name != \"Scalabrino\" else \"Scalab\"]\n",
    "\n",
    "    for i in range(10):\n",
    "        path = os.path.join(folder, f\"test_fold_{i}.csv\")\n",
    "        df = pd.read_csv(path)\n",
    "        metrics = run_fold_zero_shot(df, labels, template, dataset_name, i)\n",
    "        all_results.append(metrics)\n",
    "\n",
    "summary_df = pd.DataFrame(all_results)\n",
    "summary_df.to_csv(os.path.join(OUT_DIR, \"zero_shot_folded_summary.csv\"), index=False)\n",
    "print(\"\\n📁 Saved per-fold macro/micro results.\")\n",
    "# ─── FINAL FULL SET EVALUATION ───\n",
    "print(\"\\n📊 Computing final combined weighted metrics...\")\n",
    "\n",
    "def safe_metric(report, key, metric):\n",
    "    return report.get(key, {}).get(metric, 0.0)\n",
    "\n",
    "for dataset_name in DATASET_DIRS:\n",
    "    fold_preds = []\n",
    "    for i in range(10):\n",
    "        fold_path = os.path.join(PRED_DIR, f\"{dataset_name}_fold{i}_preds.csv\")\n",
    "        fold_df = pd.read_csv(fold_path)\n",
    "        fold_preds.append(fold_df)\n",
    "\n",
    "    all_df = pd.concat(fold_preds, ignore_index=True)\n",
    "    y_true = all_df[\"gold\"].str.lower()\n",
    "    y_pred = all_df[\"pred\"].str.lower()\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    final_metrics = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"macro_precision\":   safe_metric(report, \"macro avg\", \"precision\"),\n",
    "        \"macro_recall\":      safe_metric(report, \"macro avg\", \"recall\"),\n",
    "        \"macro_f1\":          safe_metric(report, \"macro avg\", \"f1-score\"),\n",
    "        \"micro_precision\":   safe_metric(report, \"micro avg\", \"precision\"),\n",
    "        \"micro_recall\":      safe_metric(report, \"micro avg\", \"recall\"),\n",
    "        \"micro_f1\":          safe_metric(report, \"micro avg\", \"f1-score\"),\n",
    "        \"weighted_precision\": safe_metric(report, \"weighted avg\", \"precision\"),\n",
    "        \"weighted_recall\":    safe_metric(report, \"weighted avg\", \"recall\"),\n",
    "        \"weighted_f1\":        safe_metric(report, \"weighted avg\", \"f1-score\")\n",
    "    }\n",
    "\n",
    "    pd.DataFrame([final_metrics]).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{dataset_name}_final_combined_metrics.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"✅ {dataset_name}: macro-F1={final_metrics['macro_f1']:.3f}, weighted-F1={final_metrics['weighted_f1']:.3f}\")\n",
    "\n",
    "print(\"\\n🎯 Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "295f6cc2-31f7-49b7-bb63-e045b5a18cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pan ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pan Fold-0: 100%|██████████| 139/139 [00:14<00:00,  9.37it/s]\n",
      "Pan Fold-1: 100%|██████████| 139/139 [00:13<00:00, 10.64it/s]\n",
      "Pan Fold-2: 100%|██████████| 139/139 [00:12<00:00, 11.53it/s]\n",
      "Pan Fold-3: 100%|██████████| 139/139 [00:12<00:00, 11.19it/s]\n",
      "Pan Fold-4: 100%|██████████| 139/139 [00:11<00:00, 12.01it/s]\n",
      "Pan Fold-5: 100%|██████████| 139/139 [00:11<00:00, 11.89it/s]\n",
      "Pan Fold-6: 100%|██████████| 139/139 [00:13<00:00,  9.94it/s]\n",
      "Pan Fold-7: 100%|██████████| 139/139 [00:13<00:00, 10.47it/s]\n",
      "Pan Fold-8: 100%|██████████| 139/139 [00:12<00:00, 11.47it/s]\n",
      "Pan Fold-9: 100%|██████████| 139/139 [00:11<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Maalej ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maalej Fold-0: 100%|██████████| 370/370 [00:43<00:00,  8.60it/s]\n",
      "Maalej Fold-1: 100%|██████████| 370/370 [00:39<00:00,  9.39it/s]\n",
      "Maalej Fold-2: 100%|██████████| 370/370 [00:43<00:00,  8.58it/s]\n",
      "Maalej Fold-3: 100%|██████████| 370/370 [00:36<00:00, 10.24it/s]\n",
      "Maalej Fold-4: 100%|██████████| 370/370 [00:40<00:00,  9.12it/s]\n",
      "Maalej Fold-5: 100%|██████████| 370/370 [00:41<00:00,  8.82it/s]\n",
      "Maalej Fold-6: 100%|██████████| 370/370 [00:40<00:00,  9.15it/s]\n",
      "Maalej Fold-7: 100%|██████████| 370/370 [00:40<00:00,  9.03it/s]\n",
      "Maalej Fold-8: 100%|██████████| 370/370 [00:39<00:00,  9.42it/s]\n",
      "Maalej Fold-9: 100%|██████████| 370/370 [00:40<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Scalabrino ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scalabrino Fold-0: 100%|██████████| 300/300 [02:13<00:00,  2.25it/s]\n",
      "Scalabrino Fold-1: 100%|██████████| 300/300 [02:07<00:00,  2.35it/s]\n",
      "Scalabrino Fold-2: 100%|██████████| 300/300 [02:06<00:00,  2.38it/s]\n",
      "Scalabrino Fold-3: 100%|██████████| 300/300 [02:04<00:00,  2.41it/s]\n",
      "Scalabrino Fold-4: 100%|██████████| 300/300 [02:11<00:00,  2.28it/s]\n",
      "Scalabrino Fold-5: 100%|██████████| 300/300 [02:06<00:00,  2.38it/s]\n",
      "Scalabrino Fold-6: 100%|██████████| 300/300 [02:07<00:00,  2.36it/s]\n",
      "Scalabrino Fold-7: 100%|██████████| 300/300 [02:13<00:00,  2.25it/s]\n",
      "Scalabrino Fold-8: 100%|██████████| 300/300 [02:11<00:00,  2.28it/s]\n",
      "Scalabrino Fold-9: 100%|██████████| 300/300 [02:11<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Saved per-fold macro/micro results.\n",
      "\n",
      "📊 Computing final combined weighted metrics...\n",
      "✅ Pan: macro-F1=0.662, weighted-F1=0.749\n",
      "✅ Maalej: macro-F1=0.404, weighted-F1=0.452\n",
      "✅ Scalabrino: macro-F1=0.475, weighted-F1=0.288\n",
      "\n",
      "🎯 Done!\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# ─── CONFIG ───\n",
    "DATASET_DIRS = {\n",
    "    \"Pan\": \"stratified_splits_80_10_10/pan\",\n",
    "    \"Maalej\": \"stratified_splits_80_10_10/maalej\",\n",
    "    \"Scalabrino\": \"stratified_splits_80_10_10/scalabrino\",\n",
    "}\n",
    "\n",
    "OLLAMA_MODEL = \"wizardlm2:7b\"\n",
    "# Sanitize model name to make it a valid folder name\n",
    "MODEL_NAME_CLEAN = OLLAMA_MODEL.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "OUT_DIR = f\"zero_shot_folds_{MODEL_NAME_CLEAN}\"\n",
    "PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "os.makedirs(PRED_DIR, exist_ok=True)\n",
    "\n",
    "llm = OllamaLLM(model=OLLAMA_MODEL)\n",
    "\n",
    "# ─── PROMPT TEMPLATES ───\n",
    "LLAMA3_TEMPLATES = {\n",
    "    \"Pan\": (\n",
    "        \"You are a requirement classification assistant.\\n\"\n",
    "        \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "        \"Information Giving: factual descriptions, app details, or user opinions.\\n\"\n",
    "        \"Problem Discovery: issues, bugs, crashes, or errors.\\n\"\n",
    "        \"Feature Request: suggestions or desired improvements.\\n\"\n",
    "        \"Information Seeking: questions or asking for help.\\n\\n\"\n",
    "        \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    ),\n",
    "    \"Maalej\": (\n",
    "        \"You are a requirement classification assistant.\\n\"\n",
    "        \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "        \"Feature Request: suggestions or desires for new features, functionality, or improvements.\\n\"\n",
    "        \"Rating: numeric scores or general feedback like 'great app' or 'bad service'.\\n\"\n",
    "        \"User Experience: opinions about usability, UI, speed, or ease of use.\\n\"\n",
    "        \"Problem Discovery: reports of bugs, crashes, or errors.\\n\\n\"\n",
    "        \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    ),\n",
    "    \"Scalab\": (\n",
    "        \"You are a strict classification assistant.\\n\"\n",
    "        \"Classify the following app review into ONE and ONLY ONE of these categories:\\n\\n\"\n",
    "        \"BUG\\nFEATURE\\nPERFORMANCE\\nENERGY\\nSECURITY\\nUSABILITY\\nOTHER\\n\\n\"\n",
    "        \"- If unclear, choose OTHER.\\n\"\n",
    "        \"- Output the label name exactly as written above.\\n\\n\"\n",
    "        \"Review: {req_text}\\n\"\n",
    "        \"Label:\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# ─── EVALUATION ───\n",
    "all_results = []\n",
    "\n",
    "def run_fold_zero_shot(df, labels, template, dataset_name, fold_id):\n",
    "    y_true = df[\"class\"].tolist()\n",
    "    req_ids = df[\"id\"].tolist()\n",
    "    texts = df[\"review\"].tolist() if \"review\" in df.columns else df[\"text\"].tolist()\n",
    "\n",
    "    preds = []\n",
    "    for txt in tqdm(texts, desc=f\"{dataset_name} Fold-{fold_id}\"):\n",
    "        prompt = template.format(req_text=txt)\n",
    "        pred = llm.invoke(prompt).strip()\n",
    "        pred = next((lab for lab in labels if lab.lower() in pred.lower()), labels[0])\n",
    "        preds.append(pred)\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"id\": req_ids,\n",
    "        \"text\": texts,\n",
    "        \"gold\": y_true,\n",
    "        \"pred\": preds\n",
    "    }).to_csv(os.path.join(PRED_DIR, f\"{dataset_name}_fold{fold_id}_preds.csv\"), index=False)\n",
    "\n",
    "    macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(y_true, preds, average=\"macro\", zero_division=0)\n",
    "    micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(y_true, preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_name, \"fold\": fold_id,\n",
    "        \"macro_precision\": macro_p, \"macro_recall\": macro_r, \"macro_f1\": macro_f1,\n",
    "        \"micro_precision\": micro_p, \"micro_recall\": micro_r, \"micro_f1\": micro_f1\n",
    "    }\n",
    "\n",
    "# ─── MAIN FOLD LOOP ───\n",
    "for dataset_name, folder in DATASET_DIRS.items():\n",
    "    print(f\"\\n=== {dataset_name} ===\")\n",
    "    labels = sorted(pd.read_csv(os.path.join(folder, \"test_fold_0.csv\"))[\"class\"].unique())\n",
    "    template = LLAMA3_TEMPLATES[dataset_name if dataset_name != \"Scalabrino\" else \"Scalab\"]\n",
    "\n",
    "    for i in range(10):\n",
    "        path = os.path.join(folder, f\"test_fold_{i}.csv\")\n",
    "        df = pd.read_csv(path)\n",
    "        metrics = run_fold_zero_shot(df, labels, template, dataset_name, i)\n",
    "        all_results.append(metrics)\n",
    "\n",
    "summary_df = pd.DataFrame(all_results)\n",
    "summary_df.to_csv(os.path.join(OUT_DIR, \"zero_shot_folded_summary.csv\"), index=False)\n",
    "print(\"\\n📁 Saved per-fold macro/micro results.\")\n",
    "# ─── FINAL FULL SET EVALUATION ───\n",
    "print(\"\\n📊 Computing final combined weighted metrics...\")\n",
    "\n",
    "def safe_metric(report, key, metric):\n",
    "    return report.get(key, {}).get(metric, 0.0)\n",
    "\n",
    "for dataset_name in DATASET_DIRS:\n",
    "    fold_preds = []\n",
    "    for i in range(10):\n",
    "        fold_path = os.path.join(PRED_DIR, f\"{dataset_name}_fold{i}_preds.csv\")\n",
    "        fold_df = pd.read_csv(fold_path)\n",
    "        fold_preds.append(fold_df)\n",
    "\n",
    "    all_df = pd.concat(fold_preds, ignore_index=True)\n",
    "    y_true = all_df[\"gold\"].str.lower()\n",
    "    y_pred = all_df[\"pred\"].str.lower()\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    final_metrics = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"macro_precision\":   safe_metric(report, \"macro avg\", \"precision\"),\n",
    "        \"macro_recall\":      safe_metric(report, \"macro avg\", \"recall\"),\n",
    "        \"macro_f1\":          safe_metric(report, \"macro avg\", \"f1-score\"),\n",
    "        \"micro_precision\":   safe_metric(report, \"micro avg\", \"precision\"),\n",
    "        \"micro_recall\":      safe_metric(report, \"micro avg\", \"recall\"),\n",
    "        \"micro_f1\":          safe_metric(report, \"micro avg\", \"f1-score\"),\n",
    "        \"weighted_precision\": safe_metric(report, \"weighted avg\", \"precision\"),\n",
    "        \"weighted_recall\":    safe_metric(report, \"weighted avg\", \"recall\"),\n",
    "        \"weighted_f1\":        safe_metric(report, \"weighted avg\", \"f1-score\")\n",
    "    }\n",
    "\n",
    "    pd.DataFrame([final_metrics]).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{dataset_name}_final_combined_metrics.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"✅ {dataset_name}: macro-F1={final_metrics['macro_f1']:.3f}, weighted-F1={final_metrics['weighted_f1']:.3f}\")\n",
    "\n",
    "print(\"\\n🎯 Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2554eeac-e2d7-46b6-8683-ac3d1df7800e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PAN | Fold-0 | 1-shot: 100%|██████████| 139/139 [00:43<00:00,  3.19req/s]\n",
      "PAN | Fold-0 | 3-shot: 100%|██████████| 139/139 [00:44<00:00,  3.14req/s]\n",
      "PAN | Fold-0 | 5-shot: 100%|██████████| 139/139 [00:43<00:00,  3.17req/s]\n",
      "PAN | Fold-0 | 7-shot: 100%|██████████| 139/139 [00:44<00:00,  3.12req/s]\n",
      "PAN | Fold-1 | 1-shot: 100%|██████████| 139/139 [00:43<00:00,  3.18req/s]\n",
      "PAN | Fold-1 | 3-shot: 100%|██████████| 139/139 [00:44<00:00,  3.10req/s]\n",
      "PAN | Fold-1 | 5-shot: 100%|██████████| 139/139 [00:45<00:00,  3.05req/s]\n",
      "PAN | Fold-1 | 7-shot: 100%|██████████| 139/139 [00:45<00:00,  3.05req/s]\n",
      "PAN | Fold-2 | 1-shot: 100%|██████████| 139/139 [00:45<00:00,  3.09req/s]\n",
      "PAN | Fold-2 | 3-shot: 100%|██████████| 139/139 [00:44<00:00,  3.11req/s]\n",
      "PAN | Fold-2 | 5-shot: 100%|██████████| 139/139 [00:45<00:00,  3.04req/s]\n",
      "PAN | Fold-2 | 7-shot: 100%|██████████| 139/139 [00:46<00:00,  2.98req/s]\n",
      "PAN | Fold-3 | 1-shot: 100%|██████████| 139/139 [00:45<00:00,  3.08req/s]\n",
      "PAN | Fold-3 | 3-shot: 100%|██████████| 139/139 [00:44<00:00,  3.14req/s]\n",
      "PAN | Fold-3 | 5-shot: 100%|██████████| 139/139 [00:44<00:00,  3.12req/s]\n",
      "PAN | Fold-3 | 7-shot: 100%|██████████| 139/139 [00:45<00:00,  3.08req/s]\n",
      "PAN | Fold-4 | 1-shot: 100%|██████████| 139/139 [00:43<00:00,  3.20req/s]\n",
      "PAN | Fold-4 | 3-shot: 100%|██████████| 139/139 [00:44<00:00,  3.15req/s]\n",
      "PAN | Fold-4 | 5-shot: 100%|██████████| 139/139 [00:44<00:00,  3.09req/s]\n",
      "PAN | Fold-4 | 7-shot: 100%|██████████| 139/139 [00:45<00:00,  3.08req/s]\n",
      "PAN | Fold-5 | 1-shot: 100%|██████████| 139/139 [00:44<00:00,  3.16req/s]\n",
      "PAN | Fold-5 | 3-shot: 100%|██████████| 139/139 [00:44<00:00,  3.14req/s]\n",
      "PAN | Fold-5 | 5-shot: 100%|██████████| 139/139 [00:44<00:00,  3.11req/s]\n",
      "PAN | Fold-5 | 7-shot: 100%|██████████| 139/139 [00:44<00:00,  3.11req/s]\n",
      "PAN | Fold-6 | 1-shot: 100%|██████████| 139/139 [00:44<00:00,  3.11req/s]\n",
      "PAN | Fold-6 | 3-shot: 100%|██████████| 139/139 [00:44<00:00,  3.11req/s]\n",
      "PAN | Fold-6 | 5-shot: 100%|██████████| 139/139 [00:45<00:00,  3.06req/s]\n",
      "PAN | Fold-6 | 7-shot: 100%|██████████| 139/139 [00:44<00:00,  3.09req/s]\n",
      "PAN | Fold-7 | 1-shot: 100%|██████████| 139/139 [00:43<00:00,  3.18req/s]\n",
      "PAN | Fold-7 | 3-shot: 100%|██████████| 139/139 [00:44<00:00,  3.15req/s]\n",
      "PAN | Fold-7 | 5-shot: 100%|██████████| 139/139 [00:44<00:00,  3.14req/s]\n",
      "PAN | Fold-7 | 7-shot: 100%|██████████| 139/139 [00:45<00:00,  3.07req/s]\n",
      "PAN | Fold-8 | 1-shot: 100%|██████████| 139/139 [00:45<00:00,  3.08req/s]\n",
      "PAN | Fold-8 | 3-shot: 100%|██████████| 139/139 [00:45<00:00,  3.05req/s]\n",
      "PAN | Fold-8 | 5-shot: 100%|██████████| 139/139 [00:45<00:00,  3.03req/s]\n",
      "PAN | Fold-8 | 7-shot: 100%|██████████| 139/139 [00:46<00:00,  3.00req/s]\n",
      "PAN | Fold-9 | 1-shot: 100%|██████████| 139/139 [00:45<00:00,  3.05req/s]\n",
      "PAN | Fold-9 | 3-shot: 100%|██████████| 139/139 [00:45<00:00,  3.07req/s]\n",
      "PAN | Fold-9 | 5-shot: 100%|██████████| 139/139 [00:45<00:00,  3.06req/s]\n",
      "PAN | Fold-9 | 7-shot: 100%|██████████| 139/139 [00:46<00:00,  3.00req/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Few-shot evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# few_shot_folds_ollama.py\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "DATASET_NAME = \"pan\"\n",
    "OLLAMA_MODEL = \"llama3:70b\"\n",
    "K_VALUES = [1, 3, 5, 7]\n",
    "SEED = 42\n",
    "\n",
    "FOLD_DIR = f\"stratified_splits_80_10_10/{DATASET_NAME}\"\n",
    "MODEL_CLEAN = OLLAMA_MODEL.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "OUT_DIR = f\"few_shot_folds_{MODEL_CLEAN}_{DATASET_NAME}\"\n",
    "PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "os.makedirs(PRED_DIR, exist_ok=True)\n",
    "random.seed(SEED)\n",
    "\n",
    "LABEL_LIST = [\n",
    "    \"Information Giving\",\n",
    "    \"Problem Discovery\",\n",
    "    \"Feature Request\",\n",
    "    \"Information Seeking\",\n",
    "]\n",
    "\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"You are a requirement classification assistant.\\n\"\n",
    "    \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "    \"- Information Giving: factual descriptions, app details, or user opinions.\\n\"\n",
    "    \"- Problem Discovery: issues, bugs, crashes, or errors.\\n\"\n",
    "    \"- Feature Request: suggestions or desired improvements.\\n\"\n",
    "    \"- Information Seeking: questions or asking for help.\\n\\n\"\n",
    "    \"{examples_section}\"\n",
    "    \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "    \"Review: {req_text}\\n\"\n",
    "    \"Label:\"\n",
    ")\n",
    "\n",
    "llm = OllamaLLM(model=OLLAMA_MODEL)\n",
    "\n",
    "# =============== HELPERS ===============\n",
    "def build_examples(df):\n",
    "    return \"\\n\".join(f\"{row.review} , {row['class']}\" for _, row in df.iterrows())\n",
    "\n",
    "def call_llm(prompt: str) -> str:\n",
    "    return llm.invoke(prompt).strip()\n",
    "\n",
    "def extract_label(response: str, labels: list[str]) -> str:\n",
    "    rl = response.lower()\n",
    "    for lab in labels:\n",
    "        if lab.lower() in rl:\n",
    "            return lab\n",
    "    return labels[0]\n",
    "\n",
    "def k_examples_per_class(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    return (\n",
    "        df.assign(len=df.review.str.len())\n",
    "          .sort_values(\"len\")\n",
    "          .groupby(\"class\", group_keys=False)\n",
    "          .head(k)\n",
    "          .drop(columns=\"len\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# =============== MAIN LOOP ===============\n",
    "all_metrics = []\n",
    "summary_rows = []\n",
    "\n",
    "for fold in range(10):\n",
    "    test_path = os.path.join(FOLD_DIR, f\"test_fold_{fold}.csv\")\n",
    "    train_path = os.path.join(FOLD_DIR, f\"train_fold_{fold}.csv\")\n",
    "    test_df = pd.read_csv(test_path).reset_index(drop=True)\n",
    "    train_df = pd.read_csv(train_path).reset_index(drop=True)\n",
    "\n",
    "    labels = sorted(train_df[\"class\"].unique())\n",
    "\n",
    "    for k in K_VALUES:\n",
    "        fewshot_df = k_examples_per_class(train_df, k)\n",
    "        example_block = build_examples(fewshot_df)\n",
    "        examples_section = f\"Here are {k} examples (text , class):\\n{example_block}\\n\\n\"\n",
    "\n",
    "        y_true, preds = [], []\n",
    "\n",
    "        for _, row in tqdm(test_df.iterrows(), total=len(test_df),\n",
    "                           desc=f\"{DATASET_NAME.upper()} | Fold-{fold} | {k}-shot\", unit=\"req\"):\n",
    "\n",
    "            prompt = PROMPT_TEMPLATE.format(\n",
    "                examples_section=examples_section,\n",
    "                req_text=row.review\n",
    "            )\n",
    "\n",
    "            resp = call_llm(prompt)\n",
    "            pred = extract_label(resp, labels)\n",
    "            y_true.append(row[\"class\"])\n",
    "            preds.append(pred)\n",
    "\n",
    "        # ─── METRICS ──────────────────────────────\n",
    "        macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
    "            y_true, preds, labels=labels, average=\"macro\", zero_division=0)\n",
    "        micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(\n",
    "            y_true, preds, labels=labels, average=\"micro\", zero_division=0)\n",
    "        weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(\n",
    "            y_true, preds, labels=labels, average=\"weighted\", zero_division=0)\n",
    "\n",
    "        # ─── SAVE PREDICTIONS ─────────────────────\n",
    "        pd.DataFrame({\n",
    "            \"text\": test_df.review,\n",
    "            \"gold\": y_true,\n",
    "            \"pred\": preds\n",
    "        }).to_csv(\n",
    "            os.path.join(PRED_DIR, f\"{DATASET_NAME}_fold{fold}_{k}shot_preds.csv\"),\n",
    "            index=False, encoding=\"utf-8\"\n",
    "        )\n",
    "\n",
    "        # ─── RECORD METRICS ───────────────────────\n",
    "        summary_rows.append({\n",
    "            \"dataset\": DATASET_NAME,\n",
    "            \"model\": OLLAMA_MODEL,\n",
    "            \"fold\": fold,\n",
    "            \"k_shot\": k,\n",
    "            \"macro_f1\": macro_f1,\n",
    "            \"micro_f1\": micro_f1,\n",
    "            \"weighted_f1\": weighted_f1\n",
    "        })\n",
    "\n",
    "        for i, lab in enumerate(labels):\n",
    "            all_metrics.append({\n",
    "                \"dataset\": DATASET_NAME,\n",
    "                \"model\": OLLAMA_MODEL,\n",
    "                \"fold\": fold,\n",
    "                \"k_shot\": k,\n",
    "                \"class_label\": lab,\n",
    "                \"macro_f1\": macro_f1,\n",
    "                \"micro_f1\": micro_f1,\n",
    "                \"weighted_f1\": weighted_f1,\n",
    "            })\n",
    "\n",
    "# ─── SAVE RESULTS ───────────────────────────────\n",
    "pd.DataFrame(summary_rows).to_csv(\n",
    "    os.path.join(OUT_DIR, \"pan_fewshot_folded_summary.csv\"),\n",
    "    index=False, encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "pd.DataFrame(all_metrics).to_csv(\n",
    "    os.path.join(OUT_DIR, \"pan_fewshot_all_metrics.csv\"),\n",
    "    index=False, encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Few-shot evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "649c30f9-6ace-45db-8d73-8ebbb402ed1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PAN | Fold-0 | 1-shot: 100%|██████████| 139/139 [00:28<00:00,  4.80req/s]\n",
      "PAN | Fold-0 | 3-shot: 100%|██████████| 139/139 [00:26<00:00,  5.27req/s]\n",
      "PAN | Fold-0 | 5-shot: 100%|██████████| 139/139 [00:26<00:00,  5.18req/s]\n",
      "PAN | Fold-0 | 7-shot: 100%|██████████| 139/139 [00:27<00:00,  5.15req/s]\n",
      "PAN | Fold-1 | 1-shot: 100%|██████████| 139/139 [00:26<00:00,  5.29req/s]\n",
      "PAN | Fold-1 | 3-shot: 100%|██████████| 139/139 [00:26<00:00,  5.19req/s]\n",
      "PAN | Fold-1 | 5-shot: 100%|██████████| 139/139 [00:26<00:00,  5.20req/s]\n",
      "PAN | Fold-1 | 7-shot: 100%|██████████| 139/139 [00:27<00:00,  5.13req/s]\n",
      "PAN | Fold-2 | 1-shot: 100%|██████████| 139/139 [00:26<00:00,  5.27req/s]\n",
      "PAN | Fold-2 | 3-shot: 100%|██████████| 139/139 [00:26<00:00,  5.27req/s]\n",
      "PAN | Fold-2 | 5-shot: 100%|██████████| 139/139 [00:26<00:00,  5.26req/s]\n",
      "PAN | Fold-2 | 7-shot: 100%|██████████| 139/139 [00:27<00:00,  5.13req/s]\n",
      "PAN | Fold-3 | 1-shot: 100%|██████████| 139/139 [00:26<00:00,  5.24req/s]\n",
      "PAN | Fold-3 | 3-shot: 100%|██████████| 139/139 [00:26<00:00,  5.16req/s]\n",
      "PAN | Fold-3 | 5-shot: 100%|██████████| 139/139 [00:26<00:00,  5.28req/s]\n",
      "PAN | Fold-3 | 7-shot: 100%|██████████| 139/139 [00:26<00:00,  5.20req/s]\n",
      "PAN | Fold-4 | 1-shot: 100%|██████████| 139/139 [00:26<00:00,  5.20req/s]\n",
      "PAN | Fold-4 | 3-shot: 100%|██████████| 139/139 [00:26<00:00,  5.21req/s]\n",
      "PAN | Fold-4 | 5-shot: 100%|██████████| 139/139 [00:26<00:00,  5.23req/s]\n",
      "PAN | Fold-4 | 7-shot: 100%|██████████| 139/139 [00:27<00:00,  5.15req/s]\n",
      "PAN | Fold-5 | 1-shot: 100%|██████████| 139/139 [00:26<00:00,  5.23req/s]\n",
      "PAN | Fold-5 | 3-shot: 100%|██████████| 139/139 [00:26<00:00,  5.24req/s]\n",
      "PAN | Fold-5 | 5-shot: 100%|██████████| 139/139 [00:26<00:00,  5.17req/s]\n",
      "PAN | Fold-5 | 7-shot: 100%|██████████| 139/139 [00:27<00:00,  5.14req/s]\n",
      "PAN | Fold-6 | 1-shot: 100%|██████████| 139/139 [00:26<00:00,  5.24req/s]\n",
      "PAN | Fold-6 | 3-shot: 100%|██████████| 139/139 [00:26<00:00,  5.23req/s]\n",
      "PAN | Fold-6 | 5-shot: 100%|██████████| 139/139 [00:26<00:00,  5.17req/s]\n",
      "PAN | Fold-6 | 7-shot: 100%|██████████| 139/139 [00:27<00:00,  5.09req/s]\n",
      "PAN | Fold-7 | 1-shot: 100%|██████████| 139/139 [00:26<00:00,  5.17req/s]\n",
      "PAN | Fold-7 | 3-shot: 100%|██████████| 139/139 [00:26<00:00,  5.23req/s]\n",
      "PAN | Fold-7 | 5-shot: 100%|██████████| 139/139 [00:26<00:00,  5.18req/s]\n",
      "PAN | Fold-7 | 7-shot: 100%|██████████| 139/139 [00:26<00:00,  5.19req/s]\n",
      "PAN | Fold-8 | 1-shot: 100%|██████████| 139/139 [00:26<00:00,  5.17req/s]\n",
      "PAN | Fold-8 | 3-shot: 100%|██████████| 139/139 [00:26<00:00,  5.23req/s]\n",
      "PAN | Fold-8 | 5-shot: 100%|██████████| 139/139 [00:26<00:00,  5.19req/s]\n",
      "PAN | Fold-8 | 7-shot: 100%|██████████| 139/139 [00:27<00:00,  5.11req/s]\n",
      "PAN | Fold-9 | 1-shot: 100%|██████████| 139/139 [00:26<00:00,  5.23req/s]\n",
      "PAN | Fold-9 | 3-shot: 100%|██████████| 139/139 [00:26<00:00,  5.29req/s]\n",
      "PAN | Fold-9 | 5-shot: 100%|██████████| 139/139 [00:27<00:00,  5.10req/s]\n",
      "PAN | Fold-9 | 7-shot: 100%|██████████| 139/139 [00:27<00:00,  5.12req/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Few-shot evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "# few_shot_folds_ollama.py\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "DATASET_NAME = \"pan\"\n",
    "OLLAMA_MODEL = \"llama3:8b\"\n",
    "K_VALUES = [1, 3, 5, 7]\n",
    "SEED = 42\n",
    "\n",
    "FOLD_DIR = f\"stratified_splits_80_10_10/{DATASET_NAME}\"\n",
    "MODEL_CLEAN = OLLAMA_MODEL.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "OUT_DIR = f\"few_shot_folds_{MODEL_CLEAN}_{DATASET_NAME}\"\n",
    "PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "os.makedirs(PRED_DIR, exist_ok=True)\n",
    "random.seed(SEED)\n",
    "\n",
    "LABEL_LIST = [\n",
    "    \"Information Giving\",\n",
    "    \"Problem Discovery\",\n",
    "    \"Feature Request\",\n",
    "    \"Information Seeking\",\n",
    "]\n",
    "\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"You are a requirement classification assistant.\\n\"\n",
    "    \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "    \"- Information Giving: factual descriptions, app details, or user opinions.\\n\"\n",
    "    \"- Problem Discovery: issues, bugs, crashes, or errors.\\n\"\n",
    "    \"- Feature Request: suggestions or desired improvements.\\n\"\n",
    "    \"- Information Seeking: questions or asking for help.\\n\\n\"\n",
    "    \"{examples_section}\"\n",
    "    \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "    \"Review: {req_text}\\n\"\n",
    "    \"Label:\"\n",
    ")\n",
    "\n",
    "llm = OllamaLLM(model=OLLAMA_MODEL)\n",
    "\n",
    "# =============== HELPERS ===============\n",
    "def build_examples(df):\n",
    "    return \"\\n\".join(f\"{row.review} , {row['class']}\" for _, row in df.iterrows())\n",
    "\n",
    "def call_llm(prompt: str) -> str:\n",
    "    return llm.invoke(prompt).strip()\n",
    "\n",
    "def extract_label(response: str, labels: list[str]) -> str:\n",
    "    rl = response.lower()\n",
    "    for lab in labels:\n",
    "        if lab.lower() in rl:\n",
    "            return lab\n",
    "    return labels[0]\n",
    "\n",
    "def k_examples_per_class(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    return (\n",
    "        df.assign(len=df.review.str.len())\n",
    "          .sort_values(\"len\")\n",
    "          .groupby(\"class\", group_keys=False)\n",
    "          .head(k)\n",
    "          .drop(columns=\"len\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# =============== MAIN LOOP ===============\n",
    "all_metrics = []\n",
    "summary_rows = []\n",
    "\n",
    "for fold in range(10):\n",
    "    test_path = os.path.join(FOLD_DIR, f\"test_fold_{fold}.csv\")\n",
    "    train_path = os.path.join(FOLD_DIR, f\"train_fold_{fold}.csv\")\n",
    "    test_df = pd.read_csv(test_path).reset_index(drop=True)\n",
    "    train_df = pd.read_csv(train_path).reset_index(drop=True)\n",
    "\n",
    "    labels = sorted(train_df[\"class\"].unique())\n",
    "\n",
    "    for k in K_VALUES:\n",
    "        fewshot_df = k_examples_per_class(train_df, k)\n",
    "        example_block = build_examples(fewshot_df)\n",
    "        examples_section = f\"Here are {k} examples (text , class):\\n{example_block}\\n\\n\"\n",
    "\n",
    "        y_true, preds = [], []\n",
    "\n",
    "        for _, row in tqdm(test_df.iterrows(), total=len(test_df),\n",
    "                           desc=f\"{DATASET_NAME.upper()} | Fold-{fold} | {k}-shot\", unit=\"req\"):\n",
    "\n",
    "            prompt = PROMPT_TEMPLATE.format(\n",
    "                examples_section=examples_section,\n",
    "                req_text=row.review\n",
    "            )\n",
    "\n",
    "            resp = call_llm(prompt)\n",
    "            pred = extract_label(resp, labels)\n",
    "            y_true.append(row[\"class\"])\n",
    "            preds.append(pred)\n",
    "\n",
    "        # ─── METRICS ──────────────────────────────\n",
    "        macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
    "            y_true, preds, labels=labels, average=\"macro\", zero_division=0)\n",
    "        micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(\n",
    "            y_true, preds, labels=labels, average=\"micro\", zero_division=0)\n",
    "        weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(\n",
    "            y_true, preds, labels=labels, average=\"weighted\", zero_division=0)\n",
    "\n",
    "        # ─── SAVE PREDICTIONS ─────────────────────\n",
    "        pd.DataFrame({\n",
    "            \"text\": test_df.review,\n",
    "            \"gold\": y_true,\n",
    "            \"pred\": preds\n",
    "        }).to_csv(\n",
    "            os.path.join(PRED_DIR, f\"{DATASET_NAME}_fold{fold}_{k}shot_preds.csv\"),\n",
    "            index=False, encoding=\"utf-8\"\n",
    "        )\n",
    "\n",
    "        # ─── RECORD METRICS ───────────────────────\n",
    "        summary_rows.append({\n",
    "            \"dataset\": DATASET_NAME,\n",
    "            \"model\": OLLAMA_MODEL,\n",
    "            \"fold\": fold,\n",
    "            \"k_shot\": k,\n",
    "            \"macro_f1\": macro_f1,\n",
    "            \"micro_f1\": micro_f1,\n",
    "            \"weighted_f1\": weighted_f1\n",
    "        })\n",
    "\n",
    "        for i, lab in enumerate(labels):\n",
    "            all_metrics.append({\n",
    "                \"dataset\": DATASET_NAME,\n",
    "                \"model\": OLLAMA_MODEL,\n",
    "                \"fold\": fold,\n",
    "                \"k_shot\": k,\n",
    "                \"class_label\": lab,\n",
    "                \"macro_f1\": macro_f1,\n",
    "                \"micro_f1\": micro_f1,\n",
    "                \"weighted_f1\": weighted_f1,\n",
    "            })\n",
    "\n",
    "# ─── SAVE RESULTS ───────────────────────────────\n",
    "pd.DataFrame(summary_rows).to_csv(\n",
    "    os.path.join(OUT_DIR, \"pan_fewshot_folded_summary.csv\"),\n",
    "    index=False, encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "pd.DataFrame(all_metrics).to_csv(\n",
    "    os.path.join(OUT_DIR, \"pan_fewshot_all_metrics.csv\"),\n",
    "    index=False, encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Few-shot evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4621760-fa66-4f99-b568-9326e580b1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PAN | Fold-0 | 1-shot: 100%|██████████| 139/139 [00:14<00:00,  9.64req/s]\n",
      "PAN | Fold-0 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.40req/s]\n",
      "PAN | Fold-0 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 11.04req/s]\n",
      "PAN | Fold-0 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 10.86req/s]\n",
      "PAN | Fold-1 | 1-shot: 100%|██████████| 139/139 [00:12<00:00, 11.34req/s]\n",
      "PAN | Fold-1 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.38req/s]\n",
      "PAN | Fold-1 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 10.96req/s]\n",
      "PAN | Fold-1 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 10.72req/s]\n",
      "PAN | Fold-2 | 1-shot: 100%|██████████| 139/139 [00:11<00:00, 11.61req/s]\n",
      "PAN | Fold-2 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.13req/s]\n",
      "PAN | Fold-2 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 11.19req/s]\n",
      "PAN | Fold-2 | 7-shot: 100%|██████████| 139/139 [00:13<00:00, 10.64req/s]\n",
      "PAN | Fold-3 | 1-shot: 100%|██████████| 139/139 [00:12<00:00, 11.46req/s]\n",
      "PAN | Fold-3 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.43req/s]\n",
      "PAN | Fold-3 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 11.14req/s]\n",
      "PAN | Fold-3 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 11.01req/s]\n",
      "PAN | Fold-4 | 1-shot: 100%|██████████| 139/139 [00:12<00:00, 11.56req/s]\n",
      "PAN | Fold-4 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.29req/s]\n",
      "PAN | Fold-4 | 5-shot: 100%|██████████| 139/139 [00:13<00:00, 10.54req/s]\n",
      "PAN | Fold-4 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 10.91req/s]\n",
      "PAN | Fold-5 | 1-shot: 100%|██████████| 139/139 [00:12<00:00, 11.42req/s]\n",
      "PAN | Fold-5 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.45req/s]\n",
      "PAN | Fold-5 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 11.33req/s]\n",
      "PAN | Fold-5 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 11.01req/s]\n",
      "PAN | Fold-6 | 1-shot: 100%|██████████| 139/139 [00:12<00:00, 11.52req/s]\n",
      "PAN | Fold-6 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.27req/s]\n",
      "PAN | Fold-6 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 11.29req/s]\n",
      "PAN | Fold-6 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 11.01req/s]\n",
      "PAN | Fold-7 | 1-shot: 100%|██████████| 139/139 [00:12<00:00, 11.47req/s]\n",
      "PAN | Fold-7 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.58req/s]\n",
      "PAN | Fold-7 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 11.28req/s]\n",
      "PAN | Fold-7 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 11.08req/s]\n",
      "PAN | Fold-8 | 1-shot: 100%|██████████| 139/139 [00:12<00:00, 11.36req/s]\n",
      "PAN | Fold-8 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.36req/s]\n",
      "PAN | Fold-8 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 11.20req/s]\n",
      "PAN | Fold-8 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 10.98req/s]\n",
      "PAN | Fold-9 | 1-shot: 100%|██████████| 139/139 [00:11<00:00, 11.68req/s]\n",
      "PAN | Fold-9 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.54req/s]\n",
      "PAN | Fold-9 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 11.21req/s]\n",
      "PAN | Fold-9 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 10.87req/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Few-shot evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# few_shot_folds_ollama.py\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "DATASET_NAME = \"pan\"\n",
    "OLLAMA_MODEL = \"mistral:7b\"\n",
    "K_VALUES = [1, 3, 5, 7]\n",
    "SEED = 42\n",
    "\n",
    "FOLD_DIR = f\"stratified_splits_80_10_10/{DATASET_NAME}\"\n",
    "MODEL_CLEAN = OLLAMA_MODEL.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "OUT_DIR = f\"few_shot_folds_{MODEL_CLEAN}_{DATASET_NAME}\"\n",
    "PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "os.makedirs(PRED_DIR, exist_ok=True)\n",
    "random.seed(SEED)\n",
    "\n",
    "LABEL_LIST = [\n",
    "    \"Information Giving\",\n",
    "    \"Problem Discovery\",\n",
    "    \"Feature Request\",\n",
    "    \"Information Seeking\",\n",
    "]\n",
    "\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"You are a requirement classification assistant.\\n\"\n",
    "    \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "    \"- Information Giving: factual descriptions, app details, or user opinions.\\n\"\n",
    "    \"- Problem Discovery: issues, bugs, crashes, or errors.\\n\"\n",
    "    \"- Feature Request: suggestions or desired improvements.\\n\"\n",
    "    \"- Information Seeking: questions or asking for help.\\n\\n\"\n",
    "    \"{examples_section}\"\n",
    "    \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "    \"Review: {req_text}\\n\"\n",
    "    \"Label:\"\n",
    ")\n",
    "\n",
    "llm = OllamaLLM(model=OLLAMA_MODEL)\n",
    "\n",
    "# =============== HELPERS ===============\n",
    "def build_examples(df):\n",
    "    return \"\\n\".join(f\"{row.review} , {row['class']}\" for _, row in df.iterrows())\n",
    "\n",
    "def call_llm(prompt: str) -> str:\n",
    "    return llm.invoke(prompt).strip()\n",
    "\n",
    "def extract_label(response: str, labels: list[str]) -> str:\n",
    "    rl = response.lower()\n",
    "    for lab in labels:\n",
    "        if lab.lower() in rl:\n",
    "            return lab\n",
    "    return labels[0]\n",
    "\n",
    "def k_examples_per_class(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    return (\n",
    "        df.assign(len=df.review.str.len())\n",
    "          .sort_values(\"len\")\n",
    "          .groupby(\"class\", group_keys=False)\n",
    "          .head(k)\n",
    "          .drop(columns=\"len\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# =============== MAIN LOOP ===============\n",
    "all_metrics = []\n",
    "summary_rows = []\n",
    "\n",
    "for fold in range(10):\n",
    "    test_path = os.path.join(FOLD_DIR, f\"test_fold_{fold}.csv\")\n",
    "    train_path = os.path.join(FOLD_DIR, f\"train_fold_{fold}.csv\")\n",
    "    test_df = pd.read_csv(test_path).reset_index(drop=True)\n",
    "    train_df = pd.read_csv(train_path).reset_index(drop=True)\n",
    "\n",
    "    labels = sorted(train_df[\"class\"].unique())\n",
    "\n",
    "    for k in K_VALUES:\n",
    "        fewshot_df = k_examples_per_class(train_df, k)\n",
    "        example_block = build_examples(fewshot_df)\n",
    "        examples_section = f\"Here are {k} examples (text , class):\\n{example_block}\\n\\n\"\n",
    "\n",
    "        y_true, preds = [], []\n",
    "\n",
    "        for _, row in tqdm(test_df.iterrows(), total=len(test_df),\n",
    "                           desc=f\"{DATASET_NAME.upper()} | Fold-{fold} | {k}-shot\", unit=\"req\"):\n",
    "\n",
    "            prompt = PROMPT_TEMPLATE.format(\n",
    "                examples_section=examples_section,\n",
    "                req_text=row.review\n",
    "            )\n",
    "\n",
    "            resp = call_llm(prompt)\n",
    "            pred = extract_label(resp, labels)\n",
    "            y_true.append(row[\"class\"])\n",
    "            preds.append(pred)\n",
    "\n",
    "        # ─── METRICS ──────────────────────────────\n",
    "        macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
    "            y_true, preds, labels=labels, average=\"macro\", zero_division=0)\n",
    "        micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(\n",
    "            y_true, preds, labels=labels, average=\"micro\", zero_division=0)\n",
    "        weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(\n",
    "            y_true, preds, labels=labels, average=\"weighted\", zero_division=0)\n",
    "\n",
    "        # ─── SAVE PREDICTIONS ─────────────────────\n",
    "        pd.DataFrame({\n",
    "            \"text\": test_df.review,\n",
    "            \"gold\": y_true,\n",
    "            \"pred\": preds\n",
    "        }).to_csv(\n",
    "            os.path.join(PRED_DIR, f\"{DATASET_NAME}_fold{fold}_{k}shot_preds.csv\"),\n",
    "            index=False, encoding=\"utf-8\"\n",
    "        )\n",
    "\n",
    "        # ─── RECORD METRICS ───────────────────────\n",
    "        summary_rows.append({\n",
    "            \"dataset\": DATASET_NAME,\n",
    "            \"model\": OLLAMA_MODEL,\n",
    "            \"fold\": fold,\n",
    "            \"k_shot\": k,\n",
    "            \"macro_f1\": macro_f1,\n",
    "            \"micro_f1\": micro_f1,\n",
    "            \"weighted_f1\": weighted_f1\n",
    "        })\n",
    "\n",
    "        for i, lab in enumerate(labels):\n",
    "            all_metrics.append({\n",
    "                \"dataset\": DATASET_NAME,\n",
    "                \"model\": OLLAMA_MODEL,\n",
    "                \"fold\": fold,\n",
    "                \"k_shot\": k,\n",
    "                \"class_label\": lab,\n",
    "                \"macro_f1\": macro_f1,\n",
    "                \"micro_f1\": micro_f1,\n",
    "                \"weighted_f1\": weighted_f1,\n",
    "            })\n",
    "\n",
    "# ─── SAVE RESULTS ───────────────────────────────\n",
    "pd.DataFrame(summary_rows).to_csv(\n",
    "    os.path.join(OUT_DIR, \"pan_fewshot_folded_summary.csv\"),\n",
    "    index=False, encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "pd.DataFrame(all_metrics).to_csv(\n",
    "    os.path.join(OUT_DIR, \"pan_fewshot_all_metrics.csv\"),\n",
    "    index=False, encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Few-shot evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f67e93c4-bc98-44a1-a44a-2f51c56a2e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gemma3:4b | Fold-0 | 1-shot: 100%|██████████| 139/139 [00:38<00:00,  3.60req/s]\n",
      "gemma3:4b | Fold-0 | 3-shot: 100%|██████████| 139/139 [00:34<00:00,  4.00req/s]\n",
      "gemma3:4b | Fold-0 | 5-shot: 100%|██████████| 139/139 [00:34<00:00,  4.03req/s]\n",
      "gemma3:4b | Fold-0 | 7-shot: 100%|██████████| 139/139 [00:35<00:00,  3.95req/s]\n",
      "gemma3:4b | Fold-1 | 1-shot: 100%|██████████| 139/139 [00:34<00:00,  4.00req/s]\n",
      "gemma3:4b | Fold-1 | 3-shot: 100%|██████████| 139/139 [00:33<00:00,  4.10req/s]\n",
      "gemma3:4b | Fold-1 | 5-shot: 100%|██████████| 139/139 [00:36<00:00,  3.86req/s]\n",
      "gemma3:4b | Fold-1 | 7-shot: 100%|██████████| 139/139 [00:35<00:00,  3.91req/s]\n",
      "gemma3:4b | Fold-2 | 1-shot: 100%|██████████| 139/139 [00:35<00:00,  3.96req/s]\n",
      "gemma3:4b | Fold-2 | 3-shot: 100%|██████████| 139/139 [00:34<00:00,  4.04req/s]\n",
      "gemma3:4b | Fold-2 | 5-shot: 100%|██████████| 139/139 [00:35<00:00,  3.94req/s]\n",
      "gemma3:4b | Fold-2 | 7-shot: 100%|██████████| 139/139 [00:34<00:00,  4.03req/s]\n",
      "gemma3:4b | Fold-3 | 1-shot: 100%|██████████| 139/139 [00:33<00:00,  4.11req/s]\n",
      "gemma3:4b | Fold-3 | 3-shot: 100%|██████████| 139/139 [00:34<00:00,  4.00req/s]\n",
      "gemma3:4b | Fold-3 | 5-shot: 100%|██████████| 139/139 [00:34<00:00,  4.04req/s]\n",
      "gemma3:4b | Fold-3 | 7-shot: 100%|██████████| 139/139 [00:35<00:00,  3.88req/s]\n",
      "gemma3:4b | Fold-4 | 1-shot: 100%|██████████| 139/139 [00:34<00:00,  3.97req/s]\n",
      "gemma3:4b | Fold-4 | 3-shot: 100%|██████████| 139/139 [00:35<00:00,  3.96req/s]\n",
      "gemma3:4b | Fold-4 | 5-shot: 100%|██████████| 139/139 [00:35<00:00,  3.97req/s]\n",
      "gemma3:4b | Fold-4 | 7-shot: 100%|██████████| 139/139 [00:34<00:00,  4.01req/s]\n",
      "gemma3:4b | Fold-5 | 1-shot: 100%|██████████| 139/139 [00:34<00:00,  4.05req/s]\n",
      "gemma3:4b | Fold-5 | 3-shot: 100%|██████████| 139/139 [00:34<00:00,  4.01req/s]\n",
      "gemma3:4b | Fold-5 | 5-shot: 100%|██████████| 139/139 [00:35<00:00,  3.96req/s]\n",
      "gemma3:4b | Fold-5 | 7-shot: 100%|██████████| 139/139 [00:34<00:00,  3.99req/s]\n",
      "gemma3:4b | Fold-6 | 1-shot: 100%|██████████| 139/139 [00:34<00:00,  4.04req/s]\n",
      "gemma3:4b | Fold-6 | 3-shot: 100%|██████████| 139/139 [00:33<00:00,  4.11req/s]\n",
      "gemma3:4b | Fold-6 | 5-shot: 100%|██████████| 139/139 [00:34<00:00,  4.01req/s]\n",
      "gemma3:4b | Fold-6 | 7-shot: 100%|██████████| 139/139 [00:34<00:00,  4.06req/s]\n",
      "gemma3:4b | Fold-7 | 1-shot: 100%|██████████| 139/139 [00:34<00:00,  3.97req/s]\n",
      "gemma3:4b | Fold-7 | 3-shot: 100%|██████████| 139/139 [00:34<00:00,  3.99req/s]\n",
      "gemma3:4b | Fold-7 | 5-shot: 100%|██████████| 139/139 [00:34<00:00,  4.02req/s]\n",
      "gemma3:4b | Fold-7 | 7-shot: 100%|██████████| 139/139 [00:34<00:00,  4.03req/s]\n",
      "gemma3:4b | Fold-8 | 1-shot: 100%|██████████| 139/139 [00:34<00:00,  3.99req/s]\n",
      "gemma3:4b | Fold-8 | 3-shot: 100%|██████████| 139/139 [00:34<00:00,  3.97req/s]\n",
      "gemma3:4b | Fold-8 | 5-shot: 100%|██████████| 139/139 [00:34<00:00,  4.04req/s]\n",
      "gemma3:4b | Fold-8 | 7-shot: 100%|██████████| 139/139 [00:34<00:00,  4.03req/s]\n",
      "gemma3:4b | Fold-9 | 1-shot: 100%|██████████| 139/139 [00:34<00:00,  4.02req/s]\n",
      "gemma3:4b | Fold-9 | 3-shot: 100%|██████████| 139/139 [00:34<00:00,  4.03req/s]\n",
      "gemma3:4b | Fold-9 | 5-shot: 100%|██████████| 139/139 [00:34<00:00,  3.98req/s]\n",
      "gemma3:4b | Fold-9 | 7-shot: 100%|██████████| 139/139 [00:34<00:00,  3.99req/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ gemma3:4b few-shot evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wizardlm2:7b | Fold-0 | 1-shot: 100%|██████████| 139/139 [00:13<00:00, 10.06req/s]\n",
      "wizardlm2:7b | Fold-0 | 3-shot: 100%|██████████| 139/139 [00:11<00:00, 11.68req/s]\n",
      "wizardlm2:7b | Fold-0 | 5-shot: 100%|██████████| 139/139 [00:11<00:00, 11.61req/s]\n",
      "wizardlm2:7b | Fold-0 | 7-shot: 100%|██████████| 139/139 [00:11<00:00, 11.65req/s]\n",
      "wizardlm2:7b | Fold-1 | 1-shot: 100%|██████████| 139/139 [00:11<00:00, 12.42req/s]\n",
      "wizardlm2:7b | Fold-1 | 3-shot: 100%|██████████| 139/139 [00:11<00:00, 11.97req/s]\n",
      "wizardlm2:7b | Fold-1 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 11.23req/s]\n",
      "wizardlm2:7b | Fold-1 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 11.11req/s]\n",
      "wizardlm2:7b | Fold-2 | 1-shot: 100%|██████████| 139/139 [00:11<00:00, 12.19req/s]\n",
      "wizardlm2:7b | Fold-2 | 3-shot: 100%|██████████| 139/139 [00:11<00:00, 11.63req/s]\n",
      "wizardlm2:7b | Fold-2 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 11.25req/s]\n",
      "wizardlm2:7b | Fold-2 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 11.38req/s]\n",
      "wizardlm2:7b | Fold-3 | 1-shot: 100%|██████████| 139/139 [00:11<00:00, 12.41req/s]\n",
      "wizardlm2:7b | Fold-3 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.50req/s]\n",
      "wizardlm2:7b | Fold-3 | 5-shot: 100%|██████████| 139/139 [00:11<00:00, 11.91req/s]\n",
      "wizardlm2:7b | Fold-3 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 11.30req/s]\n",
      "wizardlm2:7b | Fold-4 | 1-shot: 100%|██████████| 139/139 [00:11<00:00, 12.14req/s]\n",
      "wizardlm2:7b | Fold-4 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.16req/s]\n",
      "wizardlm2:7b | Fold-4 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 11.15req/s]\n",
      "wizardlm2:7b | Fold-4 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 11.26req/s]\n",
      "wizardlm2:7b | Fold-5 | 1-shot: 100%|██████████| 139/139 [00:11<00:00, 12.59req/s]\n",
      "wizardlm2:7b | Fold-5 | 3-shot: 100%|██████████| 139/139 [00:11<00:00, 11.64req/s]\n",
      "wizardlm2:7b | Fold-5 | 5-shot: 100%|██████████| 139/139 [00:11<00:00, 11.76req/s]\n",
      "wizardlm2:7b | Fold-5 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 11.56req/s]\n",
      "wizardlm2:7b | Fold-6 | 1-shot: 100%|██████████| 139/139 [00:12<00:00, 11.17req/s]\n",
      "wizardlm2:7b | Fold-6 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.23req/s]\n",
      "wizardlm2:7b | Fold-6 | 5-shot: 100%|██████████| 139/139 [00:13<00:00, 10.69req/s]\n",
      "wizardlm2:7b | Fold-6 | 7-shot: 100%|██████████| 139/139 [00:13<00:00, 10.29req/s]\n",
      "wizardlm2:7b | Fold-7 | 1-shot: 100%|██████████| 139/139 [00:11<00:00, 11.98req/s]\n",
      "wizardlm2:7b | Fold-7 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.56req/s]\n",
      "wizardlm2:7b | Fold-7 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 11.08req/s]\n",
      "wizardlm2:7b | Fold-7 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 10.76req/s]\n",
      "wizardlm2:7b | Fold-8 | 1-shot: 100%|██████████| 139/139 [00:11<00:00, 12.07req/s]\n",
      "wizardlm2:7b | Fold-8 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 11.49req/s]\n",
      "wizardlm2:7b | Fold-8 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 11.28req/s]\n",
      "wizardlm2:7b | Fold-8 | 7-shot: 100%|██████████| 139/139 [00:12<00:00, 11.22req/s]\n",
      "wizardlm2:7b | Fold-9 | 1-shot: 100%|██████████| 139/139 [00:11<00:00, 11.92req/s]\n",
      "wizardlm2:7b | Fold-9 | 3-shot: 100%|██████████| 139/139 [00:12<00:00, 10.96req/s]\n",
      "wizardlm2:7b | Fold-9 | 5-shot: 100%|██████████| 139/139 [00:12<00:00, 10.93req/s]\n",
      "wizardlm2:7b | Fold-9 | 7-shot: 100%|██████████| 139/139 [00:13<00:00, 10.43req/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ wizardlm2:7b few-shot evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run_few_shot_all_models.py\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "DATASET_NAME = \"pan\"\n",
    "FOLD_DIR = f\"stratified_splits_80_10_10/{DATASET_NAME}\"\n",
    "K_VALUES = [1, 3, 5, 7]\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "LABEL_LIST = [\n",
    "    \"Information Giving\",\n",
    "    \"Problem Discovery\",\n",
    "    \"Feature Request\",\n",
    "    \"Information Seeking\",\n",
    "]\n",
    "\n",
    "OLLAMA_MODELS = [\n",
    "  \n",
    "    \"gemma3:4b\",\n",
    "    \"wizardlm2:7b\"\n",
    "]\n",
    "\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"You are a requirement classification assistant.\\n\"\n",
    "    \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "    \"- Information Giving: factual descriptions, app details, or user opinions.\\n\"\n",
    "    \"- Problem Discovery: issues, bugs, crashes, or errors.\\n\"\n",
    "    \"- Feature Request: suggestions or desired improvements.\\n\"\n",
    "    \"- Information Seeking: questions or asking for help.\\n\\n\"\n",
    "    \"{examples_section}\"\n",
    "    \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "    \"Review: {req_text}\\n\"\n",
    "    \"Label:\"\n",
    ")\n",
    "\n",
    "# =============== HELPERS ===============\n",
    "def build_examples(df):\n",
    "    return \"\\n\".join(f\"{row.review} , {row['class']}\" for _, row in df.iterrows())\n",
    "\n",
    "def call_llm(llm, prompt: str) -> str:\n",
    "    return llm.invoke(prompt).strip()\n",
    "\n",
    "def extract_label(response: str, labels: list[str]) -> str:\n",
    "    rl = response.lower()\n",
    "    for lab in labels:\n",
    "        if lab.lower() in rl:\n",
    "            return lab\n",
    "    return labels[0]\n",
    "\n",
    "def k_examples_per_class(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    return (\n",
    "        df.assign(len=df.review.str.len())\n",
    "          .sort_values(\"len\")\n",
    "          .groupby(\"class\", group_keys=False)\n",
    "          .head(k)\n",
    "          .drop(columns=\"len\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# =============== MAIN ===============\n",
    "for model_name in OLLAMA_MODELS:\n",
    "    MODEL_CLEAN = model_name.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "    OUT_DIR = f\"few_shot_folds_{MODEL_CLEAN}_{DATASET_NAME}\"\n",
    "    PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "    os.makedirs(PRED_DIR, exist_ok=True)\n",
    "\n",
    "    llm = OllamaLLM(model=model_name)\n",
    "\n",
    "    all_metrics = []\n",
    "    summary_rows = []\n",
    "\n",
    "    for fold in range(10):\n",
    "        test_path = os.path.join(FOLD_DIR, f\"test_fold_{fold}.csv\")\n",
    "        train_path = os.path.join(FOLD_DIR, f\"train_fold_{fold}.csv\")\n",
    "        test_df = pd.read_csv(test_path).reset_index(drop=True)\n",
    "        train_df = pd.read_csv(train_path).reset_index(drop=True)\n",
    "\n",
    "        labels = sorted(train_df[\"class\"].unique())\n",
    "\n",
    "        for k in K_VALUES:\n",
    "            fewshot_df = k_examples_per_class(train_df, k)\n",
    "            example_block = build_examples(fewshot_df)\n",
    "            examples_section = f\"Here are {k} examples (text , class):\\n{example_block}\\n\\n\"\n",
    "\n",
    "            y_true, preds = [], []\n",
    "\n",
    "            for _, row in tqdm(test_df.iterrows(), total=len(test_df),\n",
    "                               desc=f\"{model_name} | Fold-{fold} | {k}-shot\", unit=\"req\"):\n",
    "\n",
    "                prompt = PROMPT_TEMPLATE.format(\n",
    "                    examples_section=examples_section,\n",
    "                    req_text=row.review\n",
    "                )\n",
    "\n",
    "                resp = call_llm(llm, prompt)\n",
    "                pred = extract_label(resp, labels)\n",
    "                y_true.append(row[\"class\"])\n",
    "                preds.append(pred)\n",
    "\n",
    "            # ─── METRICS ──────────────────────────────\n",
    "            macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"macro\", zero_division=0)\n",
    "            micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"micro\", zero_division=0)\n",
    "            weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"weighted\", zero_division=0)\n",
    "\n",
    "            # ─── SAVE PREDICTIONS ─────────────────────\n",
    "            pd.DataFrame({\n",
    "                \"text\": test_df.review,\n",
    "                \"gold\": y_true,\n",
    "                \"pred\": preds\n",
    "            }).to_csv(\n",
    "                os.path.join(PRED_DIR, f\"{DATASET_NAME}_fold{fold}_{k}shot_preds.csv\"),\n",
    "                index=False, encoding=\"utf-8\"\n",
    "            )\n",
    "\n",
    "            # ─── RECORD METRICS ───────────────────────\n",
    "            summary_rows.append({\n",
    "                \"dataset\": DATASET_NAME,\n",
    "                \"model\": model_name,\n",
    "                \"fold\": fold,\n",
    "                \"k_shot\": k,\n",
    "                \"macro_f1\": macro_f1,\n",
    "                \"micro_f1\": micro_f1,\n",
    "                \"weighted_f1\": weighted_f1\n",
    "            })\n",
    "\n",
    "            for i, lab in enumerate(labels):\n",
    "                all_metrics.append({\n",
    "                    \"dataset\": DATASET_NAME,\n",
    "                    \"model\": model_name,\n",
    "                    \"fold\": fold,\n",
    "                    \"k_shot\": k,\n",
    "                    \"class_label\": lab,\n",
    "                    \"macro_f1\": macro_f1,\n",
    "                    \"micro_f1\": micro_f1,\n",
    "                    \"weighted_f1\": weighted_f1,\n",
    "                })\n",
    "\n",
    "    # ─── SAVE RESULTS ───────────────────────────────\n",
    "    pd.DataFrame(summary_rows).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{DATASET_NAME}_fewshot_folded_summary.csv\"),\n",
    "        index=False, encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    pd.DataFrame(all_metrics).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{DATASET_NAME}_fewshot_all_metrics.csv\"),\n",
    "        index=False, encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✅ {model_name} few-shot evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc36fdc6-5a0c-4687-8c0f-3075b2b40f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama3:70b | Fold-0 | 1-shot: 100%|██████████| 370/370 [01:59<00:00,  3.11req/s]\n",
      "llama3:70b | Fold-0 | 3-shot:   5%|▍         | 17/370 [00:05<02:01,  2.91req/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 106\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m tqdm(test_df\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_df),\n\u001b[1;32m     99\u001b[0m                    desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Fold-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-shot\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreq\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    101\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m PROMPT_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    102\u001b[0m         examples_section\u001b[38;5;241m=\u001b[39mexamples_section,\n\u001b[1;32m    103\u001b[0m         req_text\u001b[38;5;241m=\u001b[39mrow\u001b[38;5;241m.\u001b[39mreview\n\u001b[1;32m    104\u001b[0m     )\n\u001b[0;32m--> 106\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mcall_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     pred \u001b[38;5;241m=\u001b[39m extract_label(resp, labels)\n\u001b[1;32m    108\u001b[0m     y_true\u001b[38;5;241m.\u001b[39mappend(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[9], line 52\u001b[0m, in \u001b[0;36mcall_llm\u001b[0;34m(llm, prompt)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_llm\u001b[39m(llm, prompt: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_core/language_models/llms.py:389\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    386\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    387\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    401\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_core/language_models/llms.py:766\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    764\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    765\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_core/language_models/llms.py:971\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    958\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    959\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    969\u001b[0m         )\n\u001b[1;32m    970\u001b[0m     ]\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    979\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    980\u001b[0m         callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    981\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[1;32m    989\u001b[0m     ]\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_core/language_models/llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    783\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 792\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    796\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    800\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    803\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_ollama/llms.py:362\u001b[0m, in \u001b[0;36mOllamaLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m--> 362\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_ollama/llms.py:321\u001b[0m, in \u001b[0;36mOllamaLLM._stream_with_aggregation\u001b[0;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    320\u001b[0m thinking_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_generate_stream(prompt, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream_resp, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthinking\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_ollama/llms.py:265\u001b[0m, in \u001b[0;36mOllamaLLM._create_generate_stream\u001b[0;34m(self, prompt, stop, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_generate_stream\u001b[39m(\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    261\u001b[0m     stop: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    263\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client:\n\u001b[0;32m--> 265\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_params(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    267\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/ollama/_client.py:165\u001b[0m, in \u001b[0;36mClient._request.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m():\n\u001b[0;32m--> 165\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mstream(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m       r\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpx/_client.py:868\u001b[0m, in \u001b[0;36mClient.stream\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;124;03mAlternative to `httpx.request()` that streams the response body\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;124;03minstead of loading it into memory at once.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;124;03m[0]: /quickstart#streaming-responses\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    855\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    856\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    857\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    866\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    867\u001b[0m )\n\u001b[0;32m--> 868\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run_few_shot_all_models.py\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "DATASET_NAME = \"maalej\"\n",
    "FOLD_DIR = f\"stratified_splits_80_10_10/{DATASET_NAME}\"\n",
    "K_VALUES = [1, 3, 5, 7]\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "LABEL_LIST = [\n",
    "    \"feature request\",\n",
    "    \"rating\",\n",
    "    \"user experience\",\n",
    "    \"problem discovery\",\n",
    "]\n",
    "\n",
    "OLLAMA_MODELS = [\n",
    "    \"llama3:70b\",\n",
    "    \"llama3:8b\"\n",
    "]\n",
    "\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"You are a requirement classification assistant.\\n\"\n",
    "    \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "    \"- Feature Request: suggestions or desires for new features, functionality, or improvements. \"\n",
    "    \"Often uses words like 'add', 'should have', 'need', 'wish', 'please include'.\\n\"\n",
    "    \"- Rating: numeric scores (e.g. 5 stars) or general feedback like 'great app' or 'bad service' without \"\n",
    "    \"any specific details.\\n\"\n",
    "    \"- User Experience: opinions about usability, speed, UI, navigation, or general interaction quality. \"\n",
    "    \"Might mention design, slow loading, or ease of use.\\n\"\n",
    "    \"- Problem Discovery: reports of bugs, crashes, errors, or issues. Often contains words like \"\n",
    "    \"'doesn't work', 'crash', 'bug', 'problem', 'error'.\\n\\n\"\n",
    "    \"{examples_section}\"\n",
    "    \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "    \"Review: {req_text}\\n\"\n",
    "    \"Label:\"\n",
    "\n",
    ")\n",
    "\n",
    "# =============== HELPERS ===============\n",
    "def build_examples(df):\n",
    "    return \"\\n\".join(f\"{row.review} , {row['class']}\" for _, row in df.iterrows())\n",
    "\n",
    "def call_llm(llm, prompt: str) -> str:\n",
    "    return llm.invoke(prompt).strip()\n",
    "\n",
    "def extract_label(response: str, labels: list[str]) -> str:\n",
    "    rl = response.lower()\n",
    "    for lab in labels:\n",
    "        if lab.lower() in rl:\n",
    "            return lab\n",
    "    return labels[0]\n",
    "\n",
    "def k_examples_per_class(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    return (\n",
    "        df.assign(len=df.review.str.len())\n",
    "          .sort_values(\"len\")\n",
    "          .groupby(\"class\", group_keys=False)\n",
    "          .head(k)\n",
    "          .drop(columns=\"len\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# =============== MAIN ===============\n",
    "for model_name in OLLAMA_MODELS:\n",
    "    MODEL_CLEAN = model_name.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "    OUT_DIR = f\"few_shot_folds_{MODEL_CLEAN}_{DATASET_NAME}\"\n",
    "    PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "    os.makedirs(PRED_DIR, exist_ok=True)\n",
    "\n",
    "    llm = OllamaLLM(model=model_name)\n",
    "\n",
    "    all_metrics = []\n",
    "    summary_rows = []\n",
    "\n",
    "    for fold in range(10):\n",
    "        test_path = os.path.join(FOLD_DIR, f\"test_fold_{fold}.csv\")\n",
    "        train_path = os.path.join(FOLD_DIR, f\"train_fold_{fold}.csv\")\n",
    "        test_df = pd.read_csv(test_path).reset_index(drop=True)\n",
    "        train_df = pd.read_csv(train_path).reset_index(drop=True)\n",
    "\n",
    "        labels = sorted(train_df[\"class\"].unique())\n",
    "\n",
    "        for k in K_VALUES:\n",
    "            fewshot_df = k_examples_per_class(train_df, k)\n",
    "            example_block = build_examples(fewshot_df)\n",
    "            examples_section = f\"Here are {k} examples (text , class):\\n{example_block}\\n\\n\"\n",
    "\n",
    "            y_true, preds = [], []\n",
    "\n",
    "            for _, row in tqdm(test_df.iterrows(), total=len(test_df),\n",
    "                               desc=f\"{model_name} | Fold-{fold} | {k}-shot\", unit=\"req\"):\n",
    "\n",
    "                prompt = PROMPT_TEMPLATE.format(\n",
    "                    examples_section=examples_section,\n",
    "                    req_text=row.review\n",
    "                )\n",
    "\n",
    "                resp = call_llm(llm, prompt)\n",
    "                pred = extract_label(resp, labels)\n",
    "                y_true.append(row[\"class\"])\n",
    "                preds.append(pred)\n",
    "\n",
    "            # ─── METRICS ──────────────────────────────\n",
    "            macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"macro\", zero_division=0)\n",
    "            micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"micro\", zero_division=0)\n",
    "            weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"weighted\", zero_division=0)\n",
    "\n",
    "            # ─── SAVE PREDICTIONS ─────────────────────\n",
    "            pd.DataFrame({\n",
    "                \"text\": test_df.review,\n",
    "                \"gold\": y_true,\n",
    "                \"pred\": preds\n",
    "            }).to_csv(\n",
    "                os.path.join(PRED_DIR, f\"{DATASET_NAME}_fold{fold}_{k}shot_preds.csv\"),\n",
    "                index=False, encoding=\"utf-8\"\n",
    "            )\n",
    "\n",
    "            # ─── RECORD METRICS ───────────────────────\n",
    "            summary_rows.append({\n",
    "                \"dataset\": DATASET_NAME,\n",
    "                \"model\": model_name,\n",
    "                \"fold\": fold,\n",
    "                \"k_shot\": k,\n",
    "                \"macro_f1\": macro_f1,\n",
    "                \"micro_f1\": micro_f1,\n",
    "                \"weighted_f1\": weighted_f1\n",
    "            })\n",
    "\n",
    "            for i, lab in enumerate(labels):\n",
    "                all_metrics.append({\n",
    "                    \"dataset\": DATASET_NAME,\n",
    "                    \"model\": model_name,\n",
    "                    \"fold\": fold,\n",
    "                    \"k_shot\": k,\n",
    "                    \"class_label\": lab,\n",
    "                    \"macro_f1\": macro_f1,\n",
    "                    \"micro_f1\": micro_f1,\n",
    "                    \"weighted_f1\": weighted_f1,\n",
    "                })\n",
    "\n",
    "    # ─── SAVE RESULTS ───────────────────────────────\n",
    "    pd.DataFrame(summary_rows).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{DATASET_NAME}_fewshot_folded_summary.csv\"),\n",
    "        index=False, encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    pd.DataFrame(all_metrics).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{DATASET_NAME}_fewshot_all_metrics.csv\"),\n",
    "        index=False, encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✅ {model_name} few-shot evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6efa9d-4c93-464b-8d77-e0418c88201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_few_shot_all_models.py\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "DATASET_NAME = \"maalej\"\n",
    "FOLD_DIR = f\"stratified_splits_80_10_10/{DATASET_NAME}\"\n",
    "K_VALUES = [1, 3, 5, 7]\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "LABEL_LIST = [\n",
    "    \"feature request\",\n",
    "    \"rating\",\n",
    "    \"user experience\",\n",
    "    \"problem discovery\",\n",
    "]\n",
    "\n",
    "OLLAMA_MODELS = [\n",
    "   \n",
    "    \"mistral:7b\",\n",
    "    \"gemma3:4b\",\n",
    "    \"wizardlm2:7b\"\n",
    "]\n",
    "\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"You are a requirement classification assistant.\\n\"\n",
    "    \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "    \"- Feature Request: suggestions or desires for new features, functionality, or improvements. \"\n",
    "    \"Often uses words like 'add', 'should have', 'need', 'wish', 'please include'.\\n\"\n",
    "    \"- Rating: numeric scores (e.g. 5 stars) or general feedback like 'great app' or 'bad service' without \"\n",
    "    \"any specific details.\\n\"\n",
    "    \"- User Experience: opinions about usability, speed, UI, navigation, or general interaction quality. \"\n",
    "    \"Might mention design, slow loading, or ease of use.\\n\"\n",
    "    \"- Problem Discovery: reports of bugs, crashes, errors, or issues. Often contains words like \"\n",
    "    \"'doesn't work', 'crash', 'bug', 'problem', 'error'.\\n\\n\"\n",
    "    \"{examples_section}\"\n",
    "    \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "    \"Review: {req_text}\\n\"\n",
    "    \"Label:\"\n",
    "\n",
    ")\n",
    "\n",
    "# =============== HELPERS ===============\n",
    "def build_examples(df):\n",
    "    return \"\\n\".join(f\"{row.review} , {row['class']}\" for _, row in df.iterrows())\n",
    "\n",
    "def call_llm(llm, prompt: str) -> str:\n",
    "    return llm.invoke(prompt).strip()\n",
    "\n",
    "def extract_label(response: str, labels: list[str]) -> str:\n",
    "    rl = response.lower()\n",
    "    for lab in labels:\n",
    "        if lab.lower() in rl:\n",
    "            return lab\n",
    "    return labels[0]\n",
    "\n",
    "def k_examples_per_class(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    return (\n",
    "        df.assign(len=df.review.str.len())\n",
    "          .sort_values(\"len\")\n",
    "          .groupby(\"class\", group_keys=False)\n",
    "          .head(k)\n",
    "          .drop(columns=\"len\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# =============== MAIN ===============\n",
    "for model_name in OLLAMA_MODELS:\n",
    "    MODEL_CLEAN = model_name.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "    OUT_DIR = f\"few_shot_folds_{MODEL_CLEAN}_{DATASET_NAME}\"\n",
    "    PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "    os.makedirs(PRED_DIR, exist_ok=True)\n",
    "\n",
    "    llm = OllamaLLM(model=model_name)\n",
    "\n",
    "    all_metrics = []\n",
    "    summary_rows = []\n",
    "\n",
    "    for fold in range(10):\n",
    "        test_path = os.path.join(FOLD_DIR, f\"test_fold_{fold}.csv\")\n",
    "        train_path = os.path.join(FOLD_DIR, f\"train_fold_{fold}.csv\")\n",
    "        test_df = pd.read_csv(test_path).reset_index(drop=True)\n",
    "        train_df = pd.read_csv(train_path).reset_index(drop=True)\n",
    "\n",
    "        labels = sorted(train_df[\"class\"].unique())\n",
    "\n",
    "        for k in K_VALUES:\n",
    "            fewshot_df = k_examples_per_class(train_df, k)\n",
    "            example_block = build_examples(fewshot_df)\n",
    "            examples_section = f\"Here are {k} examples (text , class):\\n{example_block}\\n\\n\"\n",
    "\n",
    "            y_true, preds = [], []\n",
    "\n",
    "            for _, row in tqdm(test_df.iterrows(), total=len(test_df),\n",
    "                               desc=f\"{model_name} | Fold-{fold} | {k}-shot\", unit=\"req\"):\n",
    "\n",
    "                prompt = PROMPT_TEMPLATE.format(\n",
    "                    examples_section=examples_section,\n",
    "                    req_text=row.review\n",
    "                )\n",
    "\n",
    "                resp = call_llm(llm, prompt)\n",
    "                pred = extract_label(resp, labels)\n",
    "                y_true.append(row[\"class\"])\n",
    "                preds.append(pred)\n",
    "\n",
    "            # ─── METRICS ──────────────────────────────\n",
    "            macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"macro\", zero_division=0)\n",
    "            micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"micro\", zero_division=0)\n",
    "            weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"weighted\", zero_division=0)\n",
    "\n",
    "            # ─── SAVE PREDICTIONS ─────────────────────\n",
    "            pd.DataFrame({\n",
    "                \"text\": test_df.review,\n",
    "                \"gold\": y_true,\n",
    "                \"pred\": preds\n",
    "            }).to_csv(\n",
    "                os.path.join(PRED_DIR, f\"{DATASET_NAME}_fold{fold}_{k}shot_preds.csv\"),\n",
    "                index=False, encoding=\"utf-8\"\n",
    "            )\n",
    "\n",
    "            # ─── RECORD METRICS ───────────────────────\n",
    "            summary_rows.append({\n",
    "                \"dataset\": DATASET_NAME,\n",
    "                \"model\": model_name,\n",
    "                \"fold\": fold,\n",
    "                \"k_shot\": k,\n",
    "                \"macro_f1\": macro_f1,\n",
    "                \"micro_f1\": micro_f1,\n",
    "                \"weighted_f1\": weighted_f1\n",
    "            })\n",
    "\n",
    "            for i, lab in enumerate(labels):\n",
    "                all_metrics.append({\n",
    "                    \"dataset\": DATASET_NAME,\n",
    "                    \"model\": model_name,\n",
    "                    \"fold\": fold,\n",
    "                    \"k_shot\": k,\n",
    "                    \"class_label\": lab,\n",
    "                    \"macro_f1\": macro_f1,\n",
    "                    \"micro_f1\": micro_f1,\n",
    "                    \"weighted_f1\": weighted_f1,\n",
    "                })\n",
    "\n",
    "    # ─── SAVE RESULTS ───────────────────────────────\n",
    "    pd.DataFrame(summary_rows).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{DATASET_NAME}_fewshot_folded_summary.csv\"),\n",
    "        index=False, encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    pd.DataFrame(all_metrics).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{DATASET_NAME}_fewshot_all_metrics.csv\"),\n",
    "        index=False, encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✅ {model_name} few-shot evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1f916cd-bf19-469e-aad1-37ccf5c2df85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama3:70b | Fold-0 | 1-shot: 100%|██████████| 300/300 [01:40<00:00,  2.97req/s]\n",
      "llama3:70b | Fold-0 | 3-shot: 100%|██████████| 300/300 [01:42<00:00,  2.92req/s]\n",
      "llama3:70b | Fold-0 | 5-shot: 100%|██████████| 300/300 [01:44<00:00,  2.86req/s]\n",
      "llama3:70b | Fold-0 | 7-shot: 100%|██████████| 300/300 [01:45<00:00,  2.85req/s]\n",
      "llama3:70b | Fold-1 | 1-shot: 100%|██████████| 300/300 [01:40<00:00,  2.98req/s]\n",
      "llama3:70b | Fold-1 | 3-shot: 100%|██████████| 300/300 [01:43<00:00,  2.89req/s]\n",
      "llama3:70b | Fold-1 | 5-shot: 100%|██████████| 300/300 [01:43<00:00,  2.90req/s]\n",
      "llama3:70b | Fold-1 | 7-shot: 100%|██████████| 300/300 [01:45<00:00,  2.84req/s]\n",
      "llama3:70b | Fold-2 | 1-shot: 100%|██████████| 300/300 [01:41<00:00,  2.96req/s]\n",
      "llama3:70b | Fold-2 | 3-shot: 100%|██████████| 300/300 [01:42<00:00,  2.91req/s]\n",
      "llama3:70b | Fold-2 | 5-shot: 100%|██████████| 300/300 [01:43<00:00,  2.90req/s]\n",
      "llama3:70b | Fold-2 | 7-shot: 100%|██████████| 300/300 [01:45<00:00,  2.84req/s]\n",
      "llama3:70b | Fold-3 | 1-shot: 100%|██████████| 300/300 [01:43<00:00,  2.90req/s]\n",
      "llama3:70b | Fold-3 | 3-shot: 100%|██████████| 300/300 [01:44<00:00,  2.88req/s]\n",
      "llama3:70b | Fold-3 | 5-shot: 100%|██████████| 300/300 [01:45<00:00,  2.85req/s]\n",
      "llama3:70b | Fold-3 | 7-shot: 100%|██████████| 300/300 [01:46<00:00,  2.82req/s]\n",
      "llama3:70b | Fold-4 | 1-shot: 100%|██████████| 300/300 [01:41<00:00,  2.95req/s]\n",
      "llama3:70b | Fold-4 | 3-shot: 100%|██████████| 300/300 [01:43<00:00,  2.89req/s]\n",
      "llama3:70b | Fold-4 | 5-shot: 100%|██████████| 300/300 [01:45<00:00,  2.85req/s]\n",
      "llama3:70b | Fold-4 | 7-shot: 100%|██████████| 300/300 [01:46<00:00,  2.83req/s]\n",
      "llama3:70b | Fold-5 | 1-shot: 100%|██████████| 300/300 [01:41<00:00,  2.94req/s]\n",
      "llama3:70b | Fold-5 | 3-shot: 100%|██████████| 300/300 [01:44<00:00,  2.88req/s]\n",
      "llama3:70b | Fold-5 | 5-shot: 100%|██████████| 300/300 [01:45<00:00,  2.83req/s]\n",
      "llama3:70b | Fold-5 | 7-shot: 100%|██████████| 300/300 [01:47<00:00,  2.80req/s]\n",
      "llama3:70b | Fold-6 | 1-shot: 100%|██████████| 300/300 [01:39<00:00,  3.02req/s]\n",
      "llama3:70b | Fold-6 | 3-shot: 100%|██████████| 300/300 [01:42<00:00,  2.93req/s]\n",
      "llama3:70b | Fold-6 | 5-shot: 100%|██████████| 300/300 [01:45<00:00,  2.85req/s]\n",
      "llama3:70b | Fold-6 | 7-shot: 100%|██████████| 300/300 [01:45<00:00,  2.84req/s]\n",
      "llama3:70b | Fold-7 | 1-shot: 100%|██████████| 300/300 [01:40<00:00,  2.98req/s]\n",
      "llama3:70b | Fold-7 | 3-shot: 100%|██████████| 300/300 [01:41<00:00,  2.96req/s]\n",
      "llama3:70b | Fold-7 | 5-shot: 100%|██████████| 300/300 [01:45<00:00,  2.84req/s]\n",
      "llama3:70b | Fold-7 | 7-shot: 100%|██████████| 300/300 [01:46<00:00,  2.83req/s]\n",
      "llama3:70b | Fold-8 | 1-shot: 100%|██████████| 300/300 [01:41<00:00,  2.97req/s]\n",
      "llama3:70b | Fold-8 | 3-shot: 100%|██████████| 300/300 [01:43<00:00,  2.91req/s]\n",
      "llama3:70b | Fold-8 | 5-shot: 100%|██████████| 300/300 [01:43<00:00,  2.89req/s]\n",
      "llama3:70b | Fold-8 | 7-shot: 100%|██████████| 300/300 [01:44<00:00,  2.88req/s]\n",
      "llama3:70b | Fold-9 | 1-shot: 100%|██████████| 300/300 [01:40<00:00,  2.99req/s]\n",
      "llama3:70b | Fold-9 | 3-shot: 100%|██████████| 300/300 [01:43<00:00,  2.90req/s]\n",
      "llama3:70b | Fold-9 | 5-shot: 100%|██████████| 300/300 [01:48<00:00,  2.77req/s]\n",
      "llama3:70b | Fold-9 | 7-shot: 100%|██████████| 300/300 [01:48<00:00,  2.77req/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ llama3:70b few-shot evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama3:8b | Fold-0 | 1-shot: 100%|██████████| 300/300 [01:00<00:00,  4.95req/s]\n",
      "llama3:8b | Fold-0 | 3-shot: 100%|██████████| 300/300 [00:57<00:00,  5.18req/s]\n",
      "llama3:8b | Fold-0 | 5-shot: 100%|██████████| 300/300 [00:58<00:00,  5.12req/s]\n",
      "llama3:8b | Fold-0 | 7-shot: 100%|██████████| 300/300 [00:59<00:00,  5.08req/s]\n",
      "llama3:8b | Fold-1 | 1-shot: 100%|██████████| 300/300 [00:59<00:00,  5.07req/s]\n",
      "llama3:8b | Fold-1 | 3-shot: 100%|██████████| 300/300 [00:58<00:00,  5.13req/s]\n",
      "llama3:8b | Fold-1 | 5-shot: 100%|██████████| 300/300 [00:58<00:00,  5.17req/s]\n",
      "llama3:8b | Fold-2 | 3-shot: 100%|██████████| 300/300 [00:58<00:00,  5.13req/s]\n",
      "llama3:8b | Fold-2 | 5-shot: 100%|██████████| 300/300 [00:58<00:00,  5.11req/s]\n",
      "llama3:8b | Fold-2 | 7-shot: 100%|██████████| 300/300 [00:59<00:00,  5.08req/s]\n",
      "llama3:8b | Fold-3 | 1-shot: 100%|██████████| 300/300 [00:58<00:00,  5.11req/s]\n",
      "llama3:8b | Fold-3 | 3-shot: 100%|██████████| 300/300 [00:58<00:00,  5.11req/s]\n",
      "llama3:8b | Fold-3 | 5-shot: 100%|██████████| 300/300 [00:58<00:00,  5.13req/s]\n",
      "llama3:8b | Fold-3 | 7-shot: 100%|██████████| 300/300 [00:58<00:00,  5.17req/s]\n",
      "llama3:8b | Fold-4 | 1-shot: 100%|██████████| 300/300 [00:58<00:00,  5.11req/s]\n",
      "llama3:8b | Fold-4 | 3-shot: 100%|██████████| 300/300 [00:58<00:00,  5.16req/s]\n",
      "llama3:8b | Fold-4 | 5-shot: 100%|██████████| 300/300 [00:58<00:00,  5.13req/s]\n",
      "llama3:8b | Fold-4 | 7-shot:  22%|██▏       | 66/300 [00:12<00:46,  5.06req/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "llama3:8b | Fold-4 | 7-shot: 100%|██████████| 300/300 [00:58<00:00,  5.12req/s]\n",
      "llama3:8b | Fold-5 | 1-shot: 100%|██████████| 300/300 [00:58<00:00,  5.10req/s]\n",
      "llama3:8b | Fold-5 | 3-shot: 100%|██████████| 300/300 [00:58<00:00,  5.13req/s]\n",
      "llama3:8b | Fold-5 | 5-shot: 100%|██████████| 300/300 [00:58<00:00,  5.12req/s]\n",
      "llama3:8b | Fold-5 | 7-shot: 100%|██████████| 300/300 [00:58<00:00,  5.12req/s]\n",
      "llama3:8b | Fold-6 | 1-shot: 100%|██████████| 300/300 [00:58<00:00,  5.17req/s]\n",
      "llama3:8b | Fold-6 | 3-shot: 100%|██████████| 300/300 [00:57<00:00,  5.21req/s]\n",
      "llama3:8b | Fold-6 | 5-shot: 100%|██████████| 300/300 [00:57<00:00,  5.17req/s]\n",
      "llama3:8b | Fold-6 | 7-shot: 100%|██████████| 300/300 [00:58<00:00,  5.10req/s]\n",
      "llama3:8b | Fold-7 | 1-shot: 100%|██████████| 300/300 [00:58<00:00,  5.14req/s]\n",
      "llama3:8b | Fold-7 | 7-shot: 100%|██████████| 300/300 [00:57<00:00,  5.22req/s]\n",
      "llama3:8b | Fold-8 | 1-shot: 100%|██████████| 300/300 [00:58<00:00,  5.15req/s]\n",
      "llama3:8b | Fold-8 | 3-shot: 100%|██████████| 300/300 [00:57<00:00,  5.26req/s]\n",
      "llama3:8b | Fold-8 | 5-shot: 100%|██████████| 300/300 [00:57<00:00,  5.24req/s]\n",
      "llama3:8b | Fold-8 | 7-shot: 100%|██████████| 300/300 [00:58<00:00,  5.16req/s]\n",
      "llama3:8b | Fold-9 | 1-shot: 100%|██████████| 300/300 [00:57<00:00,  5.22req/s]\n",
      "llama3:8b | Fold-9 | 3-shot: 100%|██████████| 300/300 [00:58<00:00,  5.13req/s]\n",
      "llama3:8b | Fold-9 | 5-shot: 100%|██████████| 300/300 [00:58<00:00,  5.13req/s]\n",
      "llama3:8b | Fold-9 | 7-shot: 100%|██████████| 300/300 [00:58<00:00,  5.13req/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ llama3:8b few-shot evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#scalab_few_shots\n",
    "# run_few_shot_all_models.py\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "DATASET_NAME = \"scalabrino\"\n",
    "FOLD_DIR = f\"stratified_splits_80_10_10/{DATASET_NAME}\"\n",
    "K_VALUES = [1, 3, 5, 7]\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "LABEL_LIST = [\n",
    "    \"BUG\",\n",
    "    \"FEATURE\",\n",
    "    \"PERFORMANCE\",\n",
    "    \"ENERGY\",\n",
    "    \"OTHER\",\n",
    "    \"SECURITY\",\n",
    "    \"USABILITY\",\n",
    "]\n",
    "\n",
    "OLLAMA_MODELS = [\n",
    "   \n",
    "    \"llama3:70b\",\n",
    "    \"llama3:8b\"\n",
    "]\n",
    "\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"You are a requirement classification assistant.\\n\"\n",
    "    \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "    \"- Feature Request: suggestions or desires for new features, functionality, or improvements. \"\n",
    "    \"Often uses words like 'add', 'should have', 'need', 'wish', 'please include'.\\n\"\n",
    "    \"- Rating: numeric scores (e.g. 5 stars) or general feedback like 'great app' or 'bad service' without \"\n",
    "    \"any specific details.\\n\"\n",
    "    \"- User Experience: opinions about usability, speed, UI, navigation, or general interaction quality. \"\n",
    "    \"Might mention design, slow loading, or ease of use.\\n\"\n",
    "    \"- Problem Discovery: reports of bugs, crashes, errors, or issues. Often contains words like \"\n",
    "    \"'doesn't work', 'crash', 'bug', 'problem', 'error'.\\n\\n\"\n",
    "    \"{examples_section}\"\n",
    "    \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "    \"Review: {req_text}\\n\"\n",
    "    \"Label:\"\n",
    "\n",
    ")\n",
    "\n",
    "# =============== HELPERS ===============\n",
    "def build_examples(df):\n",
    "    return \"\\n\".join(f\"{row.review} , {row['class']}\" for _, row in df.iterrows())\n",
    "\n",
    "def call_llm(llm, prompt: str) -> str:\n",
    "    return llm.invoke(prompt).strip()\n",
    "\n",
    "def extract_label(response: str, labels: list[str]) -> str:\n",
    "    rl = response.lower()\n",
    "    for lab in labels:\n",
    "        if lab.lower() in rl:\n",
    "            return lab\n",
    "    return labels[0]\n",
    "\n",
    "def k_examples_per_class(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    return (\n",
    "        df.assign(len=df.review.str.len())\n",
    "          .sort_values(\"len\")\n",
    "          .groupby(\"class\", group_keys=False)\n",
    "          .head(k)\n",
    "          .drop(columns=\"len\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# =============== MAIN ===============\n",
    "for model_name in OLLAMA_MODELS:\n",
    "    MODEL_CLEAN = model_name.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "    OUT_DIR = f\"few_shot_folds_{MODEL_CLEAN}_{DATASET_NAME}\"\n",
    "    PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "    os.makedirs(PRED_DIR, exist_ok=True)\n",
    "\n",
    "    llm = OllamaLLM(model=model_name)\n",
    "\n",
    "    all_metrics = []\n",
    "    summary_rows = []\n",
    "\n",
    "    for fold in range(10):\n",
    "        test_path = os.path.join(FOLD_DIR, f\"test_fold_{fold}.csv\")\n",
    "        train_path = os.path.join(FOLD_DIR, f\"train_fold_{fold}.csv\")\n",
    "        test_df = pd.read_csv(test_path).reset_index(drop=True)\n",
    "        train_df = pd.read_csv(train_path).reset_index(drop=True)\n",
    "\n",
    "        labels = sorted(train_df[\"class\"].unique())\n",
    "\n",
    "        for k in K_VALUES:\n",
    "            fewshot_df = k_examples_per_class(train_df, k)\n",
    "            example_block = build_examples(fewshot_df)\n",
    "            examples_section = f\"Here are {k} examples (text , class):\\n{example_block}\\n\\n\"\n",
    "\n",
    "            y_true, preds = [], []\n",
    "\n",
    "            for _, row in tqdm(test_df.iterrows(), total=len(test_df),\n",
    "                               desc=f\"{model_name} | Fold-{fold} | {k}-shot\", unit=\"req\"):\n",
    "\n",
    "                prompt = PROMPT_TEMPLATE.format(\n",
    "                    examples_section=examples_section,\n",
    "                    req_text=row.review\n",
    "                )\n",
    "\n",
    "                resp = call_llm(llm, prompt)\n",
    "                pred = extract_label(resp, labels)\n",
    "                y_true.append(row[\"class\"])\n",
    "                preds.append(pred)\n",
    "\n",
    "            # ─── METRICS ──────────────────────────────\n",
    "            macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"macro\", zero_division=0)\n",
    "            micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"micro\", zero_division=0)\n",
    "            weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"weighted\", zero_division=0)\n",
    "\n",
    "            # ─── SAVE PREDICTIONS ─────────────────────\n",
    "            pd.DataFrame({\n",
    "                \"text\": test_df.review,\n",
    "                \"gold\": y_true,\n",
    "                \"pred\": preds\n",
    "            }).to_csv(\n",
    "                os.path.join(PRED_DIR, f\"{DATASET_NAME}_fold{fold}_{k}shot_preds.csv\"),\n",
    "                index=False, encoding=\"utf-8\"\n",
    "            )\n",
    "\n",
    "            # ─── RECORD METRICS ───────────────────────\n",
    "            summary_rows.append({\n",
    "                \"dataset\": DATASET_NAME,\n",
    "                \"model\": model_name,\n",
    "                \"fold\": fold,\n",
    "                \"k_shot\": k,\n",
    "                \"macro_f1\": macro_f1,\n",
    "                \"micro_f1\": micro_f1,\n",
    "                \"weighted_f1\": weighted_f1\n",
    "            })\n",
    "\n",
    "            for i, lab in enumerate(labels):\n",
    "                all_metrics.append({\n",
    "                    \"dataset\": DATASET_NAME,\n",
    "                    \"model\": model_name,\n",
    "                    \"fold\": fold,\n",
    "                    \"k_shot\": k,\n",
    "                    \"class_label\": lab,\n",
    "                    \"macro_f1\": macro_f1,\n",
    "                    \"micro_f1\": micro_f1,\n",
    "                    \"weighted_f1\": weighted_f1,\n",
    "                })\n",
    "\n",
    "    # ─── SAVE RESULTS ───────────────────────────────\n",
    "    pd.DataFrame(summary_rows).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{DATASET_NAME}_fewshot_folded_summary.csv\"),\n",
    "        index=False, encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    pd.DataFrame(all_metrics).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{DATASET_NAME}_fewshot_all_metrics.csv\"),\n",
    "        index=False, encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✅ {model_name} few-shot evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4827d-fbaf-4c29-8922-b9cd17212b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb3180d3-81b1-4681-86bf-f8be3d8d32a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mistral:7b | Fold-0 | 1-shot: 100%|██████████| 300/300 [00:31<00:00,  9.57req/s]\n",
      "mistral:7b | Fold-0 | 3-shot: 100%|██████████| 300/300 [00:32<00:00,  9.25req/s]\n",
      "mistral:7b | Fold-0 | 5-shot: 100%|██████████| 300/300 [00:30<00:00,  9.80req/s]\n",
      "mistral:7b | Fold-0 | 7-shot: 100%|██████████| 300/300 [00:31<00:00,  9.38req/s]\n",
      "mistral:7b | Fold-1 | 1-shot: 100%|██████████| 300/300 [00:32<00:00,  9.23req/s]\n",
      "mistral:7b | Fold-1 | 3-shot: 100%|██████████| 300/300 [00:32<00:00,  9.25req/s]\n",
      "mistral:7b | Fold-1 | 5-shot: 100%|██████████| 300/300 [00:33<00:00,  9.00req/s]\n",
      "mistral:7b | Fold-1 | 7-shot: 100%|██████████| 300/300 [00:34<00:00,  8.68req/s]\n",
      "mistral:7b | Fold-2 | 1-shot: 100%|██████████| 300/300 [00:29<00:00, 10.31req/s]\n",
      "mistral:7b | Fold-2 | 3-shot: 100%|██████████| 300/300 [00:28<00:00, 10.42req/s]\n",
      "mistral:7b | Fold-2 | 5-shot: 100%|██████████| 300/300 [00:31<00:00,  9.50req/s]\n",
      "mistral:7b | Fold-2 | 7-shot: 100%|██████████| 300/300 [00:32<00:00,  9.35req/s]\n",
      "mistral:7b | Fold-3 | 1-shot: 100%|██████████| 300/300 [00:32<00:00,  9.33req/s]\n",
      "mistral:7b | Fold-3 | 3-shot: 100%|██████████| 300/300 [00:31<00:00,  9.49req/s]\n",
      "mistral:7b | Fold-3 | 5-shot: 100%|██████████| 300/300 [00:32<00:00,  9.24req/s]\n",
      "mistral:7b | Fold-3 | 7-shot: 100%|██████████| 300/300 [00:33<00:00,  8.96req/s]\n",
      "mistral:7b | Fold-4 | 1-shot: 100%|██████████| 300/300 [00:30<00:00,  9.99req/s]\n",
      "mistral:7b | Fold-4 | 3-shot: 100%|██████████| 300/300 [00:29<00:00, 10.19req/s]\n",
      "mistral:7b | Fold-4 | 5-shot: 100%|██████████| 300/300 [00:31<00:00,  9.44req/s]\n",
      "mistral:7b | Fold-4 | 7-shot: 100%|██████████| 300/300 [00:32<00:00,  9.13req/s]\n",
      "mistral:7b | Fold-5 | 1-shot: 100%|██████████| 300/300 [00:29<00:00, 10.15req/s]\n",
      "mistral:7b | Fold-5 | 3-shot: 100%|██████████| 300/300 [00:33<00:00,  9.08req/s]\n",
      "mistral:7b | Fold-5 | 5-shot: 100%|██████████| 300/300 [00:31<00:00,  9.47req/s]\n",
      "mistral:7b | Fold-5 | 7-shot: 100%|██████████| 300/300 [00:32<00:00,  9.10req/s]\n",
      "mistral:7b | Fold-6 | 1-shot: 100%|██████████| 300/300 [00:33<00:00,  8.99req/s]\n",
      "mistral:7b | Fold-6 | 3-shot: 100%|██████████| 300/300 [00:29<00:00, 10.06req/s]\n",
      "mistral:7b | Fold-6 | 5-shot: 100%|██████████| 300/300 [12:49<00:00,  2.57s/req]   \n",
      "mistral:7b | Fold-6 | 7-shot: 100%|██████████| 300/300 [00:33<00:00,  9.03req/s]\n",
      "mistral:7b | Fold-7 | 1-shot: 100%|██████████| 300/300 [00:28<00:00, 10.40req/s]\n",
      "mistral:7b | Fold-7 | 3-shot: 100%|██████████| 300/300 [00:29<00:00, 10.24req/s]\n",
      "mistral:7b | Fold-7 | 5-shot: 100%|██████████| 300/300 [00:31<00:00,  9.40req/s]\n",
      "mistral:7b | Fold-7 | 7-shot: 100%|██████████| 300/300 [00:33<00:00,  9.02req/s]\n",
      "mistral:7b | Fold-8 | 1-shot: 100%|██████████| 300/300 [00:30<00:00,  9.89req/s]\n",
      "mistral:7b | Fold-8 | 3-shot: 100%|██████████| 300/300 [00:29<00:00, 10.19req/s]\n",
      "mistral:7b | Fold-8 | 5-shot: 100%|██████████| 300/300 [00:30<00:00,  9.88req/s]\n",
      "mistral:7b | Fold-8 | 7-shot: 100%|██████████| 300/300 [00:31<00:00,  9.39req/s]\n",
      "mistral:7b | Fold-9 | 1-shot: 100%|██████████| 300/300 [00:28<00:00, 10.51req/s]\n",
      "mistral:7b | Fold-9 | 3-shot: 100%|██████████| 300/300 [00:30<00:00,  9.79req/s]\n",
      "mistral:7b | Fold-9 | 5-shot: 100%|██████████| 300/300 [00:31<00:00,  9.39req/s]\n",
      "mistral:7b | Fold-9 | 7-shot: 100%|██████████| 300/300 [00:34<00:00,  8.80req/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ mistral:7b few-shot evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gemma3:4b | Fold-0 | 1-shot: 100%|██████████| 300/300 [01:16<00:00,  3.92req/s]\n",
      "gemma3:4b | Fold-0 | 3-shot: 100%|██████████| 300/300 [01:13<00:00,  4.08req/s]\n",
      "gemma3:4b | Fold-0 | 5-shot: 100%|██████████| 300/300 [01:14<00:00,  4.02req/s]\n",
      "gemma3:4b | Fold-0 | 7-shot: 100%|██████████| 300/300 [01:15<00:00,  4.00req/s]\n",
      "gemma3:4b | Fold-1 | 1-shot: 100%|██████████| 300/300 [01:13<00:00,  4.10req/s]\n",
      "gemma3:4b | Fold-1 | 3-shot: 100%|██████████| 300/300 [01:13<00:00,  4.11req/s]\n",
      "gemma3:4b | Fold-1 | 5-shot: 100%|██████████| 300/300 [01:14<00:00,  4.04req/s]\n",
      "gemma3:4b | Fold-1 | 7-shot: 100%|██████████| 300/300 [01:15<00:00,  3.96req/s]\n",
      "gemma3:4b | Fold-2 | 1-shot: 100%|██████████| 300/300 [01:13<00:00,  4.11req/s]\n",
      "gemma3:4b | Fold-2 | 3-shot: 100%|██████████| 300/300 [01:12<00:00,  4.11req/s]\n",
      "gemma3:4b | Fold-2 | 5-shot: 100%|██████████| 300/300 [01:14<00:00,  4.04req/s]\n",
      "gemma3:4b | Fold-2 | 7-shot: 100%|██████████| 300/300 [01:14<00:00,  4.01req/s]\n",
      "gemma3:4b | Fold-3 | 1-shot: 100%|██████████| 300/300 [01:13<00:00,  4.07req/s]\n",
      "gemma3:4b | Fold-3 | 3-shot: 100%|██████████| 300/300 [01:14<00:00,  4.02req/s]\n",
      "gemma3:4b | Fold-3 | 5-shot: 100%|██████████| 300/300 [01:14<00:00,  4.01req/s]\n",
      "gemma3:4b | Fold-3 | 7-shot:  77%|███████▋  | 231/300 [00:56<00:16,  4.07req/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 112\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m tqdm(test_df\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_df),\n\u001b[1;32m    105\u001b[0m                    desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Fold-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-shot\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreq\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    107\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m PROMPT_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    108\u001b[0m         examples_section\u001b[38;5;241m=\u001b[39mexamples_section,\n\u001b[1;32m    109\u001b[0m         req_text\u001b[38;5;241m=\u001b[39mrow\u001b[38;5;241m.\u001b[39mreview\n\u001b[1;32m    110\u001b[0m     )\n\u001b[0;32m--> 112\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mcall_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     pred \u001b[38;5;241m=\u001b[39m extract_label(resp, labels)\n\u001b[1;32m    114\u001b[0m     y_true\u001b[38;5;241m.\u001b[39mappend(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[1], line 58\u001b[0m, in \u001b[0;36mcall_llm\u001b[0;34m(llm, prompt)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_llm\u001b[39m(llm, prompt: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_core/language_models/llms.py:389\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    386\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    387\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    401\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_core/language_models/llms.py:766\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    764\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    765\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_core/language_models/llms.py:971\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    958\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    959\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    969\u001b[0m         )\n\u001b[1;32m    970\u001b[0m     ]\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    979\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    980\u001b[0m         callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    981\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[1;32m    989\u001b[0m     ]\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_core/language_models/llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    783\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 792\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    796\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    800\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    803\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_ollama/llms.py:362\u001b[0m, in \u001b[0;36mOllamaLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m--> 362\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_ollama/llms.py:321\u001b[0m, in \u001b[0;36mOllamaLLM._stream_with_aggregation\u001b[0;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    320\u001b[0m thinking_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_generate_stream(prompt, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream_resp, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthinking\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/langchain_ollama/llms.py:265\u001b[0m, in \u001b[0;36mOllamaLLM._create_generate_stream\u001b[0;34m(self, prompt, stop, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_generate_stream\u001b[39m(\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    261\u001b[0m     stop: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    263\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client:\n\u001b[0;32m--> 265\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_params(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    267\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/ollama/_client.py:165\u001b[0m, in \u001b[0;36mClient._request.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m():\n\u001b[0;32m--> 165\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mstream(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m       r\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpx/_client.py:868\u001b[0m, in \u001b[0;36mClient.stream\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;124;03mAlternative to `httpx.request()` that streams the response body\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;124;03minstead of loading it into memory at once.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;124;03m[0]: /quickstart#streaming-responses\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    855\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    856\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    857\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    866\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    867\u001b[0m )\n\u001b[0;32m--> 868\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/.conda/envs/myenv310/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#scalab_few_shots\n",
    "# run_few_shot_all_models.py\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "DATASET_NAME = \"scalabrino\"\n",
    "FOLD_DIR = f\"stratified_splits_80_10_10/{DATASET_NAME}\"\n",
    "K_VALUES = [1, 3, 5, 7]\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "LABEL_LIST = [\n",
    "    \"BUG\",\n",
    "    \"FEATURE\",\n",
    "    \"PERFORMANCE\",\n",
    "    \"ENERGY\",\n",
    "    \"OTHER\",\n",
    "    \"SECURITY\",\n",
    "    \"USABILITY\",\n",
    "]\n",
    "\n",
    "OLLAMA_MODELS = [\n",
    "   \n",
    "    \"mistral:7b\",\n",
    "    \"gemma3:4b\",\n",
    "    \"wizardlm2:7b\"\n",
    "]\n",
    "\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"You are a requirement classification assistant.\\n\"\n",
    "    \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "    \"- Feature Request: suggestions or desires for new features, functionality, or improvements. \"\n",
    "    \"Often uses words like 'add', 'should have', 'need', 'wish', 'please include'.\\n\"\n",
    "    \"- Rating: numeric scores (e.g. 5 stars) or general feedback like 'great app' or 'bad service' without \"\n",
    "    \"any specific details.\\n\"\n",
    "    \"- User Experience: opinions about usability, speed, UI, navigation, or general interaction quality. \"\n",
    "    \"Might mention design, slow loading, or ease of use.\\n\"\n",
    "    \"- Problem Discovery: reports of bugs, crashes, errors, or issues. Often contains words like \"\n",
    "    \"'doesn't work', 'crash', 'bug', 'problem', 'error'.\\n\\n\"\n",
    "    \"{examples_section}\"\n",
    "    \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "    \"Review: {req_text}\\n\"\n",
    "    \"Label:\"\n",
    "\n",
    ")\n",
    "\n",
    "# =============== HELPERS ===============\n",
    "def build_examples(df):\n",
    "    return \"\\n\".join(f\"{row.review} , {row['class']}\" for _, row in df.iterrows())\n",
    "\n",
    "def call_llm(llm, prompt: str) -> str:\n",
    "    return llm.invoke(prompt).strip()\n",
    "\n",
    "def extract_label(response: str, labels: list[str]) -> str:\n",
    "    rl = response.lower()\n",
    "    for lab in labels:\n",
    "        if lab.lower() in rl:\n",
    "            return lab\n",
    "    return labels[0]\n",
    "\n",
    "def k_examples_per_class(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    return (\n",
    "        df.assign(len=df.review.str.len())\n",
    "          .sort_values(\"len\")\n",
    "          .groupby(\"class\", group_keys=False)\n",
    "          .head(k)\n",
    "          .drop(columns=\"len\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# =============== MAIN ===============\n",
    "for model_name in OLLAMA_MODELS:\n",
    "    MODEL_CLEAN = model_name.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "    OUT_DIR = f\"few_shot_folds_{MODEL_CLEAN}_{DATASET_NAME}\"\n",
    "    PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "    os.makedirs(PRED_DIR, exist_ok=True)\n",
    "\n",
    "    llm = OllamaLLM(model=model_name)\n",
    "\n",
    "    all_metrics = []\n",
    "    summary_rows = []\n",
    "\n",
    "    for fold in range(10):\n",
    "        test_path = os.path.join(FOLD_DIR, f\"test_fold_{fold}.csv\")\n",
    "        train_path = os.path.join(FOLD_DIR, f\"train_fold_{fold}.csv\")\n",
    "        test_df = pd.read_csv(test_path).reset_index(drop=True)\n",
    "        train_df = pd.read_csv(train_path).reset_index(drop=True)\n",
    "\n",
    "        labels = sorted(train_df[\"class\"].unique())\n",
    "\n",
    "        for k in K_VALUES:\n",
    "            fewshot_df = k_examples_per_class(train_df, k)\n",
    "            example_block = build_examples(fewshot_df)\n",
    "            examples_section = f\"Here are {k} examples (text , class):\\n{example_block}\\n\\n\"\n",
    "\n",
    "            y_true, preds = [], []\n",
    "\n",
    "            for _, row in tqdm(test_df.iterrows(), total=len(test_df),\n",
    "                               desc=f\"{model_name} | Fold-{fold} | {k}-shot\", unit=\"req\"):\n",
    "\n",
    "                prompt = PROMPT_TEMPLATE.format(\n",
    "                    examples_section=examples_section,\n",
    "                    req_text=row.review\n",
    "                )\n",
    "\n",
    "                resp = call_llm(llm, prompt)\n",
    "                pred = extract_label(resp, labels)\n",
    "                y_true.append(row[\"class\"])\n",
    "                preds.append(pred)\n",
    "\n",
    "            # ─── METRICS ──────────────────────────────\n",
    "            macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"macro\", zero_division=0)\n",
    "            micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"micro\", zero_division=0)\n",
    "            weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"weighted\", zero_division=0)\n",
    "\n",
    "            # ─── SAVE PREDICTIONS ─────────────────────\n",
    "            pd.DataFrame({\n",
    "                \"text\": test_df.review,\n",
    "                \"gold\": y_true,\n",
    "                \"pred\": preds\n",
    "            }).to_csv(\n",
    "                os.path.join(PRED_DIR, f\"{DATASET_NAME}_fold{fold}_{k}shot_preds.csv\"),\n",
    "                index=False, encoding=\"utf-8\"\n",
    "            )\n",
    "\n",
    "            # ─── RECORD METRICS ───────────────────────\n",
    "            summary_rows.append({\n",
    "                \"dataset\": DATASET_NAME,\n",
    "                \"model\": model_name,\n",
    "                \"fold\": fold,\n",
    "                \"k_shot\": k,\n",
    "                \"macro_f1\": macro_f1,\n",
    "                \"micro_f1\": micro_f1,\n",
    "                \"weighted_f1\": weighted_f1\n",
    "            })\n",
    "\n",
    "            for i, lab in enumerate(labels):\n",
    "                all_metrics.append({\n",
    "                    \"dataset\": DATASET_NAME,\n",
    "                    \"model\": model_name,\n",
    "                    \"fold\": fold,\n",
    "                    \"k_shot\": k,\n",
    "                    \"class_label\": lab,\n",
    "                    \"macro_f1\": macro_f1,\n",
    "                    \"micro_f1\": micro_f1,\n",
    "                    \"weighted_f1\": weighted_f1,\n",
    "                })\n",
    "\n",
    "    # ─── SAVE RESULTS ───────────────────────────────\n",
    "    pd.DataFrame(summary_rows).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{DATASET_NAME}_fewshot_folded_summary.csv\"),\n",
    "        index=False, encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    pd.DataFrame(all_metrics).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{DATASET_NAME}_fewshot_all_metrics.csv\"),\n",
    "        index=False, encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✅ {model_name} few-shot evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0423eb80-ba14-4c2b-a9d7-994a2dab367b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gemma3:4b | Fold-0 | 1-shot: 100%|██████████| 300/300 [01:15<00:00,  3.96req/s]\n",
      "gemma3:4b | Fold-0 | 3-shot: 100%|██████████| 300/300 [01:13<00:00,  4.09req/s]\n",
      "gemma3:4b | Fold-0 | 5-shot: 100%|██████████| 300/300 [01:15<00:00,  3.98req/s]\n",
      "gemma3:4b | Fold-0 | 7-shot: 100%|██████████| 300/300 [01:14<00:00,  4.04req/s]\n",
      "gemma3:4b | Fold-1 | 1-shot: 100%|██████████| 300/300 [01:12<00:00,  4.13req/s]\n",
      "gemma3:4b | Fold-1 | 3-shot: 100%|██████████| 300/300 [01:14<00:00,  4.05req/s]\n",
      "gemma3:4b | Fold-1 | 5-shot: 100%|██████████| 300/300 [01:13<00:00,  4.06req/s]\n",
      "gemma3:4b | Fold-1 | 7-shot: 100%|██████████| 300/300 [01:15<00:00,  3.95req/s]\n",
      "gemma3:4b | Fold-2 | 1-shot: 100%|██████████| 300/300 [01:12<00:00,  4.13req/s]\n",
      "gemma3:4b | Fold-2 | 3-shot: 100%|██████████| 300/300 [01:13<00:00,  4.10req/s]\n",
      "gemma3:4b | Fold-2 | 5-shot: 100%|██████████| 300/300 [01:14<00:00,  4.05req/s]\n",
      "gemma3:4b | Fold-2 | 7-shot: 100%|██████████| 300/300 [01:14<00:00,  4.03req/s]\n",
      "gemma3:4b | Fold-3 | 1-shot: 100%|██████████| 300/300 [01:12<00:00,  4.13req/s]\n",
      "gemma3:4b | Fold-3 | 3-shot: 100%|██████████| 300/300 [01:14<00:00,  4.04req/s]\n",
      "gemma3:4b | Fold-3 | 5-shot: 100%|██████████| 300/300 [01:14<00:00,  4.05req/s]\n",
      "gemma3:4b | Fold-3 | 7-shot: 100%|██████████| 300/300 [01:14<00:00,  4.03req/s]\n",
      "gemma3:4b | Fold-4 | 1-shot: 100%|██████████| 300/300 [01:11<00:00,  4.19req/s]\n",
      "gemma3:4b | Fold-4 | 3-shot: 100%|██████████| 300/300 [01:12<00:00,  4.14req/s]\n",
      "gemma3:4b | Fold-4 | 5-shot: 100%|██████████| 300/300 [01:14<00:00,  4.04req/s]\n",
      "gemma3:4b | Fold-4 | 7-shot: 100%|██████████| 300/300 [01:14<00:00,  4.05req/s]\n",
      "gemma3:4b | Fold-5 | 1-shot: 100%|██████████| 300/300 [01:12<00:00,  4.14req/s]\n",
      "gemma3:4b | Fold-5 | 3-shot: 100%|██████████| 300/300 [01:14<00:00,  4.01req/s]\n",
      "gemma3:4b | Fold-5 | 5-shot: 100%|██████████| 300/300 [01:14<00:00,  4.04req/s]\n",
      "gemma3:4b | Fold-5 | 7-shot: 100%|██████████| 300/300 [01:15<00:00,  3.97req/s]\n",
      "gemma3:4b | Fold-6 | 1-shot: 100%|██████████| 300/300 [01:14<00:00,  4.02req/s]\n",
      "gemma3:4b | Fold-6 | 3-shot: 100%|██████████| 300/300 [01:13<00:00,  4.08req/s]\n",
      "gemma3:4b | Fold-6 | 5-shot: 100%|██████████| 300/300 [01:14<00:00,  4.02req/s]\n",
      "gemma3:4b | Fold-6 | 7-shot: 100%|██████████| 300/300 [01:16<00:00,  3.95req/s]\n",
      "gemma3:4b | Fold-7 | 1-shot: 100%|██████████| 300/300 [01:13<00:00,  4.07req/s]\n",
      "gemma3:4b | Fold-7 | 3-shot: 100%|██████████| 300/300 [01:14<00:00,  4.03req/s]\n",
      "gemma3:4b | Fold-7 | 5-shot: 100%|██████████| 300/300 [01:14<00:00,  4.00req/s]\n",
      "gemma3:4b | Fold-7 | 7-shot: 100%|██████████| 300/300 [01:14<00:00,  4.02req/s]\n",
      "gemma3:4b | Fold-8 | 1-shot: 100%|██████████| 300/300 [01:12<00:00,  4.14req/s]\n",
      "gemma3:4b | Fold-8 | 3-shot: 100%|██████████| 300/300 [01:13<00:00,  4.06req/s]\n",
      "gemma3:4b | Fold-8 | 5-shot: 100%|██████████| 300/300 [01:14<00:00,  4.04req/s]\n",
      "gemma3:4b | Fold-8 | 7-shot: 100%|██████████| 300/300 [01:14<00:00,  4.04req/s]\n",
      "gemma3:4b | Fold-9 | 1-shot: 100%|██████████| 300/300 [01:13<00:00,  4.09req/s]\n",
      "gemma3:4b | Fold-9 | 3-shot: 100%|██████████| 300/300 [01:14<00:00,  4.03req/s]\n",
      "gemma3:4b | Fold-9 | 5-shot: 100%|██████████| 300/300 [01:14<00:00,  4.05req/s]\n",
      "gemma3:4b | Fold-9 | 7-shot: 100%|██████████| 300/300 [01:14<00:00,  4.04req/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ gemma3:4b few-shot evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wizardlm2:7b | Fold-0 | 1-shot: 100%|██████████| 300/300 [00:37<00:00,  7.95req/s]\n",
      "wizardlm2:7b | Fold-0 | 3-shot: 100%|██████████| 300/300 [00:31<00:00,  9.48req/s]\n",
      "wizardlm2:7b | Fold-0 | 5-shot: 100%|██████████| 300/300 [00:34<00:00,  8.70req/s]\n",
      "wizardlm2:7b | Fold-0 | 7-shot: 100%|██████████| 300/300 [00:33<00:00,  9.05req/s]\n",
      "wizardlm2:7b | Fold-1 | 1-shot: 100%|██████████| 300/300 [00:32<00:00,  9.27req/s]\n",
      "wizardlm2:7b | Fold-1 | 3-shot: 100%|██████████| 300/300 [00:35<00:00,  8.41req/s]\n",
      "wizardlm2:7b | Fold-1 | 5-shot: 100%|██████████| 300/300 [00:31<00:00,  9.54req/s]\n",
      "wizardlm2:7b | Fold-1 | 7-shot: 100%|██████████| 300/300 [00:36<00:00,  8.11req/s]\n",
      "wizardlm2:7b | Fold-2 | 1-shot: 100%|██████████| 300/300 [00:34<00:00,  8.78req/s]\n",
      "wizardlm2:7b | Fold-2 | 3-shot: 100%|██████████| 300/300 [00:31<00:00,  9.64req/s]\n",
      "wizardlm2:7b | Fold-2 | 5-shot: 100%|██████████| 300/300 [00:33<00:00,  9.02req/s]\n",
      "wizardlm2:7b | Fold-2 | 7-shot: 100%|██████████| 300/300 [00:36<00:00,  8.17req/s]\n",
      "wizardlm2:7b | Fold-3 | 1-shot: 100%|██████████| 300/300 [00:33<00:00,  9.05req/s]\n",
      "wizardlm2:7b | Fold-3 | 3-shot: 100%|██████████| 300/300 [00:35<00:00,  8.53req/s]\n",
      "wizardlm2:7b | Fold-3 | 5-shot: 100%|██████████| 300/300 [00:35<00:00,  8.57req/s]\n",
      "wizardlm2:7b | Fold-3 | 7-shot: 100%|██████████| 300/300 [00:38<00:00,  7.78req/s]\n",
      "wizardlm2:7b | Fold-4 | 1-shot: 100%|██████████| 300/300 [00:31<00:00,  9.49req/s]\n",
      "wizardlm2:7b | Fold-4 | 3-shot: 100%|██████████| 300/300 [00:30<00:00,  9.91req/s]\n",
      "wizardlm2:7b | Fold-4 | 5-shot: 100%|██████████| 300/300 [00:31<00:00,  9.50req/s]\n",
      "wizardlm2:7b | Fold-4 | 7-shot: 100%|██████████| 300/300 [00:30<00:00,  9.75req/s]\n",
      "wizardlm2:7b | Fold-5 | 1-shot: 100%|██████████| 300/300 [00:27<00:00, 10.89req/s]\n",
      "wizardlm2:7b | Fold-5 | 3-shot: 100%|██████████| 300/300 [00:34<00:00,  8.79req/s]\n",
      "wizardlm2:7b | Fold-5 | 5-shot: 100%|██████████| 300/300 [00:32<00:00,  9.26req/s]\n",
      "wizardlm2:7b | Fold-5 | 7-shot: 100%|██████████| 300/300 [00:34<00:00,  8.72req/s]\n",
      "wizardlm2:7b | Fold-6 | 1-shot: 100%|██████████| 300/300 [00:33<00:00,  8.88req/s]\n",
      "wizardlm2:7b | Fold-6 | 3-shot: 100%|██████████| 300/300 [00:31<00:00,  9.57req/s]\n",
      "wizardlm2:7b | Fold-6 | 5-shot: 100%|██████████| 300/300 [00:31<00:00,  9.40req/s]\n",
      "wizardlm2:7b | Fold-6 | 7-shot: 100%|██████████| 300/300 [00:35<00:00,  8.39req/s]\n",
      "wizardlm2:7b | Fold-7 | 1-shot: 100%|██████████| 300/300 [00:30<00:00,  9.82req/s]\n",
      "wizardlm2:7b | Fold-7 | 3-shot: 100%|██████████| 300/300 [00:34<00:00,  8.70req/s]\n",
      "wizardlm2:7b | Fold-7 | 5-shot: 100%|██████████| 300/300 [00:32<00:00,  9.20req/s]\n",
      "wizardlm2:7b | Fold-7 | 7-shot: 100%|██████████| 300/300 [00:35<00:00,  8.51req/s]\n",
      "wizardlm2:7b | Fold-8 | 1-shot: 100%|██████████| 300/300 [00:33<00:00,  9.09req/s]\n",
      "wizardlm2:7b | Fold-8 | 3-shot: 100%|██████████| 300/300 [00:35<00:00,  8.39req/s]\n",
      "wizardlm2:7b | Fold-8 | 5-shot: 100%|██████████| 300/300 [00:35<00:00,  8.57req/s]\n",
      "wizardlm2:7b | Fold-8 | 7-shot: 100%|██████████| 300/300 [00:34<00:00,  8.73req/s]\n",
      "wizardlm2:7b | Fold-9 | 1-shot: 100%|██████████| 300/300 [00:32<00:00,  9.33req/s]\n",
      "wizardlm2:7b | Fold-9 | 3-shot: 100%|██████████| 300/300 [00:30<00:00,  9.72req/s]\n",
      "wizardlm2:7b | Fold-9 | 5-shot: 100%|██████████| 300/300 [00:35<00:00,  8.36req/s]\n",
      "wizardlm2:7b | Fold-9 | 7-shot: 100%|██████████| 300/300 [00:35<00:00,  8.43req/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ wizardlm2:7b few-shot evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#scalab_few_shots\n",
    "# run_few_shot_all_models.py\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "DATASET_NAME = \"scalabrino\"\n",
    "FOLD_DIR = f\"stratified_splits_80_10_10/{DATASET_NAME}\"\n",
    "K_VALUES = [1, 3, 5, 7]\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "LABEL_LIST = [\n",
    "    \"BUG\",\n",
    "    \"FEATURE\",\n",
    "    \"PERFORMANCE\",\n",
    "    \"ENERGY\",\n",
    "    \"OTHER\",\n",
    "    \"SECURITY\",\n",
    "    \"USABILITY\",\n",
    "]\n",
    "\n",
    "OLLAMA_MODELS = [\n",
    "   \n",
    "\n",
    "    \"gemma3:4b\",\n",
    "    \"wizardlm2:7b\"\n",
    "]\n",
    "\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"You are a requirement classification assistant.\\n\"\n",
    "    \"Your task is to classify a user review into ONE of the following four categories:\\n\\n\"\n",
    "    \"- Feature Request: suggestions or desires for new features, functionality, or improvements. \"\n",
    "    \"Often uses words like 'add', 'should have', 'need', 'wish', 'please include'.\\n\"\n",
    "    \"- Rating: numeric scores (e.g. 5 stars) or general feedback like 'great app' or 'bad service' without \"\n",
    "    \"any specific details.\\n\"\n",
    "    \"- User Experience: opinions about usability, speed, UI, navigation, or general interaction quality. \"\n",
    "    \"Might mention design, slow loading, or ease of use.\\n\"\n",
    "    \"- Problem Discovery: reports of bugs, crashes, errors, or issues. Often contains words like \"\n",
    "    \"'doesn't work', 'crash', 'bug', 'problem', 'error'.\\n\\n\"\n",
    "    \"{examples_section}\"\n",
    "    \"Return ONLY the label name, no explanation.\\n\\n\"\n",
    "    \"Review: {req_text}\\n\"\n",
    "    \"Label:\"\n",
    "\n",
    ")\n",
    "\n",
    "# =============== HELPERS ===============\n",
    "def build_examples(df):\n",
    "    return \"\\n\".join(f\"{row.review} , {row['class']}\" for _, row in df.iterrows())\n",
    "\n",
    "def call_llm(llm, prompt: str) -> str:\n",
    "    return llm.invoke(prompt).strip()\n",
    "\n",
    "def extract_label(response: str, labels: list[str]) -> str:\n",
    "    rl = response.lower()\n",
    "    for lab in labels:\n",
    "        if lab.lower() in rl:\n",
    "            return lab\n",
    "    return labels[0]\n",
    "\n",
    "def k_examples_per_class(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    return (\n",
    "        df.assign(len=df.review.str.len())\n",
    "          .sort_values(\"len\")\n",
    "          .groupby(\"class\", group_keys=False)\n",
    "          .head(k)\n",
    "          .drop(columns=\"len\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# =============== MAIN ===============\n",
    "for model_name in OLLAMA_MODELS:\n",
    "    MODEL_CLEAN = model_name.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "    OUT_DIR = f\"few_shot_folds_{MODEL_CLEAN}_{DATASET_NAME}\"\n",
    "    PRED_DIR = os.path.join(OUT_DIR, \"preds\")\n",
    "    os.makedirs(PRED_DIR, exist_ok=True)\n",
    "\n",
    "    llm = OllamaLLM(model=model_name)\n",
    "\n",
    "    all_metrics = []\n",
    "    summary_rows = []\n",
    "\n",
    "    for fold in range(10):\n",
    "        test_path = os.path.join(FOLD_DIR, f\"test_fold_{fold}.csv\")\n",
    "        train_path = os.path.join(FOLD_DIR, f\"train_fold_{fold}.csv\")\n",
    "        test_df = pd.read_csv(test_path).reset_index(drop=True)\n",
    "        train_df = pd.read_csv(train_path).reset_index(drop=True)\n",
    "\n",
    "        labels = sorted(train_df[\"class\"].unique())\n",
    "\n",
    "        for k in K_VALUES:\n",
    "            fewshot_df = k_examples_per_class(train_df, k)\n",
    "            example_block = build_examples(fewshot_df)\n",
    "            examples_section = f\"Here are {k} examples (text , class):\\n{example_block}\\n\\n\"\n",
    "\n",
    "            y_true, preds = [], []\n",
    "\n",
    "            for _, row in tqdm(test_df.iterrows(), total=len(test_df),\n",
    "                               desc=f\"{model_name} | Fold-{fold} | {k}-shot\", unit=\"req\"):\n",
    "\n",
    "                prompt = PROMPT_TEMPLATE.format(\n",
    "                    examples_section=examples_section,\n",
    "                    req_text=row.review\n",
    "                )\n",
    "\n",
    "                resp = call_llm(llm, prompt)\n",
    "                pred = extract_label(resp, labels)\n",
    "                y_true.append(row[\"class\"])\n",
    "                preds.append(pred)\n",
    "\n",
    "            # ─── METRICS ──────────────────────────────\n",
    "            macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"macro\", zero_division=0)\n",
    "            micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"micro\", zero_division=0)\n",
    "            weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(\n",
    "                y_true, preds, labels=labels, average=\"weighted\", zero_division=0)\n",
    "\n",
    "            # ─── SAVE PREDICTIONS ─────────────────────\n",
    "            pd.DataFrame({\n",
    "                \"text\": test_df.review,\n",
    "                \"gold\": y_true,\n",
    "                \"pred\": preds\n",
    "            }).to_csv(\n",
    "                os.path.join(PRED_DIR, f\"{DATASET_NAME}_fold{fold}_{k}shot_preds.csv\"),\n",
    "                index=False, encoding=\"utf-8\"\n",
    "            )\n",
    "\n",
    "            # ─── RECORD METRICS ───────────────────────\n",
    "            summary_rows.append({\n",
    "                \"dataset\": DATASET_NAME,\n",
    "                \"model\": model_name,\n",
    "                \"fold\": fold,\n",
    "                \"k_shot\": k,\n",
    "                \"macro_f1\": macro_f1,\n",
    "                \"micro_f1\": micro_f1,\n",
    "                \"weighted_f1\": weighted_f1\n",
    "            })\n",
    "\n",
    "            for i, lab in enumerate(labels):\n",
    "                all_metrics.append({\n",
    "                    \"dataset\": DATASET_NAME,\n",
    "                    \"model\": model_name,\n",
    "                    \"fold\": fold,\n",
    "                    \"k_shot\": k,\n",
    "                    \"class_label\": lab,\n",
    "                    \"macro_f1\": macro_f1,\n",
    "                    \"micro_f1\": micro_f1,\n",
    "                    \"weighted_f1\": weighted_f1,\n",
    "                })\n",
    "\n",
    "    # ─── SAVE RESULTS ───────────────────────────────\n",
    "    pd.DataFrame(summary_rows).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{DATASET_NAME}_fewshot_folded_summary.csv\"),\n",
    "        index=False, encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    pd.DataFrame(all_metrics).to_csv(\n",
    "        os.path.join(OUT_DIR, f\"{DATASET_NAME}_fewshot_all_metrics.csv\"),\n",
    "        index=False, encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✅ {model_name} few-shot evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c860a891-c4c6-4f18-98db-8e387d23a6c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F1 scores for all configurations...\n",
      "Expected zero-shot path format: zero_shot_folds_MODEL_NAME/preds/DATASET_foldN_preds.csv\n",
      "Expected few-shot path format: few_shot_folds_MODEL_NAME_DATASET/preds/DATASET_foldN_Nshot_preds.csv\n",
      "\n",
      "==================================================\n",
      "Processing model: llama3_8b\n",
      "==================================================\n",
      "\n",
      "Processing ZERO-SHOT for llama3_8b:\n",
      "\n",
      "  Dataset: pan\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/pan_fold0_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.7248, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/pan_fold1_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.6443, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/pan_fold2_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.6368, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/pan_fold3_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.6978, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/pan_fold4_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.7600, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/pan_fold5_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.7095, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/pan_fold6_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.5746, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/pan_fold7_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.6761, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/pan_fold8_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.6424, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/pan_fold9_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.6338, samples=139\n",
      "  pan ZERO-SHOT: Avg F1=0.6700 (from 10 folds)\n",
      "\n",
      "  Dataset: maalej\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/maalej_fold0_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.3791, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/maalej_fold1_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.2997, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/maalej_fold2_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.3403, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/maalej_fold3_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.3463, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/maalej_fold4_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.3165, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/maalej_fold5_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.3688, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/maalej_fold6_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.3229, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/maalej_fold7_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.3351, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/maalej_fold8_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.3525, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/maalej_fold9_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.3368, samples=370\n",
      "  maalej ZERO-SHOT: Avg F1=0.3398 (from 10 folds)\n",
      "\n",
      "  Dataset: scalabrino\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/scalabrino_fold0_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.5761, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/scalabrino_fold1_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.5240, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/scalabrino_fold2_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.6350, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/scalabrino_fold3_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.5114, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/scalabrino_fold4_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.5527, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/scalabrino_fold5_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.5321, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/scalabrino_fold6_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.5703, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/scalabrino_fold7_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.4900, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/scalabrino_fold8_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.5954, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_8b/preds/scalabrino_fold9_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.5297, samples=300\n",
      "  scalabrino ZERO-SHOT: Avg F1=0.5517 (from 10 folds)\n",
      "\n",
      "Processing FEW-SHOT for llama3_8b:\n",
      "\n",
      "  1-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.7311, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.6851, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6681, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.6668, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7057, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7659, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.5973, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.6951, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7403, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6444, samples=139\n",
      "    pan: Avg F1=0.6900 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.3341, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.2921, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.3157, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.3568, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.3153, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.3784, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.3662, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.3563, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.3745, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.3677, samples=370\n",
      "    maalej: Avg F1=0.3457 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.4531, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.4237, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.4440, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.4212, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.4121, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.4490, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.4741, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.3447, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.3496, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.3968, samples=300\n",
      "    scalabrino: Avg F1=0.4168 (from 10 folds)\n",
      "\n",
      "  3-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.7496, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.6872, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6742, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.6536, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7252, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7683, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.5894, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7443, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7354, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6375, samples=139\n",
      "    pan: Avg F1=0.6965 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.4013, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.3708, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.3868, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.3727, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.3485, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.3713, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.4205, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.3510, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.3888, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.3473, samples=370\n",
      "    maalej: Avg F1=0.3759 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.4940, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.4822, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.5215, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.5264, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.4625, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.4877, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.4532, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.4217, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.5114, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.4947, samples=300\n",
      "    scalabrino: Avg F1=0.4855 (from 10 folds)\n",
      "\n",
      "  5-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.7587, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.6664, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6481, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.6894, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7400, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7614, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6599, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7354, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7428, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6600, samples=139\n",
      "    pan: Avg F1=0.7062 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.4371, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.4458, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.4133, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.4422, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.3457, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.3912, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.4450, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.3401, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.4111, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.3809, samples=370\n",
      "    maalej: Avg F1=0.4052 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.5544, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.4878, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.5588, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.5671, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.4875, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.5140, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.4763, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.4661, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.5697, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.5006, samples=300\n",
      "    scalabrino: Avg F1=0.5182 (from 10 folds)\n",
      "\n",
      "  7-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.7405, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.6596, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6412, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7055, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7549, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7371, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6535, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7265, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7830, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_pan/preds/pan_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6731, samples=139\n",
      "    pan: Avg F1=0.7075 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.4649, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.4573, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.4318, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.4395, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.3620, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.4674, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.4436, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.3937, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.4000, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_maalej/preds/maalej_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.3806, samples=370\n",
      "    maalej: Avg F1=0.4241 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.5565, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.4648, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.6094, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.5333, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.4928, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.5697, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.4867, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.5100, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.5539, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_8b_scalabrino/preds/scalabrino_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.5485, samples=300\n",
      "    scalabrino: Avg F1=0.5326 (from 10 folds)\n",
      "\n",
      "==================================================\n",
      "Processing model: llama3_70b\n",
      "==================================================\n",
      "\n",
      "Processing ZERO-SHOT for llama3_70b:\n",
      "\n",
      "  Dataset: pan\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/pan_fold0_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.8311, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/pan_fold1_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.6889, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/pan_fold2_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.6954, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/pan_fold3_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.7522, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/pan_fold4_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.7812, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/pan_fold5_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.7691, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/pan_fold6_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.6799, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/pan_fold7_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.7175, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/pan_fold8_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.7382, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/pan_fold9_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.6859, samples=139\n",
      "  pan ZERO-SHOT: Avg F1=0.7339 (from 10 folds)\n",
      "\n",
      "  Dataset: maalej\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/maalej_fold0_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.4853, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/maalej_fold1_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.4469, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/maalej_fold2_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.4654, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/maalej_fold3_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.4828, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/maalej_fold4_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.4437, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/maalej_fold5_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.4616, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/maalej_fold6_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.4772, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/maalej_fold7_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.4667, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/maalej_fold8_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.4454, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/maalej_fold9_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.4760, samples=370\n",
      "  maalej ZERO-SHOT: Avg F1=0.4651 (from 10 folds)\n",
      "\n",
      "  Dataset: scalabrino\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/scalabrino_fold0_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.5727, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/scalabrino_fold1_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.5455, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/scalabrino_fold2_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.5425, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/scalabrino_fold3_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.5504, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/scalabrino_fold4_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.5592, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/scalabrino_fold5_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.5384, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/scalabrino_fold6_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.5338, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/scalabrino_fold7_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.5118, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/scalabrino_fold8_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.5911, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_llama3_70b/preds/scalabrino_fold9_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.5148, samples=300\n",
      "  scalabrino ZERO-SHOT: Avg F1=0.5460 (from 10 folds)\n",
      "\n",
      "Processing FEW-SHOT for llama3_70b:\n",
      "\n",
      "  1-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.7855, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.6997, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6588, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7564, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.8044, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7373, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6712, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7201, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.6710, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6256, samples=139\n",
      "    pan: Avg F1=0.7130 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.5672, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.4509, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.5177, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.5107, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.4651, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.5275, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.5334, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.4962, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.5140, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.5645, samples=370\n",
      "    maalej: Avg F1=0.5147 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.4257, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.3567, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.4194, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.4168, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.4096, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.3461, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.3534, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.3758, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.4856, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.3534, samples=300\n",
      "    scalabrino: Avg F1=0.3943 (from 10 folds)\n",
      "\n",
      "  3-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.7757, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.7090, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6763, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7777, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.8080, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7298, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6523, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7602, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7112, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6166, samples=139\n",
      "    pan: Avg F1=0.7217 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.5820, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.4750, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.5461, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.5356, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.4712, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.5379, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.5082, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.4926, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.5202, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.5672, samples=370\n",
      "    maalej: Avg F1=0.5236 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.4957, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.3968, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.5408, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.4414, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.4914, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.4383, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.5001, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.3746, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.5684, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.3914, samples=300\n",
      "    scalabrino: Avg F1=0.4639 (from 10 folds)\n",
      "\n",
      "  5-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.8093, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.7061, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6907, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7447, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7731, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7789, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6615, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7421, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7486, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6897, samples=139\n",
      "    pan: Avg F1=0.7345 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.5881, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.4942, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.5417, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.5683, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.4066, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.4887, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.5328, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.4647, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.4902, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.5012, samples=370\n",
      "    maalej: Avg F1=0.5077 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.5838, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.4967, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.5958, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.5608, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.5406, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.5565, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.4988, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.5126, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.6075, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.5391, samples=300\n",
      "    scalabrino: Avg F1=0.5492 (from 10 folds)\n",
      "\n",
      "  7-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.7973, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.7288, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6973, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7265, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7824, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7527, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6759, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7219, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7394, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_pan/preds/pan_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6958, samples=139\n",
      "    pan: Avg F1=0.7318 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.5605, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.4808, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.5176, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.5555, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.4024, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.4889, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.4814, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.4310, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.4962, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_maalej/preds/maalej_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.4607, samples=370\n",
      "    maalej: Avg F1=0.4875 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.6001, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.5292, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.5718, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.6096, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.5660, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.5794, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.5757, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.5169, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.6144, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_llama3_70b_scalabrino/preds/scalabrino_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.6033, samples=300\n",
      "    scalabrino: Avg F1=0.5766 (from 10 folds)\n",
      "\n",
      "==================================================\n",
      "Processing model: mistral_7b\n",
      "==================================================\n",
      "\n",
      "Processing ZERO-SHOT for mistral_7b:\n",
      "\n",
      "  Dataset: pan\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/pan_fold0_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.8125, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/pan_fold1_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.6634, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/pan_fold2_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.7116, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/pan_fold3_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.7567, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/pan_fold4_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.7962, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/pan_fold5_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.7430, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/pan_fold6_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.6270, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/pan_fold7_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.7090, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/pan_fold8_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.6793, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/pan_fold9_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.7087, samples=139\n",
      "  pan ZERO-SHOT: Avg F1=0.7207 (from 10 folds)\n",
      "\n",
      "  Dataset: maalej\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/maalej_fold0_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.4828, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/maalej_fold1_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.4179, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/maalej_fold2_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.4494, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/maalej_fold3_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.4535, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/maalej_fold4_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.3700, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/maalej_fold5_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.4893, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/maalej_fold6_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.4611, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/maalej_fold7_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.4539, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/maalej_fold8_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.4541, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/maalej_fold9_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.4671, samples=370\n",
      "  maalej ZERO-SHOT: Avg F1=0.4499 (from 10 folds)\n",
      "\n",
      "  Dataset: scalabrino\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/scalabrino_fold0_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.3907, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/scalabrino_fold1_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.3307, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/scalabrino_fold2_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.4253, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/scalabrino_fold3_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.3928, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/scalabrino_fold4_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.3916, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/scalabrino_fold5_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.4307, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/scalabrino_fold6_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.4281, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/scalabrino_fold7_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.3808, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/scalabrino_fold8_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.4126, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_mistral_7b/preds/scalabrino_fold9_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.4147, samples=300\n",
      "  scalabrino ZERO-SHOT: Avg F1=0.3998 (from 10 folds)\n",
      "\n",
      "Processing FEW-SHOT for mistral_7b:\n",
      "\n",
      "  1-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.8146, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.7218, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6434, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.8009, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7604, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7293, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6531, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7204, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7119, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.7033, samples=139\n",
      "    pan: Avg F1=0.7259 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.3419, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.3872, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.3974, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.3601, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.2549, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.2875, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.2674, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.2795, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.2873, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.3014, samples=370\n",
      "    maalej: Avg F1=0.3165 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.5084, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.4398, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.5427, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.4938, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.4613, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.5183, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.4610, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.4691, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.5504, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.4823, samples=300\n",
      "    scalabrino: Avg F1=0.4927 (from 10 folds)\n",
      "\n",
      "  3-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.8328, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.7255, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6257, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7195, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7591, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7673, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6455, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7209, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7003, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6851, samples=139\n",
      "    pan: Avg F1=0.7182 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.3455, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.3478, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.3396, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.3873, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.3038, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.2751, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.3351, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.3231, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.3551, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.3247, samples=370\n",
      "    maalej: Avg F1=0.3337 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.5461, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.6279, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.7112, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.5925, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.6572, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.6438, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.5771, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.6035, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.6601, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.6211, samples=300\n",
      "    scalabrino: Avg F1=0.6241 (from 10 folds)\n",
      "\n",
      "  5-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.8614, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.7303, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6621, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7555, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7722, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7959, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6437, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7402, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7416, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6749, samples=139\n",
      "    pan: Avg F1=0.7378 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.3870, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.3768, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.3497, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.3684, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.2927, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.3181, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.3189, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.3105, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.3481, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.3164, samples=370\n",
      "    maalej: Avg F1=0.3387 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.6200, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.5725, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.6978, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.5984, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.5943, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.6238, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.5965, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.6167, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.6999, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.6295, samples=300\n",
      "    scalabrino: Avg F1=0.6249 (from 10 folds)\n",
      "\n",
      "  7-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.8443, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.7072, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6358, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7645, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.8277, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7491, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6284, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7262, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7181, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_pan/preds/pan_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6306, samples=139\n",
      "    pan: Avg F1=0.7232 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.4009, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.3648, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.3481, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.3631, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.3218, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.3410, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.3259, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.3282, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.3499, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_maalej/preds/maalej_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.3368, samples=370\n",
      "    maalej: Avg F1=0.3481 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.6643, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.5560, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.6974, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.6305, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.5915, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.6428, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.5847, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.6121, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.6935, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_mistral_7b_scalabrino/preds/scalabrino_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.6252, samples=300\n",
      "    scalabrino: Avg F1=0.6298 (from 10 folds)\n",
      "\n",
      "==================================================\n",
      "Processing model: gemma3_4b\n",
      "==================================================\n",
      "\n",
      "Processing ZERO-SHOT for gemma3_4b:\n",
      "\n",
      "  Dataset: pan\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/pan_fold0_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.7083, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/pan_fold1_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.6641, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/pan_fold2_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.5362, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/pan_fold3_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.7199, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/pan_fold4_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.7053, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/pan_fold5_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.6893, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/pan_fold6_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.6011, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/pan_fold7_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.6687, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/pan_fold8_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.6509, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/pan_fold9_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.6245, samples=139\n",
      "  pan ZERO-SHOT: Avg F1=0.6568 (from 10 folds)\n",
      "\n",
      "  Dataset: maalej\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/maalej_fold0_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.4660, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/maalej_fold1_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.4284, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/maalej_fold2_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.4456, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/maalej_fold3_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.4498, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/maalej_fold4_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.4114, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/maalej_fold5_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.4273, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/maalej_fold6_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.4644, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/maalej_fold7_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.4505, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/maalej_fold8_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.4445, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/maalej_fold9_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.4607, samples=370\n",
      "  maalej ZERO-SHOT: Avg F1=0.4449 (from 10 folds)\n",
      "\n",
      "  Dataset: scalabrino\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/scalabrino_fold0_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.5183, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/scalabrino_fold1_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.4819, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/scalabrino_fold2_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.5534, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/scalabrino_fold3_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.5236, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/scalabrino_fold4_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.5064, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/scalabrino_fold5_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.5015, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/scalabrino_fold6_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.5347, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/scalabrino_fold7_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.4867, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/scalabrino_fold8_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.5143, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_gemma3_4b/preds/scalabrino_fold9_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.4980, samples=300\n",
      "  scalabrino ZERO-SHOT: Avg F1=0.5119 (from 10 folds)\n",
      "\n",
      "Processing FEW-SHOT for gemma3_4b:\n",
      "\n",
      "  1-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.7151, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.6786, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6385, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7548, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7550, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7299, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6289, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7681, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.6760, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6241, samples=139\n",
      "    pan: Avg F1=0.6969 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.5010, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.4435, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.4711, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.4842, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.4132, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.4305, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.4346, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.4219, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.4410, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.4715, samples=370\n",
      "    maalej: Avg F1=0.4513 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.3579, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.4414, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.4712, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.4003, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.4047, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.5438, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.4224, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.4103, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.4699, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.4891, samples=300\n",
      "    scalabrino: Avg F1=0.4411 (from 10 folds)\n",
      "\n",
      "  3-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.7896, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.6929, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6555, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7945, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7939, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7707, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6457, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7587, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.6729, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6517, samples=139\n",
      "    pan: Avg F1=0.7226 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.4635, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.3616, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.4054, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.3872, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.3986, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.3059, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.2450, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.3061, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.2761, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.3645, samples=370\n",
      "    maalej: Avg F1=0.3514 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.6064, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.6156, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.6546, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.6759, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.6338, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.6611, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.5609, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.5757, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.6258, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.6680, samples=300\n",
      "    scalabrino: Avg F1=0.6278 (from 10 folds)\n",
      "\n",
      "  5-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.8139, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.6807, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6973, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7811, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.8135, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7409, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6596, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7371, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7193, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6793, samples=139\n",
      "    pan: Avg F1=0.7323 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.3628, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.3329, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.3242, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.3980, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.3468, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.3729, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.3683, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.3875, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.3501, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.3988, samples=370\n",
      "    maalej: Avg F1=0.3642 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.7059, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.5884, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.7104, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.7127, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.6608, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.6815, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.6591, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.6314, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.7327, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.7024, samples=300\n",
      "    scalabrino: Avg F1=0.6785 (from 10 folds)\n",
      "\n",
      "  7-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.7736, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.6990, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6405, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7723, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.8125, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7360, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6503, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.7658, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7061, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_pan/preds/pan_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6749, samples=139\n",
      "    pan: Avg F1=0.7231 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.3600, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.3639, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.3084, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.3701, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.3290, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.3900, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.3501, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.3352, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.3409, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_maalej/preds/maalej_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.4310, samples=370\n",
      "    maalej: Avg F1=0.3579 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.7139, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.6069, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.7265, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.7086, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.6516, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.6879, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.7154, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.6441, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.7070, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_gemma3_4b_scalabrino/preds/scalabrino_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.6845, samples=300\n",
      "    scalabrino: Avg F1=0.6846 (from 10 folds)\n",
      "\n",
      "==================================================\n",
      "Processing model: wizardlm2_7b\n",
      "==================================================\n",
      "\n",
      "Processing ZERO-SHOT for wizardlm2_7b:\n",
      "\n",
      "  Dataset: pan\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/pan_fold0_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.7209, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/pan_fold1_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.6492, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/pan_fold2_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.6060, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/pan_fold3_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.6403, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/pan_fold4_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.7705, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/pan_fold5_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.6714, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/pan_fold6_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.6112, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/pan_fold7_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.6577, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/pan_fold8_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.6410, samples=139\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/pan_fold9_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.6259, samples=139\n",
      "  pan ZERO-SHOT: Avg F1=0.6594 (from 10 folds)\n",
      "\n",
      "  Dataset: maalej\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/maalej_fold0_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.4391, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/maalej_fold1_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.3837, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/maalej_fold2_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.3983, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/maalej_fold3_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.4384, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/maalej_fold4_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.3858, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/maalej_fold5_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.4169, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/maalej_fold6_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.4014, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/maalej_fold7_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.3692, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/maalej_fold8_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.3718, samples=370\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/maalej_fold9_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.4283, samples=370\n",
      "  maalej ZERO-SHOT: Avg F1=0.4033 (from 10 folds)\n",
      "\n",
      "  Dataset: scalabrino\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/scalabrino_fold0_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 0: F1=0.4836, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/scalabrino_fold1_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 1: F1=0.5011, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/scalabrino_fold2_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 2: F1=0.5108, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/scalabrino_fold3_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 3: F1=0.4946, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/scalabrino_fold4_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 4: F1=0.4135, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/scalabrino_fold5_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 5: F1=0.4631, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/scalabrino_fold6_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 6: F1=0.4986, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/scalabrino_fold7_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 7: F1=0.3682, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/scalabrino_fold8_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 8: F1=0.5238, samples=300\n",
      "ZERO-SHOT PATH: zero_shot_folds_wizardlm2_7b/preds/scalabrino_fold9_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['id', 'text', 'gold', 'pred']\n",
      "    Fold 9: F1=0.4817, samples=300\n",
      "  scalabrino ZERO-SHOT: Avg F1=0.4739 (from 10 folds)\n",
      "\n",
      "Processing FEW-SHOT for wizardlm2_7b:\n",
      "\n",
      "  1-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.6965, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.6191, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.5723, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.6724, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7317, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.6418, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.5871, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.6254, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.5893, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6439, samples=139\n",
      "    pan: Avg F1=0.6379 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.3291, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.3097, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.3292, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.3499, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.2509, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.3181, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.2892, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.2732, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.2673, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.2814, samples=370\n",
      "    maalej: Avg F1=0.2998 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold0_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.2761, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold1_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.3461, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold2_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.2872, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold3_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.2354, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold4_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.3432, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold5_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.2080, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold6_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.3401, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold7_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.2505, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold8_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.3086, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold9_1shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.3484, samples=300\n",
      "    scalabrino: Avg F1=0.2944 (from 10 folds)\n",
      "\n",
      "  3-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.7460, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.6217, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6317, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7389, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7855, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7506, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6100, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.6789, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.6884, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6382, samples=139\n",
      "    pan: Avg F1=0.6890 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.3876, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.3655, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.3905, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.4229, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.3596, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.3937, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.4158, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.3640, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.3511, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.4008, samples=370\n",
      "    maalej: Avg F1=0.3851 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold0_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.4816, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold1_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.4879, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold2_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.4890, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold3_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.4775, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold4_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.5080, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold5_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.5240, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold6_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.4724, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold7_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.5393, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold8_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.5265, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold9_3shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.4324, samples=300\n",
      "    scalabrino: Avg F1=0.4938 (from 10 folds)\n",
      "\n",
      "  5-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.8097, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.6683, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6967, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7143, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.7850, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7546, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6310, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.6987, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7065, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.5996, samples=139\n",
      "    pan: Avg F1=0.7065 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.4119, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.4216, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.4352, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.4644, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.3720, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.4055, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.4105, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.3412, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.3522, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.4066, samples=370\n",
      "    maalej: Avg F1=0.4021 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold0_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.4264, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold1_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.4663, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold2_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.5921, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold3_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.5227, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold4_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.4733, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold5_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.5596, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold6_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.4407, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold7_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.5525, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold8_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.6119, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold9_5shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.5593, samples=300\n",
      "    scalabrino: Avg F1=0.5205 (from 10 folds)\n",
      "\n",
      "  7-shot:\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 0: F1=0.7912, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 1: F1=0.6580, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 2: F1=0.6310, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 3: F1=0.7166, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 4: F1=0.6738, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 5: F1=0.7734, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 6: F1=0.6278, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 7: F1=0.6885, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 8: F1=0.7096, samples=139\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_pan/preds/pan_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 139 rows, columns: ['text', 'gold', 'pred']\n",
      "    pan Fold 9: F1=0.6780, samples=139\n",
      "    pan: Avg F1=0.6948 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 0: F1=0.4168, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 1: F1=0.3760, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 2: F1=0.4022, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 3: F1=0.4191, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 4: F1=0.3534, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 5: F1=0.4353, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 6: F1=0.3593, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 7: F1=0.3182, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 8: F1=0.3607, samples=370\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_maalej/preds/maalej_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 370 rows, columns: ['text', 'gold', 'pred']\n",
      "    maalej Fold 9: F1=0.4013, samples=370\n",
      "    maalej: Avg F1=0.3842 (from 10 folds)\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold0_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 0: F1=0.4934, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold1_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 1: F1=0.5276, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold2_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 2: F1=0.6516, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold3_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 3: F1=0.4704, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold4_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 4: F1=0.4963, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold5_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 5: F1=0.5765, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold6_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 6: F1=0.5057, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold7_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 7: F1=0.4742, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold8_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 8: F1=0.5817, samples=300\n",
      "FEW-SHOT PATH: few_shot_folds_wizardlm2_7b_scalabrino/preds/scalabrino_fold9_7shot_preds.csv\n",
      "SUCCESS: Loaded 300 rows, columns: ['text', 'gold', 'pred']\n",
      "    scalabrino Fold 9: F1=0.6434, samples=300\n",
      "    scalabrino: Avg F1=0.5421 (from 10 folds)\n",
      "\n",
      "DEBUG: Results DataFrame shape: (75, 6)\n",
      "DEBUG: Available combinations:\n",
      "         model shot_config     dataset    avg_f1\n",
      "0    llama3_8b      0-shot         pan  0.669998\n",
      "1    llama3_8b      0-shot      maalej  0.339793\n",
      "2    llama3_8b      0-shot  scalabrino  0.551665\n",
      "3    llama3_8b      1-shot         pan  0.689994\n",
      "4    llama3_8b      1-shot      maalej  0.345710\n",
      "5    llama3_8b      1-shot  scalabrino  0.416843\n",
      "6    llama3_8b      3-shot         pan  0.696473\n",
      "7    llama3_8b      3-shot      maalej  0.375892\n",
      "8    llama3_8b      3-shot  scalabrino  0.485539\n",
      "9    llama3_8b      5-shot         pan  0.706190\n",
      "10   llama3_8b      5-shot      maalej  0.405244\n",
      "11   llama3_8b      5-shot  scalabrino  0.518231\n",
      "12   llama3_8b      7-shot         pan  0.707496\n",
      "13   llama3_8b      7-shot      maalej  0.424075\n",
      "14   llama3_8b      7-shot  scalabrino  0.532560\n",
      "15  llama3_70b      0-shot         pan  0.733925\n",
      "16  llama3_70b      0-shot      maalej  0.465098\n",
      "17  llama3_70b      0-shot  scalabrino  0.546003\n",
      "18  llama3_70b      1-shot         pan  0.713000\n",
      "19  llama3_70b      1-shot      maalej  0.514725\n",
      "\n",
      "Creating Excel-style table...\n",
      "DEBUG: llama3_8b pan 0-shot = 0.670\n",
      "DEBUG: llama3_8b pan 1-shot = 0.690\n",
      "DEBUG: llama3_8b pan 3-shot = 0.696\n",
      "DEBUG: llama3_8b pan 5-shot = 0.706\n",
      "DEBUG: llama3_8b pan 7-shot = 0.707\n",
      "DEBUG: llama3_8b maalej 0-shot = 0.340\n",
      "DEBUG: llama3_8b maalej 1-shot = 0.346\n",
      "DEBUG: llama3_8b maalej 3-shot = 0.376\n",
      "DEBUG: llama3_8b maalej 5-shot = 0.405\n",
      "DEBUG: llama3_8b maalej 7-shot = 0.424\n",
      "DEBUG: llama3_8b scalabrino 0-shot = 0.552\n",
      "DEBUG: llama3_8b scalabrino 1-shot = 0.417\n",
      "DEBUG: llama3_8b scalabrino 3-shot = 0.486\n",
      "DEBUG: llama3_8b scalabrino 5-shot = 0.518\n",
      "DEBUG: llama3_8b scalabrino 7-shot = 0.533\n",
      "DEBUG: llama3_70b pan 0-shot = 0.734\n",
      "DEBUG: llama3_70b pan 1-shot = 0.713\n",
      "DEBUG: llama3_70b pan 3-shot = 0.722\n",
      "DEBUG: llama3_70b pan 5-shot = 0.734\n",
      "DEBUG: llama3_70b pan 7-shot = 0.732\n",
      "DEBUG: llama3_70b maalej 0-shot = 0.465\n",
      "DEBUG: llama3_70b maalej 1-shot = 0.515\n",
      "DEBUG: llama3_70b maalej 3-shot = 0.524\n",
      "DEBUG: llama3_70b maalej 5-shot = 0.508\n",
      "DEBUG: llama3_70b maalej 7-shot = 0.487\n",
      "DEBUG: llama3_70b scalabrino 0-shot = 0.546\n",
      "DEBUG: llama3_70b scalabrino 1-shot = 0.394\n",
      "DEBUG: llama3_70b scalabrino 3-shot = 0.464\n",
      "DEBUG: llama3_70b scalabrino 5-shot = 0.549\n",
      "DEBUG: llama3_70b scalabrino 7-shot = 0.577\n",
      "DEBUG: mistral_7b pan 0-shot = 0.721\n",
      "DEBUG: mistral_7b pan 1-shot = 0.726\n",
      "DEBUG: mistral_7b pan 3-shot = 0.718\n",
      "DEBUG: mistral_7b pan 5-shot = 0.738\n",
      "DEBUG: mistral_7b pan 7-shot = 0.723\n",
      "DEBUG: mistral_7b maalej 0-shot = 0.450\n",
      "DEBUG: mistral_7b maalej 1-shot = 0.316\n",
      "DEBUG: mistral_7b maalej 3-shot = 0.334\n",
      "DEBUG: mistral_7b maalej 5-shot = 0.339\n",
      "DEBUG: mistral_7b maalej 7-shot = 0.348\n",
      "DEBUG: mistral_7b scalabrino 0-shot = 0.400\n",
      "DEBUG: mistral_7b scalabrino 1-shot = 0.493\n",
      "DEBUG: mistral_7b scalabrino 3-shot = 0.624\n",
      "DEBUG: mistral_7b scalabrino 5-shot = 0.625\n",
      "DEBUG: mistral_7b scalabrino 7-shot = 0.630\n",
      "DEBUG: gemma3_4b pan 0-shot = 0.657\n",
      "DEBUG: gemma3_4b pan 1-shot = 0.697\n",
      "DEBUG: gemma3_4b pan 3-shot = 0.723\n",
      "DEBUG: gemma3_4b pan 5-shot = 0.732\n",
      "DEBUG: gemma3_4b pan 7-shot = 0.723\n",
      "DEBUG: gemma3_4b maalej 0-shot = 0.445\n",
      "DEBUG: gemma3_4b maalej 1-shot = 0.451\n",
      "DEBUG: gemma3_4b maalej 3-shot = 0.351\n",
      "DEBUG: gemma3_4b maalej 5-shot = 0.364\n",
      "DEBUG: gemma3_4b maalej 7-shot = 0.358\n",
      "DEBUG: gemma3_4b scalabrino 0-shot = 0.512\n",
      "DEBUG: gemma3_4b scalabrino 1-shot = 0.441\n",
      "DEBUG: gemma3_4b scalabrino 3-shot = 0.628\n",
      "DEBUG: gemma3_4b scalabrino 5-shot = 0.679\n",
      "DEBUG: gemma3_4b scalabrino 7-shot = 0.685\n",
      "DEBUG: wizardlm2_7b pan 0-shot = 0.659\n",
      "DEBUG: wizardlm2_7b pan 1-shot = 0.638\n",
      "DEBUG: wizardlm2_7b pan 3-shot = 0.689\n",
      "DEBUG: wizardlm2_7b pan 5-shot = 0.706\n",
      "DEBUG: wizardlm2_7b pan 7-shot = 0.695\n",
      "DEBUG: wizardlm2_7b maalej 0-shot = 0.403\n",
      "DEBUG: wizardlm2_7b maalej 1-shot = 0.300\n",
      "DEBUG: wizardlm2_7b maalej 3-shot = 0.385\n",
      "DEBUG: wizardlm2_7b maalej 5-shot = 0.402\n",
      "DEBUG: wizardlm2_7b maalej 7-shot = 0.384\n",
      "DEBUG: wizardlm2_7b scalabrino 0-shot = 0.474\n",
      "DEBUG: wizardlm2_7b scalabrino 1-shot = 0.294\n",
      "DEBUG: wizardlm2_7b scalabrino 3-shot = 0.494\n",
      "DEBUG: wizardlm2_7b scalabrino 5-shot = 0.520\n",
      "DEBUG: wizardlm2_7b scalabrino 7-shot = 0.542\n",
      "\n",
      "Files created:\n",
      "Excel-style F1 table: f1_analysis/f1_scores_excel_format.csv\n",
      "Excel-style formatted: f1_analysis/f1_scores_excel_format.xlsx\n",
      "Summary F1 scores: f1_analysis/weighted_f1_summary.csv\n",
      "\n",
      "F1 Scores by Model and Dataset:\n",
      "       Model    Dataset  Prompt Template  Zero shot  1 shot  3 shot  5 shot  7 shot\n",
      "   llama3_8b        pan PT 7- definition      0.670   0.690   0.696   0.706   0.707\n",
      "   llama3_8b     maalej PT 7- definition      0.340   0.346   0.376   0.405   0.424\n",
      "   llama3_8b scalabrino PT 7- definition      0.552   0.417   0.486   0.518   0.533\n",
      "  llama3_70b        pan PT 7- definition      0.734   0.713   0.722   0.734   0.732\n",
      "  llama3_70b     maalej PT 7- definition      0.465   0.515   0.524   0.508   0.487\n",
      "  llama3_70b scalabrino PT 7- definition      0.546   0.394   0.464   0.549   0.577\n",
      "  mistral_7b        pan PT 7- definition      0.721   0.726   0.718   0.738   0.723\n",
      "  mistral_7b     maalej PT 7- definition      0.450   0.316   0.334   0.339   0.348\n",
      "  mistral_7b scalabrino PT 7- definition      0.400   0.493   0.624   0.625   0.630\n",
      "   gemma3_4b        pan PT 7- definition      0.657   0.697   0.723   0.732   0.723\n",
      "   gemma3_4b     maalej PT 7- definition      0.445   0.451   0.351   0.364   0.358\n",
      "   gemma3_4b scalabrino PT 7- definition      0.512   0.441   0.628   0.679   0.685\n",
      "wizardlm2_7b        pan PT 7- definition      0.659   0.638   0.689   0.706   0.695\n",
      "wizardlm2_7b     maalej PT 7- definition      0.403   0.300   0.385   0.402   0.384\n",
      "wizardlm2_7b scalabrino PT 7- definition      0.474   0.294   0.494   0.520   0.542\n",
      "\n",
      "Overall Weighted F1 Summary:\n",
      "shot_config   0-shot  1-shot  3-shot  5-shot  7-shot\n",
      "model                                               \n",
      "gemma3_4b     0.5061  0.4897  0.5177  0.5440  0.5418\n",
      "llama3_70b    0.5413  0.5041  0.5355  0.5620  0.5625\n",
      "llama3_8b     0.4751  0.4312  0.4716  0.4989  0.5130\n",
      "mistral_7b    0.4779  0.4522  0.5074  0.5134  0.5170\n",
      "wizardlm2_7b  0.4735  0.3559  0.4777  0.4983  0.4961\n",
      "\n",
      "Top performing configurations:\n",
      "llama3_8b: 7-shot (F1=0.5130)\n",
      "llama3_70b: 7-shot (F1=0.5625)\n",
      "mistral_7b: 7-shot (F1=0.5170)\n",
      "gemma3_4b: 5-shot (F1=0.5440)\n",
      "wizardlm2_7b: 5-shot (F1=0.4983)\n",
      "\n",
      "DEBUG COMPLETE: Check the debug output above to see why zero-shot might be missing.\n"
     ]
    }
   ],
   "source": [
    "#f1 score analysis\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────\n",
    "ZS_PREFIX = \"zero_shot_folds_\"\n",
    "FS_PREFIX = \"few_shot_folds_\"\n",
    "DATASETS = [\"pan\", \"maalej\", \"scalabrino\"]\n",
    "MODELS = [\"llama3_8b\", \"llama3_70b\", \"mistral_7b\", \"gemma3_4b\", \"wizardlm2_7b\"]\n",
    "K_SHOTS = [1, 3, 5, 7]\n",
    "FOLDS = range(10)\n",
    "OUT_DIR = \"f1_analysis\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─── LOAD PREDICTIONS ──────────────────\n",
    "def load_preds(model_name, dataset, fold, shot=None):\n",
    "    if shot is None:\n",
    "        # Zero-shot: all datasets in same folder\n",
    "        path = os.path.join(f\"{ZS_PREFIX}{model_name}\", \"preds\", f\"{dataset}_fold{fold}_preds.csv\")\n",
    "        print(f\"ZERO-SHOT PATH: {path}\")\n",
    "    else:\n",
    "        # Few-shot: separate folder per model-dataset combination\n",
    "        path = os.path.join(f\"{FS_PREFIX}{model_name}_{dataset}\", \"preds\", f\"{dataset}_fold{fold}_{shot}shot_preds.csv\")\n",
    "        print(f\"FEW-SHOT PATH: {path}\")\n",
    "    \n",
    "    # Check if directory exists\n",
    "    dir_path = os.path.dirname(path)\n",
    "    if not os.path.exists(dir_path):\n",
    "        print(f\"DIRECTORY MISSING: {dir_path}\")\n",
    "        return None\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(f\"FILE MISSING: {path}\")\n",
    "        # List what files ARE in the directory\n",
    "        try:\n",
    "            files_in_dir = os.listdir(dir_path)\n",
    "            print(f\"Files in {dir_path}: {files_in_dir[:10]}\")  # Show first 10 files\n",
    "        except:\n",
    "            print(f\"Cannot list files in {dir_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"SUCCESS: Loaded {len(df)} rows, columns: {list(df.columns)}\")\n",
    "        \n",
    "        # Check if required columns exist\n",
    "        if 'gold' not in df.columns:\n",
    "            print(f\"ERROR: 'gold' column missing from {path}\")\n",
    "            print(f\"Available columns: {list(df.columns)}\")\n",
    "            return None\n",
    "        if 'pred' not in df.columns:\n",
    "            print(f\"ERROR: 'pred' column missing from {path}\")\n",
    "            print(f\"Available columns: {list(df.columns)}\")\n",
    "            return None\n",
    "            \n",
    "        return df[[\"text\", \"gold\", \"pred\"]]\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR reading {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ─── CALCULATE F1 SCORES ──────────────────\n",
    "print(\"Calculating F1 scores for all configurations...\")\n",
    "print(f\"Expected zero-shot path format: {ZS_PREFIX}MODEL_NAME/preds/DATASET_foldN_preds.csv\")\n",
    "print(f\"Expected few-shot path format: {FS_PREFIX}MODEL_NAME_DATASET/preds/DATASET_foldN_Nshot_preds.csv\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for model in MODELS:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing model: {model}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Process zero-shot first to debug\n",
    "    print(f\"\\nProcessing ZERO-SHOT for {model}:\")\n",
    "    for dataset in DATASETS:\n",
    "        print(f\"\\n  Dataset: {dataset}\")\n",
    "        dataset_f1_scores = []\n",
    "        dataset_sample_counts = []\n",
    "        \n",
    "        for fold in FOLDS:\n",
    "            df = load_preds(model, dataset, fold, shot=None)\n",
    "            if df is None:\n",
    "                continue\n",
    "            \n",
    "            # Validate data\n",
    "            if len(df) == 0:\n",
    "                print(f\"    WARNING: Empty dataframe for {model} {dataset} fold {fold}\")\n",
    "                continue\n",
    "                \n",
    "            # Check for missing columns or data\n",
    "            missing_gold = df[\"gold\"].isna().sum()\n",
    "            missing_pred = df[\"pred\"].isna().sum()\n",
    "            if missing_gold > 0 or missing_pred > 0:\n",
    "                print(f\"    WARNING: Missing data - gold: {missing_gold}, pred: {missing_pred}\")\n",
    "            \n",
    "            # Clean predictions and gold labels\n",
    "            gold = df[\"gold\"].str.lower().str.strip()\n",
    "            pred = df[\"pred\"].str.lower().str.strip()\n",
    "            \n",
    "            # Calculate F1 score (macro average for multi-class)\n",
    "            try:\n",
    "                f1 = f1_score(gold, pred, average='macro', zero_division=0)\n",
    "                dataset_f1_scores.append(f1)\n",
    "                dataset_sample_counts.append(len(df))\n",
    "                print(f\"    Fold {fold}: F1={f1:.4f}, samples={len(df)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"    ERROR calculating F1 for {model} {dataset} fold {fold}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if dataset_f1_scores:\n",
    "            # Calculate weighted average F1 for this dataset\n",
    "            weights = np.array(dataset_sample_counts)\n",
    "            avg_f1 = np.average(dataset_f1_scores, weights=weights)\n",
    "            \n",
    "            print(f\"  {dataset} ZERO-SHOT: Avg F1={avg_f1:.4f} (from {len(dataset_f1_scores)} folds)\")\n",
    "            \n",
    "            all_results.append({\n",
    "                'model': model,\n",
    "                'shot_config': '0-shot',\n",
    "                'dataset': dataset,\n",
    "                'avg_f1': avg_f1,\n",
    "                'total_samples': sum(dataset_sample_counts),\n",
    "                'num_folds': len(dataset_f1_scores)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"  {dataset} ZERO-SHOT: NO DATA FOUND!\")\n",
    "    \n",
    "    # Process few-shot\n",
    "    print(f\"\\nProcessing FEW-SHOT for {model}:\")\n",
    "    for shot in K_SHOTS:\n",
    "        print(f\"\\n  {shot}-shot:\")\n",
    "        for dataset in DATASETS:\n",
    "            dataset_f1_scores = []\n",
    "            dataset_sample_counts = []\n",
    "            \n",
    "            for fold in FOLDS:\n",
    "                df = load_preds(model, dataset, fold, shot=shot)\n",
    "                if df is None:\n",
    "                    continue\n",
    "                \n",
    "                # Clean predictions and gold labels\n",
    "                gold = df[\"gold\"].str.lower().str.strip()\n",
    "                pred = df[\"pred\"].str.lower().str.strip()\n",
    "                \n",
    "                # Calculate F1 score\n",
    "                try:\n",
    "                    f1 = f1_score(gold, pred, average='macro', zero_division=0)\n",
    "                    dataset_f1_scores.append(f1)\n",
    "                    dataset_sample_counts.append(len(df))\n",
    "                    print(f\"    {dataset} Fold {fold}: F1={f1:.4f}, samples={len(df)}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    ERROR calculating F1 for {model} {dataset} fold {fold} {shot}-shot: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if dataset_f1_scores:\n",
    "                # Since all folds have same sample size, use simple arithmetic mean\n",
    "                avg_f1 = np.mean(dataset_f1_scores)\n",
    "                \n",
    "                print(f\"    {dataset}: Avg F1={avg_f1:.4f} (from {len(dataset_f1_scores)} folds)\")\n",
    "                \n",
    "                all_results.append({\n",
    "                    'model': model,\n",
    "                    'shot_config': f'{shot}-shot',\n",
    "                    'dataset': dataset,\n",
    "                    'avg_f1': avg_f1,\n",
    "                    'total_samples': sum(dataset_sample_counts),\n",
    "                    'num_folds': len(dataset_f1_scores)\n",
    "                })\n",
    "            else:\n",
    "                print(f\"    {dataset}: NO DATA FOUND!\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(f\"\\nDEBUG: Results DataFrame shape: {results_df.shape}\")\n",
    "print(f\"DEBUG: Available combinations:\")\n",
    "print(results_df[['model', 'shot_config', 'dataset', 'avg_f1']].head(20))\n",
    "\n",
    "# ─── CREATE EXCEL-STYLE F1 TABLE ──────────────────\n",
    "print(f\"\\nCreating Excel-style table...\")\n",
    "excel_style_data = []\n",
    "\n",
    "for model in MODELS:\n",
    "    for dataset in DATASETS:\n",
    "        row = {\n",
    "            'Model': model,\n",
    "            'Dataset': dataset,\n",
    "            'Prompt Template': 'PT 7- definition'\n",
    "        }\n",
    "        \n",
    "        # Add F1 scores for each shot configuration\n",
    "        for shot_config in ['0-shot'] + [f'{k}-shot' for k in K_SHOTS]:\n",
    "            col_name = shot_config.replace('-shot', ' shot')\n",
    "            if col_name == '0 shot':\n",
    "                col_name = 'Zero shot'\n",
    "            \n",
    "            # Find data for this specific combination\n",
    "            model_data = results_df[\n",
    "                (results_df['model'] == model) & \n",
    "                (results_df['dataset'] == dataset) & \n",
    "                (results_df['shot_config'] == shot_config)\n",
    "            ]\n",
    "            \n",
    "            if len(model_data) > 0:\n",
    "                f1_value = model_data.iloc[0]['avg_f1']\n",
    "                row[col_name] = round(f1_value, 3)\n",
    "                print(f\"DEBUG: {model} {dataset} {shot_config} = {f1_value:.3f}\")\n",
    "            else:\n",
    "                row[col_name] = np.nan  # Use NaN instead of 0.000\n",
    "                print(f\"DEBUG: {model} {dataset} {shot_config} = NOT FOUND\")\n",
    "        \n",
    "        excel_style_data.append(row)\n",
    "\n",
    "excel_style_df = pd.DataFrame(excel_style_data)\n",
    "\n",
    "# Reorder columns to match your image\n",
    "column_order = ['Model', 'Dataset', 'Prompt Template', 'Zero shot', '1 shot', '3 shot', '5 shot', '7 shot']\n",
    "excel_style_df = excel_style_df.reindex(columns=column_order)\n",
    "\n",
    "# Replace NaN with empty string for better Excel display\n",
    "excel_style_df_display = excel_style_df.fillna('')\n",
    "\n",
    "# Define file paths\n",
    "excel_style_csv = os.path.join(OUT_DIR, \"f1_scores_excel_format.csv\")\n",
    "excel_style_excel = os.path.join(OUT_DIR, \"f1_scores_excel_format.xlsx\")\n",
    "\n",
    "# Save Excel-style table\n",
    "excel_style_df_display.to_csv(excel_style_csv, index=False)\n",
    "\n",
    "# Create Excel file with formatting\n",
    "with pd.ExcelWriter(excel_style_excel, engine='openpyxl') as writer:\n",
    "    excel_style_df_display.to_excel(writer, sheet_name='F1 Scores', index=False)\n",
    "    \n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['F1 Scores']\n",
    "    \n",
    "    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "    \n",
    "    # Styles\n",
    "    header_font = Font(bold=True, color=\"000000\")\n",
    "    header_fill = PatternFill(start_color=\"D9D9D9\", end_color=\"D9D9D9\", fill_type=\"solid\")\n",
    "    model_font = Font(bold=True)\n",
    "    model_fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "    center_alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "    thin_border = Border(\n",
    "        left=Side(style='thin'), right=Side(style='thin'),\n",
    "        top=Side(style='thin'), bottom=Side(style='thin')\n",
    "    )\n",
    "    \n",
    "    # Format header row\n",
    "    for cell in worksheet[1]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "        cell.alignment = center_alignment\n",
    "        cell.border = thin_border\n",
    "    \n",
    "    # Format data rows and merge model cells\n",
    "    current_row = 2\n",
    "    for model in MODELS:\n",
    "        model_rows = excel_style_df_display[excel_style_df_display['Model'] == model]\n",
    "        num_datasets = len(model_rows)\n",
    "        \n",
    "        if num_datasets > 0:\n",
    "            # Merge model name cells\n",
    "            if num_datasets > 1:\n",
    "                merge_range = f\"A{current_row}:A{current_row + num_datasets - 1}\"\n",
    "                worksheet.merge_cells(merge_range)\n",
    "            \n",
    "            # Format merged model cell\n",
    "            model_cell = worksheet[f\"A{current_row}\"]\n",
    "            model_cell.value = model\n",
    "            model_cell.font = model_font\n",
    "            model_cell.fill = model_fill\n",
    "            model_cell.alignment = center_alignment\n",
    "            model_cell.border = thin_border\n",
    "            \n",
    "            # Format all cells in this model's section\n",
    "            for i in range(num_datasets):\n",
    "                row_num = current_row + i\n",
    "                for col in range(1, 9):  # Columns A-H\n",
    "                    cell = worksheet.cell(row=row_num, column=col)\n",
    "                    cell.alignment = center_alignment\n",
    "                    cell.border = thin_border\n",
    "                    \n",
    "                    # Format F1 score cells to 3 decimal places\n",
    "                    if col >= 4 and cell.value is not None and cell.value != '' and isinstance(cell.value, (int, float)):\n",
    "                        cell.number_format = '0.000'\n",
    "            \n",
    "            current_row += num_datasets\n",
    "    \n",
    "    # Auto-adjust column widths\n",
    "    for column in worksheet.columns:\n",
    "        max_length = 0\n",
    "        column_letter = column[0].column_letter\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(str(cell.value))\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = min(max_length + 2, 20)\n",
    "        worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "# ─── CREATE SUMMARY TABLES ──────────────────\n",
    "# Calculate overall weighted averages\n",
    "overall_results = []\n",
    "\n",
    "for model in MODELS:\n",
    "    for shot_config in ['0-shot'] + [f'{k}-shot' for k in K_SHOTS]:\n",
    "        model_shot_data = results_df[\n",
    "            (results_df['model'] == model) & \n",
    "            (results_df['shot_config'] == shot_config)\n",
    "        ]\n",
    "        \n",
    "        if len(model_shot_data) > 0:\n",
    "            weights = model_shot_data['total_samples'].values\n",
    "            f1_scores = model_shot_data['avg_f1'].values\n",
    "            \n",
    "            if weights.sum() > 0:\n",
    "                overall_weighted_f1 = np.average(f1_scores, weights=weights)\n",
    "                \n",
    "                overall_results.append({\n",
    "                    'model': model,\n",
    "                    'shot_config': shot_config,\n",
    "                    'weighted_avg_f1': overall_weighted_f1,\n",
    "                    'total_samples': weights.sum(),\n",
    "                    'num_datasets': len(model_shot_data)\n",
    "                })\n",
    "\n",
    "overall_df = pd.DataFrame(overall_results)\n",
    "\n",
    "# Create summary pivot table\n",
    "if len(overall_df) > 0:\n",
    "    summary_pivot = overall_df.pivot_table(\n",
    "        index='model',\n",
    "        columns='shot_config', \n",
    "        values='weighted_avg_f1',\n",
    "        fill_value=np.nan\n",
    "    ).round(4)\n",
    "    \n",
    "    # Reorder columns\n",
    "    shot_order = ['0-shot', '1-shot', '3-shot', '5-shot', '7-shot']\n",
    "    summary_pivot = summary_pivot.reindex(columns=[col for col in shot_order if col in summary_pivot.columns])\n",
    "    \n",
    "    summary_csv = os.path.join(OUT_DIR, \"weighted_f1_summary.csv\")\n",
    "    summary_pivot.to_csv(summary_csv)\n",
    "    \n",
    "    print(f\"\\nFiles created:\")\n",
    "    print(f\"Excel-style F1 table: {excel_style_csv}\")\n",
    "    print(f\"Excel-style formatted: {excel_style_excel}\")\n",
    "    print(f\"Summary F1 scores: {summary_csv}\")\n",
    "    \n",
    "    print(f\"\\nF1 Scores by Model and Dataset:\")\n",
    "    print(excel_style_df_display.to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nOverall Weighted F1 Summary:\")\n",
    "    print(summary_pivot.to_string())\n",
    "    \n",
    "    # Find best performing configurations\n",
    "    print(f\"\\nTop performing configurations:\")\n",
    "    for model in MODELS:\n",
    "        if model in summary_pivot.index:\n",
    "            model_scores = summary_pivot.loc[model].dropna()\n",
    "            if len(model_scores) > 0:\n",
    "                best_shot = model_scores.idxmax()\n",
    "                best_score = model_scores.max()\n",
    "                print(f\"{model}: {best_shot} (F1={best_score:.4f})\")\n",
    "            else:\n",
    "                print(f\"{model}: No data available\")\n",
    "else:\n",
    "    print(\"No data found for summary statistics!\")\n",
    "\n",
    "print(f\"\\nDEBUG COMPLETE: Check the debug output above to see why zero-shot might be missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43235cf-9d16-4b96-8328-ca44895279ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80284cf9-1cfd-44a6-a0a7-3b07ca120fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Running McNemar tests across all models...\n",
      "============================================================\n",
      "\n",
      "📊 Processing model: llama3_8b\n",
      "  ✅ 0-shot vs 1-shot: acc_diff=-0.035, χ²=63.856, p=0.000 (0-shot significantly better)\n",
      "  ❌ 0-shot vs 3-shot: acc_diff=+0.004, χ²=0.736, p=0.391 (No significant difference)\n",
      "  ✅ 0-shot vs 5-shot: acc_diff=+0.038, χ²=67.624, p=0.000 (5-shot significantly better)\n",
      "  ✅ 0-shot vs 7-shot: acc_diff=+0.058, χ²=144.420, p=0.000 (7-shot significantly better)\n",
      "  ✅ 1-shot vs 3-shot: acc_diff=+0.038, χ²=124.368, p=0.000 (3-shot significantly better)\n",
      "  ✅ 1-shot vs 5-shot: acc_diff=+0.073, χ²=340.458, p=0.000 (5-shot significantly better)\n",
      "  ✅ 1-shot vs 7-shot: acc_diff=+0.093, χ²=478.284, p=0.000 (7-shot significantly better)\n",
      "  ✅ 3-shot vs 5-shot: acc_diff=+0.035, χ²=122.209, p=0.000 (5-shot significantly better)\n",
      "  ✅ 3-shot vs 7-shot: acc_diff=+0.055, χ²=237.064, p=0.000 (7-shot significantly better)\n",
      "  ✅ 5-shot vs 7-shot: acc_diff=+0.020, χ²=40.502, p=0.000 (7-shot significantly better)\n",
      "\n",
      "📊 Processing model: llama3_70b\n",
      "  ✅ 0-shot vs 1-shot: acc_diff=-0.037, χ²=69.122, p=0.000 (0-shot significantly better)\n",
      "  ✅ 0-shot vs 3-shot: acc_diff=-0.033, χ²=50.859, p=0.000 (0-shot significantly better)\n",
      "  ✅ 0-shot vs 5-shot: acc_diff=-0.050, χ²=94.746, p=0.000 (0-shot significantly better)\n",
      "  ✅ 0-shot vs 7-shot: acc_diff=-0.057, χ²=103.959, p=0.000 (0-shot significantly better)\n",
      "  ❌ 1-shot vs 3-shot: acc_diff=+0.004, χ²=1.721, p=0.190 (No significant difference)\n",
      "  ✅ 1-shot vs 5-shot: acc_diff=-0.014, χ²=13.363, p=0.000 (1-shot significantly better)\n",
      "  ✅ 1-shot vs 7-shot: acc_diff=-0.021, χ²=21.604, p=0.000 (1-shot significantly better)\n",
      "  ✅ 3-shot vs 5-shot: acc_diff=-0.017, χ²=31.172, p=0.000 (3-shot significantly better)\n",
      "  ✅ 3-shot vs 7-shot: acc_diff=-0.024, χ²=37.829, p=0.000 (3-shot significantly better)\n",
      "  ✅ 5-shot vs 7-shot: acc_diff=-0.007, χ²=5.602, p=0.018 (5-shot significantly better)\n",
      "\n",
      "📊 Processing model: mistral_7b\n",
      "  ✅ 0-shot vs 1-shot: acc_diff=-0.056, χ²=105.208, p=0.000 (0-shot significantly better)\n",
      "  ✅ 0-shot vs 3-shot: acc_diff=+0.036, χ²=35.119, p=0.000 (3-shot significantly better)\n",
      "  ✅ 0-shot vs 5-shot: acc_diff=+0.049, χ²=64.949, p=0.000 (5-shot significantly better)\n",
      "  ✅ 0-shot vs 7-shot: acc_diff=+0.065, χ²=111.117, p=0.000 (7-shot significantly better)\n",
      "  ✅ 1-shot vs 3-shot: acc_diff=+0.091, χ²=437.288, p=0.000 (3-shot significantly better)\n",
      "  ✅ 1-shot vs 5-shot: acc_diff=+0.105, χ²=548.809, p=0.000 (5-shot significantly better)\n",
      "  ✅ 1-shot vs 7-shot: acc_diff=+0.121, χ²=648.163, p=0.000 (7-shot significantly better)\n",
      "  ✅ 3-shot vs 5-shot: acc_diff=+0.014, χ²=18.259, p=0.000 (5-shot significantly better)\n",
      "  ✅ 3-shot vs 7-shot: acc_diff=+0.030, χ²=71.800, p=0.000 (7-shot significantly better)\n",
      "  ✅ 5-shot vs 7-shot: acc_diff=+0.016, χ²=31.815, p=0.000 (7-shot significantly better)\n",
      "\n",
      "📊 Processing model: gemma3_4b\n",
      "  ✅ 0-shot vs 1-shot: acc_diff=-0.074, χ²=142.294, p=0.000 (0-shot significantly better)\n",
      "  ✅ 0-shot vs 3-shot: acc_diff=-0.050, χ²=59.654, p=0.000 (0-shot significantly better)\n",
      "  ✅ 0-shot vs 5-shot: acc_diff=-0.016, χ²=5.625, p=0.018 (0-shot significantly better)\n",
      "  ✅ 0-shot vs 7-shot: acc_diff=-0.028, χ²=16.033, p=0.000 (0-shot significantly better)\n",
      "  ✅ 1-shot vs 3-shot: acc_diff=+0.024, χ²=19.531, p=0.000 (3-shot significantly better)\n",
      "  ✅ 1-shot vs 5-shot: acc_diff=+0.057, χ²=93.156, p=0.000 (5-shot significantly better)\n",
      "  ✅ 1-shot vs 7-shot: acc_diff=+0.046, χ²=56.723, p=0.000 (7-shot significantly better)\n",
      "  ✅ 3-shot vs 5-shot: acc_diff=+0.034, χ²=68.233, p=0.000 (5-shot significantly better)\n",
      "  ✅ 3-shot vs 7-shot: acc_diff=+0.022, χ²=25.642, p=0.000 (7-shot significantly better)\n",
      "  ✅ 5-shot vs 7-shot: acc_diff=-0.011, χ²=12.714, p=0.000 (5-shot significantly better)\n",
      "\n",
      "📊 Processing model: wizardlm2_7b\n",
      "  ✅ 0-shot vs 1-shot: acc_diff=-0.090, χ²=407.717, p=0.000 (0-shot significantly better)\n",
      "  ❌ 0-shot vs 3-shot: acc_diff=+0.007, χ²=2.568, p=0.109 (No significant difference)\n",
      "  ✅ 0-shot vs 5-shot: acc_diff=+0.042, χ²=86.884, p=0.000 (5-shot significantly better)\n",
      "  ✅ 0-shot vs 7-shot: acc_diff=+0.050, χ²=103.194, p=0.000 (7-shot significantly better)\n",
      "  ✅ 1-shot vs 3-shot: acc_diff=+0.097, χ²=522.449, p=0.000 (3-shot significantly better)\n",
      "  ✅ 1-shot vs 5-shot: acc_diff=+0.132, χ²=790.914, p=0.000 (5-shot significantly better)\n",
      "  ✅ 1-shot vs 7-shot: acc_diff=+0.140, χ²=814.035, p=0.000 (7-shot significantly better)\n",
      "  ✅ 3-shot vs 5-shot: acc_diff=+0.035, χ²=89.055, p=0.000 (5-shot significantly better)\n",
      "  ✅ 3-shot vs 7-shot: acc_diff=+0.043, χ²=106.892, p=0.000 (7-shot significantly better)\n",
      "  ❌ 5-shot vs 7-shot: acc_diff=+0.008, χ²=3.840, p=0.050 (No significant difference)\n",
      "\n",
      "============================================================\n",
      "✅ Results saved to: mcnemar_results/mcnemar_combined_all_models.csv\n",
      "\n",
      "📈 SUMMARY ANALYSIS:\n",
      "   Total comparisons: 50\n",
      "   Significant differences (p < 0.05): 46\n",
      "   Average sample size: 8286\n",
      "\n",
      "🎯 SIGNIFICANT FINDINGS BY MODEL:\n",
      "\n",
      "   llama3_8b:\n",
      "     • 0-shot vs 1-shot: 0-shot significantly better (Δacc=-0.035, p=0)\n",
      "     • 0-shot vs 5-shot: 5-shot significantly better (Δacc=+0.038, p=0)\n",
      "     • 0-shot vs 7-shot: 7-shot significantly better (Δacc=+0.058, p=0)\n",
      "     • 1-shot vs 3-shot: 3-shot significantly better (Δacc=+0.038, p=0)\n",
      "     • 1-shot vs 5-shot: 5-shot significantly better (Δacc=+0.073, p=0)\n",
      "     • 1-shot vs 7-shot: 7-shot significantly better (Δacc=+0.093, p=0)\n",
      "     • 3-shot vs 5-shot: 5-shot significantly better (Δacc=+0.035, p=0)\n",
      "     • 3-shot vs 7-shot: 7-shot significantly better (Δacc=+0.054, p=0)\n",
      "     • 5-shot vs 7-shot: 7-shot significantly better (Δacc=+0.020, p=0)\n",
      "\n",
      "   llama3_70b:\n",
      "     • 0-shot vs 1-shot: 0-shot significantly better (Δacc=-0.037, p=0)\n",
      "     • 0-shot vs 3-shot: 0-shot significantly better (Δacc=-0.033, p=0)\n",
      "     • 0-shot vs 5-shot: 0-shot significantly better (Δacc=-0.050, p=0)\n",
      "     • 0-shot vs 7-shot: 0-shot significantly better (Δacc=-0.057, p=0)\n",
      "     • 1-shot vs 5-shot: 1-shot significantly better (Δacc=-0.013, p=0.000257)\n",
      "     • 1-shot vs 7-shot: 1-shot significantly better (Δacc=-0.021, p=3e-06)\n",
      "     • 3-shot vs 5-shot: 3-shot significantly better (Δacc=-0.017, p=0)\n",
      "     • 3-shot vs 7-shot: 3-shot significantly better (Δacc=-0.024, p=0)\n",
      "     • 5-shot vs 7-shot: 5-shot significantly better (Δacc=-0.007, p=0.01794)\n",
      "\n",
      "   mistral_7b:\n",
      "     • 0-shot vs 1-shot: 0-shot significantly better (Δacc=-0.056, p=0)\n",
      "     • 0-shot vs 3-shot: 3-shot significantly better (Δacc=+0.036, p=0)\n",
      "     • 0-shot vs 5-shot: 5-shot significantly better (Δacc=+0.049, p=0)\n",
      "     • 0-shot vs 7-shot: 7-shot significantly better (Δacc=+0.065, p=0)\n",
      "     • 1-shot vs 3-shot: 3-shot significantly better (Δacc=+0.091, p=0)\n",
      "     • 1-shot vs 5-shot: 5-shot significantly better (Δacc=+0.105, p=0)\n",
      "     • 1-shot vs 7-shot: 7-shot significantly better (Δacc=+0.121, p=0)\n",
      "     • 3-shot vs 5-shot: 5-shot significantly better (Δacc=+0.014, p=1.9e-05)\n",
      "     • 3-shot vs 7-shot: 7-shot significantly better (Δacc=+0.030, p=0)\n",
      "     • 5-shot vs 7-shot: 7-shot significantly better (Δacc=+0.016, p=0)\n",
      "\n",
      "   gemma3_4b:\n",
      "     • 0-shot vs 1-shot: 0-shot significantly better (Δacc=-0.074, p=0)\n",
      "     • 0-shot vs 3-shot: 0-shot significantly better (Δacc=-0.050, p=0)\n",
      "     • 0-shot vs 5-shot: 0-shot significantly better (Δacc=-0.016, p=0.01771)\n",
      "     • 0-shot vs 7-shot: 0-shot significantly better (Δacc=-0.028, p=6.2e-05)\n",
      "     • 1-shot vs 3-shot: 3-shot significantly better (Δacc=+0.024, p=1e-05)\n",
      "     • 1-shot vs 5-shot: 5-shot significantly better (Δacc=+0.057, p=0)\n",
      "     • 1-shot vs 7-shot: 7-shot significantly better (Δacc=+0.046, p=0)\n",
      "     • 3-shot vs 5-shot: 5-shot significantly better (Δacc=+0.034, p=0)\n",
      "     • 3-shot vs 7-shot: 7-shot significantly better (Δacc=+0.022, p=0)\n",
      "     • 5-shot vs 7-shot: 5-shot significantly better (Δacc=-0.011, p=0.000363)\n",
      "\n",
      "   wizardlm2_7b:\n",
      "     • 0-shot vs 1-shot: 0-shot significantly better (Δacc=-0.090, p=0)\n",
      "     • 0-shot vs 5-shot: 5-shot significantly better (Δacc=+0.043, p=0)\n",
      "     • 0-shot vs 7-shot: 7-shot significantly better (Δacc=+0.050, p=0)\n",
      "     • 1-shot vs 3-shot: 3-shot significantly better (Δacc=+0.097, p=0)\n",
      "     • 1-shot vs 5-shot: 5-shot significantly better (Δacc=+0.132, p=0)\n",
      "     • 1-shot vs 7-shot: 7-shot significantly better (Δacc=+0.140, p=0)\n",
      "     • 3-shot vs 5-shot: 5-shot significantly better (Δacc=+0.035, p=0)\n",
      "     • 3-shot vs 7-shot: 7-shot significantly better (Δacc=+0.043, p=0)\n",
      "\n",
      "🏆 BEST SHOT CONFIGURATION PER MODEL:\n",
      "   llama3_8b: 7-shot (+0.058 vs 0-shot)\n",
      "   llama3_70b: No few-shot config significantly beats 0-shot\n",
      "   mistral_7b: 7-shot (+0.065 vs 0-shot)\n",
      "   gemma3_4b: No few-shot config significantly beats 0-shot\n",
      "   wizardlm2_7b: 7-shot (+0.050 vs 0-shot)\n",
      "\n",
      "============================================================\n",
      "\n",
      "🔍 Focused Comparison: 5-shot vs 0-shot and 5-shot vs 1-shot\n",
      "\n",
      "🧠 Model: llama3_8b\n",
      "  • 0-shot vs 5-shot: 5-shot significantly better (Δacc=+0.038, p=0, ✅ Significant)\n",
      "  • 1-shot vs 5-shot: 5-shot significantly better (Δacc=+0.073, p=0, ✅ Significant)\n",
      "\n",
      "🧠 Model: llama3_70b\n",
      "  • 0-shot vs 5-shot: 0-shot significantly better (Δacc=-0.050, p=0, ✅ Significant)\n",
      "  • 1-shot vs 5-shot: 1-shot significantly better (Δacc=-0.013, p=0.000257, ✅ Significant)\n",
      "\n",
      "🧠 Model: mistral_7b\n",
      "  • 0-shot vs 5-shot: 5-shot significantly better (Δacc=+0.049, p=0, ✅ Significant)\n",
      "  • 1-shot vs 5-shot: 5-shot significantly better (Δacc=+0.105, p=0, ✅ Significant)\n",
      "\n",
      "🧠 Model: gemma3_4b\n",
      "  • 0-shot vs 5-shot: 0-shot significantly better (Δacc=-0.016, p=0.01771, ✅ Significant)\n",
      "  • 1-shot vs 5-shot: 5-shot significantly better (Δacc=+0.057, p=0, ✅ Significant)\n",
      "\n",
      "🧠 Model: wizardlm2_7b\n",
      "  • 0-shot vs 5-shot: 5-shot significantly better (Δacc=+0.043, p=0, ✅ Significant)\n",
      "  • 1-shot vs 5-shot: 5-shot significantly better (Δacc=+0.132, p=0, ✅ Significant)\n",
      "📁 Saved: mcnemar_results/focus_BestVsBase_BestVsWorst_shot_comparisons.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "import numpy as np\n",
    "# Add this at the top of your script\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────\n",
    "ZS_PREFIX = \"zero_shot_folds_\"\n",
    "FS_PREFIX = \"few_shot_folds_\"\n",
    "DATASETS = [\"pan\", \"maalej\", \"scalabrino\"]\n",
    "MODELS = [\"llama3_8b\", \"llama3_70b\", \"mistral_7b\", \"gemma3_4b\", \"wizardlm2_7b\"]\n",
    "K_SHOTS = [1, 3, 5, 7]\n",
    "FOLDS = range(10)\n",
    "OUT_CSV = \"mcnemar_results/mcnemar_combined_all_models.csv\"\n",
    "os.makedirs(\"mcnemar_results\", exist_ok=True)\n",
    "\n",
    "# ─── LOAD PREDICTIONS ──────────────────\n",
    "def load_preds(model_name, dataset, fold, shot=None):\n",
    "    if shot is None:\n",
    "        path = os.path.join(f\"{ZS_PREFIX}{model_name}\", \"preds\", f\"{dataset}_fold{fold}_preds.csv\")\n",
    "    else:\n",
    "        path = os.path.join(f\"{FS_PREFIX}{model_name}_{dataset}\", \"preds\", f\"{dataset}_fold{fold}_{shot}shot_preds.csv\")\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Missing file: {path}\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    return df[[\"text\", \"gold\", \"pred\"]]\n",
    "\n",
    "# ─── RUN MCNEMAR TEST ──────────────────\n",
    "all_results = []\n",
    "\n",
    "print(\"🔍 Running McNemar tests across all models...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for model in MODELS:\n",
    "    print(f\"\\n📊 Processing model: {model}\")\n",
    "    \n",
    "    # Generate all comparisons\n",
    "    comparisons = [(None, k) for k in K_SHOTS]  # ZS vs FS\n",
    "    comparisons += [(k1, k2) for i, k1 in enumerate(K_SHOTS) for k2 in K_SHOTS[i+1:]]  # FS vs FS\n",
    "    \n",
    "    for s1, s2 in comparisons:\n",
    "        p1_all, p2_all = [], []\n",
    "        dataset_samples = {\"pan\": 0, \"maalej\": 0, \"scalabrino\": 0}\n",
    "        \n",
    "        for dataset in DATASETS:\n",
    "            dataset_count = 0\n",
    "            for fold in FOLDS:\n",
    "                df1 = load_preds(model, dataset, fold, s1)\n",
    "                df2 = load_preds(model, dataset, fold, s2)\n",
    "                \n",
    "                if df1 is None or df2 is None:\n",
    "                    continue\n",
    "                \n",
    "                # Use inner join to handle mismatched samples\n",
    "                merged = pd.merge(df1, df2, on=\"text\", suffixes=(\"_1\", \"_2\"), how=\"inner\")\n",
    "                \n",
    "                # Check for significant data loss\n",
    "                original_size = min(len(df1), len(df2))\n",
    "                if len(merged) < original_size * 0.8:\n",
    "                    print(f\"⚠️  Warning: {dataset} fold {fold} lost {original_size - len(merged)} samples\")\n",
    "                \n",
    "                gold = merged[\"gold_1\"].str.lower().str.strip()\n",
    "                pred1 = merged[\"pred_1\"].str.lower().str.strip()\n",
    "                pred2 = merged[\"pred_2\"].str.lower().str.strip()\n",
    "                \n",
    "                for y, p1, p2 in zip(gold, pred1, pred2):\n",
    "                    p1_all.append(p1 == y)\n",
    "                    p2_all.append(p2 == y)\n",
    "                \n",
    "                dataset_count += len(merged)\n",
    "            \n",
    "            dataset_samples[dataset] = dataset_count\n",
    "        \n",
    "        if len(p1_all) == 0:\n",
    "            print(f\"⚠️  Skipping {s1} vs {s2}: no data available\")\n",
    "            continue\n",
    "        \n",
    "        # McNemar contingency table\n",
    "        both_correct = sum(p1 and p2 for p1, p2 in zip(p1_all, p2_all))\n",
    "        only_s1 = sum(p1 and not p2 for p1, p2 in zip(p1_all, p2_all))\n",
    "        only_s2 = sum(p2 and not p1 for p1, p2 in zip(p1_all, p2_all))\n",
    "        both_wrong = sum(not p1 and not p2 for p1, p2 in zip(p1_all, p2_all))\n",
    "        \n",
    "        # Verify contingency table\n",
    "        total_check = both_correct + only_s1 + only_s2 + both_wrong\n",
    "        assert total_check == len(p1_all), f\"Contingency table error: {total_check} != {len(p1_all)}\"\n",
    "        \n",
    "        table = [[both_correct, only_s1], [only_s2, both_wrong]]\n",
    "        \n",
    "        # Check for sufficient discordant pairs\n",
    "        discordant_pairs = only_s1 + only_s2\n",
    "        if discordant_pairs < 25:\n",
    "            print(f\"⚠️  Warning: Only {discordant_pairs} discordant pairs for {s1} vs {s2}\")\n",
    "        \n",
    "        # Calculate accuracies\n",
    "        acc1 = sum(p1_all) / len(p1_all)\n",
    "        acc2 = sum(p2_all) / len(p2_all)\n",
    "        acc_diff = acc2 - acc1  # positive means s2 is better\n",
    "        \n",
    "        # Run McNemar test\n",
    "        result = mcnemar(table, exact=False, correction=True)\n",
    "        \n",
    "        # Create readable labels\n",
    "        label1 = \"0-shot\" if s1 is None else f\"{s1}-shot\"\n",
    "        label2 = f\"{s2}-shot\"\n",
    "        \n",
    "        # Determine statistical significance and practical direction\n",
    "        is_significant = result.pvalue < 0.05\n",
    "        \n",
    "        if is_significant:\n",
    "            if only_s1 > only_s2:\n",
    "                significance = f\"{label1} significantly better\"\n",
    "            else:\n",
    "                significance = f\"{label2} significantly better\"\n",
    "        else:\n",
    "            significance = \"No significant difference\"\n",
    "        \n",
    "        # Store results\n",
    "        all_results.append({\n",
    "            \"model\": model,\n",
    "            \"comparison\": f\"{label1} vs {label2}\",\n",
    "            \"method1_accuracy\": round(acc1, 4),\n",
    "            \"method2_accuracy\": round(acc2, 4),\n",
    "            \"accuracy_difference\": round(acc_diff, 4),\n",
    "            \"total_samples\": len(p1_all),\n",
    "            \"pan_samples\": dataset_samples[\"pan\"],\n",
    "            \"maalej_samples\": dataset_samples[\"maalej\"],\n",
    "            \"scalabrino_samples\": dataset_samples[\"scalabrino\"],\n",
    "            f\"{label1.replace('-', '_')}_better\": only_s1,\n",
    "            f\"{label2.replace('-', '_')}_better\": only_s2,\n",
    "            \"discordant_pairs\": discordant_pairs,\n",
    "            \"chi2_stat\": round(result.statistic, 4),\n",
    "            \"p_value\": round(result.pvalue, 6),\n",
    "            \"significant_at_05\": is_significant,\n",
    "            \"interpretation\": significance\n",
    "        })\n",
    "        \n",
    "        # Print progress\n",
    "        sig_marker = \"✅\" if is_significant else \"❌\"\n",
    "        print(f\"  {sig_marker} {label1} vs {label2}: \"\n",
    "              f\"acc_diff={acc_diff:+.3f}, χ²={result.statistic:.3f}, \"\n",
    "              f\"p={result.pvalue:.3f} ({significance})\")\n",
    "\n",
    "# ─── SAVE RESULTS ──────────────────────\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"✅ Results saved to: {OUT_CSV}\")\n",
    "\n",
    "# ─── SUMMARY ANALYSIS ──────────────────\n",
    "print(f\"\\n📈 SUMMARY ANALYSIS:\")\n",
    "print(f\"   Total comparisons: {len(results_df)}\")\n",
    "print(f\"   Significant differences (p < 0.05): {sum(results_df['significant_at_05'])}\")\n",
    "print(f\"   Average sample size: {results_df['total_samples'].mean():.0f}\")\n",
    "\n",
    "# Show significant results by model\n",
    "print(f\"\\n🎯 SIGNIFICANT FINDINGS BY MODEL:\")\n",
    "for model in MODELS:\n",
    "    model_results = results_df[\n",
    "        (results_df['model'] == model) & \n",
    "        (results_df['significant_at_05'] == True)\n",
    "    ]\n",
    "    \n",
    "    if len(model_results) > 0:\n",
    "        print(f\"\\n   {model}:\")\n",
    "        for _, row in model_results.iterrows():\n",
    "            print(f\"     • {row['comparison']}: {row['interpretation']} \"\n",
    "                  f\"(Δacc={row['accuracy_difference']:+.3f}, p={row['p_value']:.4g})\")\n",
    "    else:\n",
    "        print(f\"\\n   {model}: No significant differences found\")\n",
    "\n",
    "# Find best shot configuration per model\n",
    "print(f\"\\n🏆 BEST SHOT CONFIGURATION PER MODEL:\")\n",
    "for model in MODELS:\n",
    "    model_data = results_df[results_df['model'] == model]\n",
    "    \n",
    "    # Get all zero-shot vs few-shot comparisons for this model\n",
    "    zs_comparisons = model_data[model_data['comparison'].str.contains('0-shot vs')]\n",
    "    \n",
    "    if len(zs_comparisons) > 0:\n",
    "        # Find which few-shot configs significantly beat zero-shot\n",
    "        significant_wins = zs_comparisons[\n",
    "            (zs_comparisons['significant_at_05'] == True) &\n",
    "            (zs_comparisons['accuracy_difference'] > 0)\n",
    "        ]\n",
    "        \n",
    "        if len(significant_wins) > 0:\n",
    "            best = significant_wins.loc[significant_wins['accuracy_difference'].idxmax()]\n",
    "            print(f\"   {model}: {best['comparison'].split(' vs ')[1]} \"\n",
    "                  f\"(+{best['accuracy_difference']:.3f} vs 0-shot)\")\n",
    "        else:\n",
    "            print(f\"   {model}: No few-shot config significantly beats 0-shot\")\n",
    "    else:\n",
    "        print(f\"   {model}: No 0-shot comparisons available\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "# ─── CUSTOM FILTER: 5-shot vs 0-shot and 5-shot vs 1-shot ─────────────\n",
    "print(f\"\\n🔍 Focused Comparison: 5-shot vs 0-shot and 5-shot vs 1-shot\")\n",
    "focus_pairs = [\"0-shot vs 5-shot\", \"1-shot vs 5-shot\"]\n",
    "\n",
    "for model in MODELS:\n",
    "    print(f\"\\n🧠 Model: {model}\")\n",
    "    for pair in focus_pairs:\n",
    "        row = results_df[\n",
    "            (results_df['model'] == model) & \n",
    "            (results_df['comparison'] == pair)\n",
    "        ]\n",
    "        if not row.empty:\n",
    "            r = row.iloc[0]\n",
    "            sig = \"✅ Significant\" if r[\"significant_at_05\"] else \"❌ Not significant\"\n",
    "            print(f\"  • {pair}: {r['interpretation']} \"\n",
    "                  f\"(Δacc={r['accuracy_difference']:+.3f}, p={r['p_value']:.4g}, {sig})\")\n",
    "        else:\n",
    "            print(f\"  • {pair}: ❌ No data found\")\n",
    "focus_df = results_df[results_df['comparison'].isin(focus_pairs)].copy()\n",
    "focus_df.to_csv(\"mcnemar_results/focus_BestVsBase_BestVsWorst_shot_comparisons.csv\", index=False)\n",
    "print(\"📁 Saved: mcnemar_results/focus_BestVsBase_BestVsWorst_shot_comparisons.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97871d4-47ed-4988-88ff-aa4e65ef4e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running McNemar tests for matrix pivot...\n",
      "Processing model: llama3_8b\n",
      "Processing model: llama3_70b\n",
      "Processing model: mistral_7b\n",
      "Processing model: gemma3_4b\n",
      "Processing model: wizardlm2_7b\n",
      "\n",
      "Files saved:\n",
      "CSV: mcnemar_results/mcnemar_matrix_pivot.csv\n",
      "Excel: mcnemar_results/mcnemar_matrix_pivot.xlsx\n",
      "Format: Matrix showing (chi-square/p-value) for each comparison\n",
      "\n",
      "📊 Creating focused McNemar pivot (0-shot vs 5-shot, 1-shot vs 5-shot)...\n",
      "✅ Focused pivot saved:\n",
      " - mcnemar_results/mcnemar_focused_0_1_vs_5_pivot.csv\n",
      " - mcnemar_results/mcnemar_focused_0_1_vs_5_pivot.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────\n",
    "ZS_PREFIX = \"zero_shot_folds_\"\n",
    "FS_PREFIX = \"few_shot_folds_\"\n",
    "DATASETS = [\"pan\", \"maalej\", \"scalabrino\"]\n",
    "MODELS = [\"llama3_8b\", \"llama3_70b\", \"mistral_7b\", \"gemma3_4b\", \"wizardlm2_7b\"]\n",
    "K_SHOTS = [1, 3, 5, 7]\n",
    "FOLDS = range(10)\n",
    "OUT_CSV = \"mcnemar_results/mcnemar_matrix_pivot.csv\"\n",
    "OUT_EXCEL = \"mcnemar_results/mcnemar_matrix_pivot.xlsx\"\n",
    "os.makedirs(\"mcnemar_results\", exist_ok=True)\n",
    "\n",
    "# ─── LOAD PREDICTIONS ──────────────────\n",
    "def load_preds(model_name, dataset, fold, shot=None):\n",
    "    if shot is None:\n",
    "        path = os.path.join(f\"{ZS_PREFIX}{model_name}\", \"preds\", f\"{dataset}_fold{fold}_preds.csv\")\n",
    "    else:\n",
    "        path = os.path.join(f\"{FS_PREFIX}{model_name}_{dataset}\", \"preds\", f\"{dataset}_fold{fold}_{shot}shot_preds.csv\")\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Missing file: {path}\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    return df[[\"text\", \"gold\", \"pred\"]]\n",
    "\n",
    "# ─── RUN MCNEMAR TEST ──────────────────\n",
    "all_results = []\n",
    "\n",
    "print(\"Running McNemar tests for matrix pivot...\")\n",
    "\n",
    "for model in MODELS:\n",
    "    print(f\"Processing model: {model}\")\n",
    "    \n",
    "    # Generate all comparisons\n",
    "    comparisons = [(None, k) for k in K_SHOTS]  # ZS vs FS\n",
    "    comparisons += [(k1, k2) for i, k1 in enumerate(K_SHOTS) for k2 in K_SHOTS[i+1:]]  # FS vs FS\n",
    "    \n",
    "    for s1, s2 in comparisons:\n",
    "        p1_all, p2_all = [], []\n",
    "        \n",
    "        for dataset in DATASETS:\n",
    "            for fold in FOLDS:\n",
    "                df1 = load_preds(model, dataset, fold, s1)\n",
    "                df2 = load_preds(model, dataset, fold, s2)\n",
    "                \n",
    "                if df1 is None or df2 is None:\n",
    "                    continue\n",
    "                \n",
    "                # Use inner join to handle mismatched samples\n",
    "                merged = pd.merge(df1, df2, on=\"text\", suffixes=(\"_1\", \"_2\"), how=\"inner\")\n",
    "                \n",
    "                gold = merged[\"gold_1\"].str.lower().str.strip()\n",
    "                pred1 = merged[\"pred_1\"].str.lower().str.strip()\n",
    "                pred2 = merged[\"pred_2\"].str.lower().str.strip()\n",
    "                \n",
    "                for y, p1, p2 in zip(gold, pred1, pred2):\n",
    "                    p1_all.append(p1 == y)\n",
    "                    p2_all.append(p2 == y)\n",
    "        \n",
    "        if len(p1_all) == 0:\n",
    "            continue\n",
    "        \n",
    "        # McNemar contingency table\n",
    "        both_correct = sum(p1 and p2 for p1, p2 in zip(p1_all, p2_all))\n",
    "        only_s1 = sum(p1 and not p2 for p1, p2 in zip(p1_all, p2_all))\n",
    "        only_s2 = sum(p2 and not p1 for p1, p2 in zip(p1_all, p2_all))\n",
    "        both_wrong = sum(not p1 and not p2 for p1, p2 in zip(p1_all, p2_all))\n",
    "        \n",
    "        table = [[both_correct, only_s1], [only_s2, both_wrong]]\n",
    "        \n",
    "        # Run McNemar test\n",
    "        result = mcnemar(table, exact=False, correction=True)\n",
    "        \n",
    "        # Create readable labels\n",
    "        method1 = \"0-shot\" if s1 is None else f\"{s1}-shot\"\n",
    "        method2 = f\"{s2}-shot\"\n",
    "        \n",
    "        all_results.append({\n",
    "            \"Model\": model,\n",
    "            \"Method_1\": method1,\n",
    "            \"Method_2\": method2,\n",
    "            \"Chi_Square\": result.statistic,\n",
    "            \"P_Value\": result.pvalue\n",
    "        })\n",
    "\n",
    "# ─── CREATE MATRIX TABLE ──────────────────\n",
    "matrix_rows = []\n",
    "\n",
    "for model in MODELS:\n",
    "    model_data = [r for r in all_results if r['Model'] == model]\n",
    "    \n",
    "    # Create rows for each shot type\n",
    "    shot_types = [\"0 shot\", \"1 shot\", \"3 shot\", \"5 shot\"]\n",
    "    \n",
    "    for i, shot_row in enumerate(shot_types):\n",
    "        row_data = []\n",
    "        \n",
    "        # Add model name only in first row\n",
    "        if i == 0:\n",
    "            row_data.append(model)\n",
    "        else:\n",
    "            row_data.append(\"\")\n",
    "        \n",
    "        # Add shot type\n",
    "        row_data.append(shot_row)\n",
    "        \n",
    "        # Add comparison values for columns: 1 shot, 3 shot, 5 shot, 7 shot\n",
    "        column_shots = [\"1\", \"3\", \"5\", \"7\"]\n",
    "        \n",
    "        for col_shot in column_shots:\n",
    "            # Determine method names for lookup\n",
    "            if shot_row == \"0 shot\":\n",
    "                method1 = \"0-shot\"\n",
    "            else:\n",
    "                method1 = f\"{shot_row.replace(' shot', '')}-shot\"\n",
    "            \n",
    "            method2 = f\"{col_shot}-shot\"\n",
    "            \n",
    "            # Check if this is a valid comparison (upper triangular)\n",
    "            if shot_row == \"0 shot\":\n",
    "                # 0-shot vs all others is valid\n",
    "                pass\n",
    "            else:\n",
    "                shot_num = int(shot_row.replace(\" shot\", \"\"))\n",
    "                col_num = int(col_shot)\n",
    "                if shot_num >= col_num:\n",
    "                    row_data.append(\"\")\n",
    "                    continue\n",
    "            \n",
    "            # Find the comparison\n",
    "            comparison = next((r for r in model_data \n",
    "                             if r['Method_1'] == method1 and r['Method_2'] == method2), None)\n",
    "            \n",
    "            if comparison:\n",
    "                chi_val = comparison['Chi_Square']\n",
    "                p_val = comparison['P_Value']\n",
    "                value = f\"({chi_val:.3f}/{p_val:.3f})\"\n",
    "                row_data.append(value)\n",
    "            else:\n",
    "                row_data.append(\"\")\n",
    "        \n",
    "        matrix_rows.append(row_data)\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"Model\", \"Shot Type\", \"1 shot\", \"3 shot\", \"5 shot\", \"7 shot\"]\n",
    "matrix_df = pd.DataFrame(matrix_rows, columns=columns)\n",
    "\n",
    "# Save CSV\n",
    "matrix_df.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "# Save as Excel with formatting\n",
    "with pd.ExcelWriter(OUT_EXCEL, engine='openpyxl') as writer:\n",
    "    matrix_df.to_excel(writer, sheet_name='McNemar Matrix', index=False)\n",
    "    \n",
    "    # Get workbook and worksheet\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['McNemar Matrix']\n",
    "    \n",
    "    # Import styling\n",
    "    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "    \n",
    "    # Define styles\n",
    "    header_font = Font(bold=True, color=\"FFFFFF\")\n",
    "    header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
    "    model_font = Font(bold=True)\n",
    "    model_fill = PatternFill(start_color=\"D9D9D9\", end_color=\"D9D9D9\", fill_type=\"solid\")\n",
    "    center_alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "    thin_border = Border(\n",
    "        left=Side(style='thin'), right=Side(style='thin'),\n",
    "        top=Side(style='thin'), bottom=Side(style='thin')\n",
    "    )\n",
    "    \n",
    "    # Format header row\n",
    "    for cell in worksheet[1]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "        cell.alignment = center_alignment\n",
    "        cell.border = thin_border\n",
    "    \n",
    "    # Format data and merge model cells\n",
    "    current_row = 2\n",
    "    for model in MODELS:\n",
    "        # Merge model name cells (4 rows)\n",
    "        merge_range = f\"A{current_row}:A{current_row + 3}\"\n",
    "        worksheet.merge_cells(merge_range)\n",
    "        \n",
    "        # Format merged model cell\n",
    "        model_cell = worksheet[f\"A{current_row}\"]\n",
    "        model_cell.value = model\n",
    "        model_cell.font = model_font\n",
    "        model_cell.fill = model_fill\n",
    "        model_cell.alignment = center_alignment\n",
    "        model_cell.border = thin_border\n",
    "        \n",
    "        # Format the 4 rows for this model\n",
    "        for i in range(4):\n",
    "            row_num = current_row + i\n",
    "            for col in range(1, 7):  # Columns A-F\n",
    "                cell = worksheet.cell(row=row_num, column=col)\n",
    "                cell.alignment = center_alignment\n",
    "                cell.border = thin_border\n",
    "        \n",
    "        current_row += 4\n",
    "    \n",
    "    # Auto-adjust column widths\n",
    "    for column in worksheet.columns:\n",
    "        max_length = 0\n",
    "        column_letter = column[0].column_letter\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(str(cell.value))\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = min(max_length + 2, 25)\n",
    "        worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"CSV: {OUT_CSV}\")\n",
    "print(f\"Excel: {OUT_EXCEL}\")\n",
    "print(f\"Format: Matrix showing (chi-square/p-value) for each comparison\")\n",
    "# ─── MATRIX PIVOT TABLE: Focused on 5-shot comparisons ───────────────\n",
    "# ─── FOCUSED PIVOT: Only 0→5 and 1→5 ───────────────────────────────\n",
    "print(\"\\n📊 Creating focused McNemar pivot (0-shot vs 5-shot, 1-shot vs 5-shot)...\")\n",
    "\n",
    "focused_rows = []\n",
    "\n",
    "for model in MODELS:\n",
    "    model_data = [r for r in all_results if r[\"Model\"] == model]\n",
    "\n",
    "    for shot_row in [\"0 shot\", \"1 shot\"]:\n",
    "        row_data = []\n",
    "\n",
    "        # Add model name only once\n",
    "        if shot_row == \"0 shot\":\n",
    "            row_data.append(model)\n",
    "        else:\n",
    "            row_data.append(\"\")\n",
    "\n",
    "        # Add shot type\n",
    "        row_data.append(shot_row)\n",
    "\n",
    "        # Only one column = 5 shot\n",
    "        method1 = \"0-shot\" if shot_row == \"0 shot\" else \"1-shot\"\n",
    "        method2 = \"5-shot\"\n",
    "\n",
    "        comparison = next((r for r in model_data \n",
    "                           if r[\"Method_1\"] == method1 and r[\"Method_2\"] == method2), None)\n",
    "\n",
    "        if comparison:\n",
    "            chi_val = comparison[\"Chi_Square\"]\n",
    "            p_val = comparison[\"P_Value\"]\n",
    "            value = f\"({chi_val:.3f}/{p_val:.3f})\"\n",
    "        else:\n",
    "            value = \"\"\n",
    "\n",
    "        row_data.append(value)\n",
    "\n",
    "        focused_rows.append(row_data)\n",
    "\n",
    "# Create DataFrame\n",
    "focused_df = pd.DataFrame(focused_rows, columns=[\"Model\", \"Shot Type\", \"5 shot\"])\n",
    "\n",
    "# Save\n",
    "focused_csv = \"mcnemar_results/mcnemar_focused_0_1_vs_5_pivot.csv\"\n",
    "focused_xlsx = \"mcnemar_results/mcnemar_focused_0_1_vs_5_pivot.xlsx\"\n",
    "\n",
    "focused_df.to_csv(focused_csv, index=False)\n",
    "\n",
    "with pd.ExcelWriter(focused_xlsx, engine=\"openpyxl\") as writer:\n",
    "    focused_df.to_excel(writer, sheet_name=\"Focused McNemar\", index=False)\n",
    "\n",
    "print(f\"✅ Focused pivot saved:\\n - {focused_csv}\\n - {focused_xlsx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d0776b5-263b-49a0-acc0-e1440bf4909d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating winner analysis tables...\n",
      "\n",
      "Files created:\n",
      "Winners Pivot: mcnemar_results/mcnemar_winners_pivot.csv\n",
      "Winners Excel: mcnemar_results/mcnemar_winners_pivot.xlsx\n",
      "Summary CSV: mcnemar_results/shot_wins_summary.csv\n",
      "Summary Excel: mcnemar_results/shot_wins_summary.xlsx\n",
      "\n",
      "Win Counts Summary:\n",
      "       Model  0 shot  1 shot  3 shot  5 shot  7 shot\n",
      "   llama3_8b       1       0       1       3       4\n",
      "  llama3_70b       4       2       2       1       0\n",
      "  mistral_7b       1       0       2       3       4\n",
      "   gemma3_4b       4       0       1       3       2\n",
      "wizardlm2_7b       1       0       1       3       3\n",
      "\n",
      "First few rows of Winners Pivot:\n",
      "     Model Shot Type vs 1 shot vs 3 shot vs 5 shot vs 7 shot\n",
      " llama3_8b    0 shot    0 shot   No diff    5 shot    7 shot\n",
      "              1 shot              3 shot    5 shot    7 shot\n",
      "              3 shot                        5 shot    7 shot\n",
      "              5 shot                                  7 shot\n",
      "llama3_70b    0 shot    0 shot    0 shot    0 shot    0 shot\n",
      "              1 shot             No diff    1 shot    1 shot\n",
      "              3 shot                        3 shot    3 shot\n",
      "              5 shot                                  5 shot\n",
      "\n",
      "All interpretations matched successfully!\n",
      "\n",
      "🏆 Creating Focused Winner Pivot (0 vs 5, 1 vs 5)...\n",
      "✅ Focused winner pivot saved:\n",
      " - mcnemar_results/mcnemar_focused_winners_pivot.csv\n",
      " - mcnemar_results/mcnemar_focused_winners_pivot.xlsx\n",
      "\n",
      "Focused Winner Pivot Preview:\n",
      "     Model Shot Type 5 shot\n",
      " llama3_8b    0 shot 5 shot\n",
      "              1 shot 5 shot\n",
      "llama3_70b    0 shot 0 shot\n",
      "              1 shot 1 shot\n",
      "mistral_7b    0 shot 5 shot\n"
     ]
    }
   ],
   "source": [
    "#finding winner\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────\n",
    "MODELS = [\"llama3_8b\", \"llama3_70b\", \"mistral_7b\", \"gemma3_4b\", \"wizardlm2_7b\"]\n",
    "os.makedirs(\"mcnemar_results\", exist_ok=True)\n",
    "\n",
    "# Read the existing combined results\n",
    "combined_df = pd.read_csv(\"mcnemar_results/mcnemar_combined_all_models.csv\")\n",
    "\n",
    "print(\"Creating winner analysis tables...\")\n",
    "\n",
    "# Convert boolean column to proper boolean if it's stored as string\n",
    "combined_df['significant_at_05'] = combined_df['significant_at_05'].astype(str).str.lower().map({'true': True, 'false': False})\n",
    "\n",
    "# ─── CREATE WINNERS PIVOT TABLE ──────────────────\n",
    "def get_winner(row):\n",
    "    \"\"\"Determine winner from a comparison row\"\"\"\n",
    "    if not row['significant_at_05']:\n",
    "        return \"No diff\"\n",
    "    \n",
    "    interpretation = str(row['interpretation']).strip()\n",
    "    \n",
    "    # Simple mapping\n",
    "    winner_map = {\n",
    "        \"0-shot significantly better\": \"0 shot\",\n",
    "        \"1-shot significantly better\": \"1 shot\", \n",
    "        \"3-shot significantly better\": \"3 shot\",\n",
    "        \"5-shot significantly better\": \"5 shot\",\n",
    "        \"7-shot significantly better\": \"7 shot\"\n",
    "    }\n",
    "    \n",
    "    return winner_map.get(interpretation, f\"Unknown: {interpretation}\")\n",
    "\n",
    "# Create lookup dictionary for fast access\n",
    "comparison_lookup = {}\n",
    "for _, row in combined_df.iterrows():\n",
    "    key = (row['model'], row['comparison'])\n",
    "    comparison_lookup[key] = get_winner(row)\n",
    "\n",
    "# Build matrix rows\n",
    "matrix_rows = []\n",
    "for model in MODELS:\n",
    "    shot_types = [\"0 shot\", \"1 shot\", \"3 shot\", \"5 shot\"]\n",
    "    \n",
    "    for i, shot_row in enumerate(shot_types):\n",
    "        row_data = []\n",
    "        \n",
    "        # Model name (only in first row)\n",
    "        row_data.append(model if i == 0 else \"\")\n",
    "        \n",
    "        # Shot type\n",
    "        row_data.append(shot_row)\n",
    "        \n",
    "        # Comparisons: vs 1 shot, vs 3 shot, vs 5 shot, vs 7 shot\n",
    "        for col_shot in [\"1\", \"3\", \"5\", \"7\"]:\n",
    "            # Build comparison string\n",
    "            if shot_row == \"0 shot\":\n",
    "                comparison_str = f\"0-shot vs {col_shot}-shot\"\n",
    "            else:\n",
    "                shot_num = shot_row.replace(\" shot\", \"\")\n",
    "                \n",
    "                # Skip invalid comparisons (lower triangle)\n",
    "                if int(shot_num) >= int(col_shot):\n",
    "                    row_data.append(\"\")\n",
    "                    continue\n",
    "                    \n",
    "                comparison_str = f\"{shot_num}-shot vs {col_shot}-shot\"\n",
    "            \n",
    "            # Look up result\n",
    "            key = (model, comparison_str)\n",
    "            winner = comparison_lookup.get(key, \"Not found\")\n",
    "            row_data.append(winner)\n",
    "        \n",
    "        matrix_rows.append(row_data)\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"Model\", \"Shot Type\", \"vs 1 shot\", \"vs 3 shot\", \"vs 5 shot\", \"vs 7 shot\"]\n",
    "winners_df = pd.DataFrame(matrix_rows, columns=columns)\n",
    "\n",
    "# ─── CREATE WIN COUNTS SUMMARY ──────────────────\n",
    "summary_data = []\n",
    "\n",
    "for model in MODELS:\n",
    "    model_data = combined_df[combined_df['model'] == model]\n",
    "    \n",
    "    row = {\"Model\": model}\n",
    "    \n",
    "    # Count wins for each shot configuration\n",
    "    for shot_config in [\"0 shot\", \"1 shot\", \"3 shot\", \"5 shot\", \"7 shot\"]:\n",
    "        target_interpretation = f\"{shot_config.replace(' ', '-')} significantly better\"\n",
    "        \n",
    "        wins = len(model_data[\n",
    "            (model_data['significant_at_05'] == True) & \n",
    "            (model_data['interpretation'] == target_interpretation)\n",
    "        ])\n",
    "        \n",
    "        row[shot_config] = wins\n",
    "    \n",
    "    summary_data.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# ─── SAVE FILES ──────────────────\n",
    "# Save CSV files\n",
    "winners_csv = \"mcnemar_results/mcnemar_winners_pivot.csv\"\n",
    "summary_csv = \"mcnemar_results/shot_wins_summary.csv\"\n",
    "\n",
    "winners_df.to_csv(winners_csv, index=False)\n",
    "summary_df.to_csv(summary_csv, index=False)\n",
    "\n",
    "# Save Excel files\n",
    "winners_excel = \"mcnemar_results/mcnemar_winners_pivot.xlsx\"\n",
    "summary_excel = \"mcnemar_results/shot_wins_summary.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(winners_excel, engine='openpyxl') as writer:\n",
    "    winners_df.to_excel(writer, sheet_name='Winners Matrix', index=False)\n",
    "    \n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Winners Matrix']\n",
    "    \n",
    "    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "    \n",
    "    # Styles\n",
    "    header_font = Font(bold=True, color=\"FFFFFF\")\n",
    "    header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
    "    model_font = Font(bold=True)\n",
    "    model_fill = PatternFill(start_color=\"D9D9D9\", end_color=\"D9D9D9\", fill_type=\"solid\")\n",
    "    center_alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "    thin_border = Border(\n",
    "        left=Side(style='thin'), right=Side(style='thin'),\n",
    "        top=Side(style='thin'), bottom=Side(style='thin')\n",
    "    )\n",
    "    \n",
    "    # Format header\n",
    "    for cell in worksheet[1]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "        cell.alignment = center_alignment\n",
    "        cell.border = thin_border\n",
    "    \n",
    "    # Format and merge model cells\n",
    "    current_row = 2\n",
    "    for model in MODELS:\n",
    "        # Merge model cells (4 rows)\n",
    "        merge_range = f\"A{current_row}:A{current_row + 3}\"\n",
    "        worksheet.merge_cells(merge_range)\n",
    "        \n",
    "        model_cell = worksheet[f\"A{current_row}\"]\n",
    "        model_cell.value = model\n",
    "        model_cell.font = model_font\n",
    "        model_cell.fill = model_fill\n",
    "        model_cell.alignment = center_alignment\n",
    "        model_cell.border = thin_border\n",
    "        \n",
    "        # Format all cells in this model's section\n",
    "        for i in range(4):\n",
    "            row_num = current_row + i\n",
    "            for col in range(1, 7):\n",
    "                cell = worksheet.cell(row=row_num, column=col)\n",
    "                cell.alignment = center_alignment\n",
    "                cell.border = thin_border\n",
    "        \n",
    "        current_row += 4\n",
    "    \n",
    "    # Auto-adjust column widths\n",
    "    for column in worksheet.columns:\n",
    "        max_length = 0\n",
    "        column_letter = column[0].column_letter\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(str(cell.value))\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = min(max_length + 2, 20)\n",
    "        worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "# Summary Excel\n",
    "with pd.ExcelWriter(summary_excel, engine='openpyxl') as writer:\n",
    "    summary_df.to_excel(writer, sheet_name='Win Counts', index=False)\n",
    "    \n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Win Counts']\n",
    "    \n",
    "    # Format header\n",
    "    for cell in worksheet[1]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "        cell.alignment = center_alignment\n",
    "        cell.border = thin_border\n",
    "    \n",
    "    # Format data\n",
    "    for row in worksheet.iter_rows(min_row=2):\n",
    "        for cell in row:\n",
    "            cell.alignment = center_alignment\n",
    "            cell.border = thin_border\n",
    "    \n",
    "    # Auto-adjust columns\n",
    "    for column in worksheet.columns:\n",
    "        max_length = 0\n",
    "        column_letter = column[0].column_letter\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(str(cell.value))\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = min(max_length + 2, 15)\n",
    "        worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"Winners Pivot: {winners_csv}\")\n",
    "print(f\"Winners Excel: {winners_excel}\")\n",
    "print(f\"Summary CSV: {summary_csv}\")\n",
    "print(f\"Summary Excel: {summary_excel}\")\n",
    "\n",
    "print(f\"\\nWin Counts Summary:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nFirst few rows of Winners Pivot:\")\n",
    "print(winners_df.head(8).to_string(index=False))\n",
    "\n",
    "# Debug: Show any \"Unknown\" entries\n",
    "unknown_entries = winners_df[winners_df.apply(lambda row: any(\"Unknown:\" in str(cell) for cell in row), axis=1)]\n",
    "if len(unknown_entries) > 0:\n",
    "    print(f\"\\nDEBUG - Unknown interpretations found:\")\n",
    "    print(unknown_entries)\n",
    "else:\n",
    "    print(f\"\\nAll interpretations matched successfully!\")\n",
    "\n",
    "# ─── FOCUSED WINNER MATRIX: 0 vs 5 and 1 vs 5 ─────────────────────\n",
    "# ─── FOCUSED WINNER PIVOT: 0 vs 5 and 1 vs 5 ─────────────────────────────\n",
    "print(\"\\n🏆 Creating Focused Winner Pivot (0 vs 5, 1 vs 5)...\")\n",
    "\n",
    "focused_matrix_rows = []\n",
    "\n",
    "for model in MODELS:\n",
    "    shot_types = [\"0 shot\", \"1 shot\"]  # only rows we care about\n",
    "    \n",
    "    for i, shot_row in enumerate(shot_types):\n",
    "        row_data = []\n",
    "\n",
    "        # Add model name only for first row\n",
    "        if i == 0:\n",
    "            row_data.append(model)\n",
    "        else:\n",
    "            row_data.append(\"\")\n",
    "\n",
    "        # Shot type\n",
    "        row_data.append(shot_row)\n",
    "\n",
    "        # Only column = 5 shot\n",
    "        if shot_row == \"0 shot\":\n",
    "            comparison_str = \"0-shot vs 5-shot\"\n",
    "        else:\n",
    "            comparison_str = \"1-shot vs 5-shot\"\n",
    "\n",
    "        key = (model, comparison_str)\n",
    "        winner = comparison_lookup.get(key, \"Not found\")\n",
    "\n",
    "        row_data.append(winner)\n",
    "        focused_matrix_rows.append(row_data)\n",
    "\n",
    "# Build DataFrame\n",
    "focused_winners_df = pd.DataFrame(focused_matrix_rows,\n",
    "                                  columns=[\"Model\", \"Shot Type\", \"5 shot\"])\n",
    "\n",
    "# Save to CSV/Excel\n",
    "focused_winners_csv = \"mcnemar_results/mcnemar_focused_winners_pivot.csv\"\n",
    "focused_winners_xlsx = \"mcnemar_results/mcnemar_focused_winners_pivot.xlsx\"\n",
    "\n",
    "focused_winners_df.to_csv(focused_winners_csv, index=False)\n",
    "\n",
    "with pd.ExcelWriter(focused_winners_xlsx, engine=\"openpyxl\") as writer:\n",
    "    focused_winners_df.to_excel(writer, sheet_name=\"Focused Winners Pivot\", index=False)\n",
    "\n",
    "print(f\"✅ Focused winner pivot saved:\\n - {focused_winners_csv}\\n - {focused_winners_xlsx}\")\n",
    "\n",
    "print(\"\\nFocused Winner Pivot Preview:\")\n",
    "print(focused_winners_df.head().to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461db733-c4c0-4888-a674-f786932ace53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting F1 scores for Friedman test...\n",
      "Processing model: llama3_8b\n",
      "Processing model: llama3_70b\n",
      "Processing model: mistral_7b\n",
      "Processing model: gemma3_4b\n",
      "Processing model: wizardlm2_7b\n",
      "\n",
      "Running Friedman tests...\n",
      "\n",
      "Analyzing llama3_8b - pan:\n",
      "  Friedman χ² = 10.2400, p = 0.036573\n",
      "  Significant: Yes\n",
      "  Best config: 5-shot (rank = 3.70)\n",
      "\n",
      "Analyzing llama3_8b - maalej:\n",
      "  Friedman χ² = 29.3600, p = 0.000007\n",
      "  Significant: Yes\n",
      "  Best config: 7-shot (rank = 4.60)\n",
      "\n",
      "Analyzing llama3_8b - scalabrino:\n",
      "  Friedman χ² = 30.1600, p = 0.000005\n",
      "  Significant: Yes\n",
      "  Best config: 0-shot (rank = 4.40)\n",
      "\n",
      "Analyzing llama3_70b - pan:\n",
      "  Friedman χ² = 4.1600, p = 0.384785\n",
      "  Significant: No\n",
      "  Best config: 7-shot (rank = 3.60)\n",
      "\n",
      "Analyzing llama3_70b - maalej:\n",
      "  Friedman χ² = 18.8000, p = 0.000860\n",
      "  Significant: Yes\n",
      "  Best config: 3-shot (rank = 4.20)\n",
      "\n",
      "Analyzing llama3_70b - scalabrino:\n",
      "  Friedman χ² = 34.0000, p = 0.000001\n",
      "  Significant: Yes\n",
      "  Best config: 7-shot (rank = 4.80)\n",
      "\n",
      "Analyzing mistral_7b - pan:\n",
      "  Friedman χ² = 5.3600, p = 0.252312\n",
      "  Significant: No\n",
      "  Best config: 5-shot (rank = 3.90)\n",
      "\n",
      "Analyzing mistral_7b - maalej:\n",
      "  Friedman χ² = 24.5600, p = 0.000062\n",
      "  Significant: Yes\n",
      "  Best config: 0-shot (rank = 5.00)\n",
      "\n",
      "Analyzing mistral_7b - scalabrino:\n",
      "  Friedman χ² = 32.5600, p = 0.000001\n",
      "  Significant: Yes\n",
      "  Best config: 5-shot (rank = 4.30)\n",
      "\n",
      "Analyzing gemma3_4b - pan:\n",
      "  Friedman χ² = 26.5600, p = 0.000024\n",
      "  Significant: Yes\n",
      "  Best config: 5-shot (rank = 4.30)\n",
      "\n",
      "Analyzing gemma3_4b - maalej:\n",
      "  Friedman χ² = 30.8800, p = 0.000003\n",
      "  Significant: Yes\n",
      "  Best config: 1-shot (rank = 4.70)\n",
      "\n",
      "Analyzing gemma3_4b - scalabrino:\n",
      "  Friedman χ² = 35.2000, p = 0.000000\n",
      "  Significant: Yes\n",
      "  Best config: 7-shot (rank = 4.50)\n",
      "\n",
      "Analyzing wizardlm2_7b - pan:\n",
      "  Friedman χ² = 20.0000, p = 0.000499\n",
      "  Significant: Yes\n",
      "  Best config: 5-shot (rank = 4.10)\n",
      "\n",
      "Analyzing wizardlm2_7b - maalej:\n",
      "  Friedman χ² = 26.4000, p = 0.000026\n",
      "  Significant: Yes\n",
      "  Best config: 0-shot (rank = 4.30)\n",
      "\n",
      "Analyzing wizardlm2_7b - scalabrino:\n",
      "  Friedman χ² = 24.2400, p = 0.000071\n",
      "  Significant: Yes\n",
      "  Best config: 7-shot (rank = 4.30)\n",
      "\n",
      "Running post-hoc Nemenyi tests for significant results...\n",
      "\n",
      "Post-hoc analysis for llama3_8b - pan:\n",
      "  Nemenyi post-hoc test completed\n",
      "  Significant pairwise differences:\n",
      "    0-shot vs 5-shot: p = 0.0377\n",
      "\n",
      "Post-hoc analysis for llama3_8b - maalej:\n",
      "  Nemenyi post-hoc test completed\n",
      "  Significant pairwise differences:\n",
      "    0-shot vs 5-shot: p = 0.0013\n",
      "    0-shot vs 7-shot: p = 0.0001\n",
      "    1-shot vs 5-shot: p = 0.0248\n",
      "    1-shot vs 7-shot: p = 0.0022\n",
      "\n",
      "Post-hoc analysis for llama3_8b - scalabrino:\n",
      "  Nemenyi post-hoc test completed\n",
      "  Significant pairwise differences:\n",
      "    0-shot vs 1-shot: p = 0.0000\n",
      "    0-shot vs 3-shot: p = 0.0101\n",
      "    1-shot vs 5-shot: p = 0.0101\n",
      "    1-shot vs 7-shot: p = 0.0004\n",
      "\n",
      "Post-hoc analysis for llama3_70b - maalej:\n",
      "  Nemenyi post-hoc test completed\n",
      "  Significant pairwise differences:\n",
      "    0-shot vs 1-shot: p = 0.0248\n",
      "    0-shot vs 3-shot: p = 0.0013\n",
      "\n",
      "Post-hoc analysis for llama3_70b - scalabrino:\n",
      "  Nemenyi post-hoc test completed\n",
      "  Significant pairwise differences:\n",
      "    0-shot vs 1-shot: p = 0.0101\n",
      "    1-shot vs 5-shot: p = 0.0022\n",
      "    1-shot vs 7-shot: p = 0.0000\n",
      "    3-shot vs 7-shot: p = 0.0007\n",
      "\n",
      "Post-hoc analysis for mistral_7b - maalej:\n",
      "  Nemenyi post-hoc test completed\n",
      "  Significant pairwise differences:\n",
      "    0-shot vs 1-shot: p = 0.0000\n",
      "    0-shot vs 3-shot: p = 0.0062\n",
      "    0-shot vs 5-shot: p = 0.0037\n",
      "\n",
      "Post-hoc analysis for mistral_7b - scalabrino:\n",
      "  Nemenyi post-hoc test completed\n",
      "  Significant pairwise differences:\n",
      "    0-shot vs 3-shot: p = 0.0007\n",
      "    0-shot vs 5-shot: p = 0.0000\n",
      "    0-shot vs 7-shot: p = 0.0004\n",
      "    1-shot vs 5-shot: p = 0.0101\n",
      "\n",
      "Post-hoc analysis for gemma3_4b - pan:\n",
      "  Nemenyi post-hoc test completed\n",
      "  Significant pairwise differences:\n",
      "    0-shot vs 3-shot: p = 0.0037\n",
      "    0-shot vs 5-shot: p = 0.0001\n",
      "    0-shot vs 7-shot: p = 0.0022\n",
      "    1-shot vs 5-shot: p = 0.0377\n",
      "\n",
      "Post-hoc analysis for gemma3_4b - maalej:\n",
      "  Nemenyi post-hoc test completed\n",
      "  Significant pairwise differences:\n",
      "    0-shot vs 3-shot: p = 0.0037\n",
      "    0-shot vs 5-shot: p = 0.0377\n",
      "    0-shot vs 7-shot: p = 0.0062\n",
      "    1-shot vs 3-shot: p = 0.0004\n",
      "    1-shot vs 5-shot: p = 0.0062\n",
      "    1-shot vs 7-shot: p = 0.0007\n",
      "\n",
      "Post-hoc analysis for gemma3_4b - scalabrino:\n",
      "  Nemenyi post-hoc test completed\n",
      "  Significant pairwise differences:\n",
      "    0-shot vs 5-shot: p = 0.0062\n",
      "    0-shot vs 7-shot: p = 0.0022\n",
      "    1-shot vs 3-shot: p = 0.0248\n",
      "    1-shot vs 5-shot: p = 0.0001\n",
      "    1-shot vs 7-shot: p = 0.0000\n",
      "\n",
      "Post-hoc analysis for wizardlm2_7b - pan:\n",
      "  Nemenyi post-hoc test completed\n",
      "  Significant pairwise differences:\n",
      "    1-shot vs 5-shot: p = 0.0022\n",
      "    1-shot vs 7-shot: p = 0.0062\n",
      "\n",
      "Post-hoc analysis for wizardlm2_7b - maalej:\n",
      "  Nemenyi post-hoc test completed\n",
      "  Significant pairwise differences:\n",
      "    0-shot vs 1-shot: p = 0.0000\n",
      "    1-shot vs 5-shot: p = 0.0004\n",
      "    1-shot vs 7-shot: p = 0.0248\n",
      "\n",
      "Post-hoc analysis for wizardlm2_7b - scalabrino:\n",
      "  Nemenyi post-hoc test completed\n",
      "  Significant pairwise differences:\n",
      "    0-shot vs 1-shot: p = 0.0377\n",
      "    1-shot vs 3-shot: p = 0.0248\n",
      "    1-shot vs 5-shot: p = 0.0022\n",
      "    1-shot vs 7-shot: p = 0.0000\n",
      "\n",
      "============================================================\n",
      "FRIEDMAN TEST ANALYSIS COMPLETE\n",
      "============================================================\n",
      "\n",
      "Files created:\n",
      "Main results: friedman_analysis/friedman_test_results.csv\n",
      "Ranks summary: friedman_analysis/friedman_ranks_summary.csv\n",
      "Post-hoc tests: friedman_analysis/nemenyi_posthoc_results.csv\n",
      "Excel summary: friedman_analysis/friedman_analysis_complete.xlsx\n",
      "\n",
      "OVERALL SUMMARY:\n",
      "Total model-dataset combinations tested: 15\n",
      "Significant differences found: 13\n",
      "Percentage with significant differences: 86.7%\n",
      "\n",
      "BEST CONFIGURATIONS BY FREQUENCY:\n",
      "  5-shot: 4 cases (30.8%)\n",
      "  7-shot: 4 cases (30.8%)\n",
      "  0-shot: 3 cases (23.1%)\n",
      "  3-shot: 1 cases (7.7%)\n",
      "  1-shot: 1 cases (7.7%)\n",
      "\n",
      "SIGNIFICANT CASES:\n",
      "  llama3_8b - pan: 5-shot (p=0.0366)\n",
      "  llama3_8b - maalej: 7-shot (p=0.0000)\n",
      "  llama3_8b - scalabrino: 0-shot (p=0.0000)\n",
      "  llama3_70b - maalej: 3-shot (p=0.0009)\n",
      "  llama3_70b - scalabrino: 7-shot (p=0.0000)\n",
      "  mistral_7b - maalej: 0-shot (p=0.0001)\n",
      "  mistral_7b - scalabrino: 5-shot (p=0.0000)\n",
      "  gemma3_4b - pan: 5-shot (p=0.0000)\n",
      "  gemma3_4b - maalej: 1-shot (p=0.0000)\n",
      "  gemma3_4b - scalabrino: 7-shot (p=0.0000)\n",
      "  wizardlm2_7b - pan: 5-shot (p=0.0005)\n",
      "  wizardlm2_7b - maalej: 0-shot (p=0.0000)\n",
      "  wizardlm2_7b - scalabrino: 7-shot (p=0.0001)\n",
      "\n",
      "The Friedman test ranks configurations from 1 (best) to 5 (worst) based on performance.\n",
      "Lower rank = better performance. Post-hoc tests show which specific pairs differ significantly.\n"
     ]
    }
   ],
   "source": [
    "#friedman\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import friedmanchisquare\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────\n",
    "ZS_PREFIX = \"zero_shot_folds_\"\n",
    "FS_PREFIX = \"few_shot_folds_\"\n",
    "DATASETS = [\"pan\", \"maalej\", \"scalabrino\"]\n",
    "MODELS = [\"llama3_8b\", \"llama3_70b\", \"mistral_7b\", \"gemma3_4b\", \"wizardlm2_7b\"]\n",
    "K_SHOTS = [1, 3, 5, 7]\n",
    "FOLDS = range(10)\n",
    "OUT_DIR = \"friedman_analysis\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ─── LOAD PREDICTIONS ──────────────────\n",
    "def load_preds(model_name, dataset, fold, shot=None):\n",
    "    if shot is None:\n",
    "        path = os.path.join(f\"{ZS_PREFIX}{model_name}\", \"preds\", f\"{dataset}_fold{fold}_preds.csv\")\n",
    "    else:\n",
    "        path = os.path.join(f\"{FS_PREFIX}{model_name}_{dataset}\", \"preds\", f\"{dataset}_fold{fold}_{shot}shot_preds.csv\")\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        if 'gold' not in df.columns or 'pred' not in df.columns:\n",
    "            return None\n",
    "        return df[[\"text\", \"gold\", \"pred\"]]\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ─── COLLECT ALL F1 SCORES BY FOLD ──────────────────\n",
    "print(\"Collecting F1 scores for Friedman test...\")\n",
    "\n",
    "# Structure: [model][dataset][fold] = {shot_config: f1_score}\n",
    "fold_scores = {}\n",
    "\n",
    "for model in MODELS:\n",
    "    print(f\"Processing model: {model}\")\n",
    "    fold_scores[model] = {}\n",
    "    \n",
    "    for dataset in DATASETS:\n",
    "        fold_scores[model][dataset] = {}\n",
    "        \n",
    "        for fold in FOLDS:\n",
    "            fold_scores[model][dataset][fold] = {}\n",
    "            \n",
    "            # Zero-shot\n",
    "            df = load_preds(model, dataset, fold, shot=None)\n",
    "            if df is not None:\n",
    "                gold = df[\"gold\"].str.lower().str.strip()\n",
    "                pred = df[\"pred\"].str.lower().str.strip()\n",
    "                try:\n",
    "                    f1 = f1_score(gold, pred, average='macro', zero_division=0)\n",
    "                    fold_scores[model][dataset][fold]['0-shot'] = f1\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # Few-shot\n",
    "            for shot in K_SHOTS:\n",
    "                df = load_preds(model, dataset, fold, shot=shot)\n",
    "                if df is not None:\n",
    "                    gold = df[\"gold\"].str.lower().str.strip()\n",
    "                    pred = df[\"pred\"].str.lower().str.strip()\n",
    "                    try:\n",
    "                        f1 = f1_score(gold, pred, average='macro', zero_division=0)\n",
    "                        fold_scores[model][dataset][fold][f'{shot}-shot'] = f1\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "# ─── FRIEDMAN TEST ANALYSIS ──────────────────\n",
    "shot_configs = ['0-shot', '1-shot', '3-shot', '5-shot', '7-shot']\n",
    "friedman_results = []\n",
    "\n",
    "print(\"\\nRunning Friedman tests...\")\n",
    "\n",
    "for model in MODELS:\n",
    "    for dataset in DATASETS:\n",
    "        print(f\"\\nAnalyzing {model} - {dataset}:\")\n",
    "        \n",
    "        # Collect F1 scores for each shot configuration across folds\n",
    "        config_scores = {config: [] for config in shot_configs}\n",
    "        \n",
    "        for fold in FOLDS:\n",
    "            for config in shot_configs:\n",
    "                if (fold in fold_scores[model][dataset] and \n",
    "                    config in fold_scores[model][dataset][fold]):\n",
    "                    score = fold_scores[model][dataset][fold][config]\n",
    "                    config_scores[config].append(score)\n",
    "        \n",
    "        # Only proceed if we have complete data for all configurations\n",
    "        min_folds = min(len(scores) for scores in config_scores.values())\n",
    "        if min_folds < 3:  # Need at least 3 folds for meaningful test\n",
    "            print(f\"  Insufficient data (only {min_folds} complete folds)\")\n",
    "            continue\n",
    "        \n",
    "        # Truncate all to same length (in case some configurations have more folds)\n",
    "        for config in shot_configs:\n",
    "            config_scores[config] = config_scores[config][:min_folds]\n",
    "        \n",
    "        # Run Friedman test\n",
    "        score_arrays = [config_scores[config] for config in shot_configs]\n",
    "        \n",
    "        try:\n",
    "            statistic, p_value = friedmanchisquare(*score_arrays)\n",
    "            \n",
    "            # Calculate mean ranks (for interpretation)\n",
    "            df_ranks = pd.DataFrame(config_scores)\n",
    "            ranks = df_ranks.rank(axis=1, method='average')\n",
    "            mean_ranks = ranks.mean()\n",
    "            \n",
    "            # Determine best configuration\n",
    "            best_config = mean_ranks.idxmax()\n",
    "            best_mean_f1 = np.mean(config_scores[best_config])\n",
    "            \n",
    "            friedman_results.append({\n",
    "                'Model': model,\n",
    "                'Dataset': dataset,\n",
    "                'Friedman_Statistic': statistic,\n",
    "                'P_Value': p_value,\n",
    "                'Significant': p_value < 0.05,\n",
    "                'Num_Folds': min_folds,\n",
    "                'Best_Config': best_config,\n",
    "                'Best_Mean_F1': best_mean_f1,\n",
    "                '0_shot_rank': mean_ranks['0-shot'],\n",
    "                '1_shot_rank': mean_ranks['1-shot'],\n",
    "                '3_shot_rank': mean_ranks['3-shot'],\n",
    "                '5_shot_rank': mean_ranks['5-shot'],\n",
    "                '7_shot_rank': mean_ranks['7-shot'],\n",
    "                '0_shot_mean_f1': np.mean(config_scores['0-shot']),\n",
    "                '1_shot_mean_f1': np.mean(config_scores['1-shot']),\n",
    "                '3_shot_mean_f1': np.mean(config_scores['3-shot']),\n",
    "                '5_shot_mean_f1': np.mean(config_scores['5-shot']),\n",
    "                '7_shot_mean_f1': np.mean(config_scores['7-shot'])\n",
    "            })\n",
    "            \n",
    "            print(f\"  Friedman χ² = {statistic:.4f}, p = {p_value:.6f}\")\n",
    "            print(f\"  Significant: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "            print(f\"  Best config: {best_config} (rank = {mean_ranks[best_config]:.2f})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error in Friedman test: {e}\")\n",
    "\n",
    "# ─── POST-HOC ANALYSIS (NEMENYI TEST) ──────────────────\n",
    "print(\"\\nRunning post-hoc Nemenyi tests for significant results...\")\n",
    "\n",
    "posthoc_results = []\n",
    "\n",
    "for result in friedman_results:\n",
    "    if result['Significant']:\n",
    "        model = result['Model']\n",
    "        dataset = result['Dataset']\n",
    "        \n",
    "        print(f\"\\nPost-hoc analysis for {model} - {dataset}:\")\n",
    "        \n",
    "        # Reconstruct data for post-hoc test\n",
    "        config_scores = {config: [] for config in shot_configs}\n",
    "        \n",
    "        for fold in FOLDS:\n",
    "            if fold in fold_scores[model][dataset]:\n",
    "                for config in shot_configs:\n",
    "                    if config in fold_scores[model][dataset][fold]:\n",
    "                        score = fold_scores[model][dataset][fold][config]\n",
    "                        config_scores[config].append(score)\n",
    "        \n",
    "        # Create matrix for post-hoc test\n",
    "        min_folds = min(len(scores) for scores in config_scores.values())\n",
    "        data_matrix = []\n",
    "        for i in range(min_folds):\n",
    "            row = [config_scores[config][i] for config in shot_configs]\n",
    "            data_matrix.append(row)\n",
    "        \n",
    "        df_posthoc = pd.DataFrame(data_matrix, columns=shot_configs)\n",
    "        \n",
    "        try:\n",
    "            # Nemenyi test\n",
    "            nemenyi_result = sp.posthoc_nemenyi_friedman(df_posthoc)\n",
    "            \n",
    "            # Store pairwise comparisons\n",
    "            for i, config1 in enumerate(shot_configs):\n",
    "                for j, config2 in enumerate(shot_configs):\n",
    "                    if i < j:  # Only upper triangle\n",
    "                        p_val = nemenyi_result.iloc[i, j]\n",
    "                        posthoc_results.append({\n",
    "                            'Model': model,\n",
    "                            'Dataset': dataset,\n",
    "                            'Config1': config1,\n",
    "                            'Config2': config2,\n",
    "                            'P_Value': p_val,\n",
    "                            'Significant': p_val < 0.05,\n",
    "                            'Config1_Rank': result[f'{config1.replace(\"-\", \"_\")}_rank'],\n",
    "                            'Config2_Rank': result[f'{config2.replace(\"-\", \"_\")}_rank'],\n",
    "                            'Config1_F1': result[f'{config1.replace(\"-\", \"_\")}_mean_f1'],\n",
    "                            'Config2_F1': result[f'{config2.replace(\"-\", \"_\")}_mean_f1']\n",
    "                        })\n",
    "            \n",
    "            print(f\"  Nemenyi post-hoc test completed\")\n",
    "            print(f\"  Significant pairwise differences:\")\n",
    "            significant_pairs = [(i, j) for i, config1 in enumerate(shot_configs) \n",
    "                               for j, config2 in enumerate(shot_configs) \n",
    "                               if i < j and nemenyi_result.iloc[i, j] < 0.05]\n",
    "            \n",
    "            for i, j in significant_pairs:\n",
    "                config1, config2 = shot_configs[i], shot_configs[j]\n",
    "                p_val = nemenyi_result.iloc[i, j]\n",
    "                print(f\"    {config1} vs {config2}: p = {p_val:.4f}\")\n",
    "            \n",
    "            if not significant_pairs:\n",
    "                print(f\"    No significant pairwise differences found\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error in post-hoc test: {e}\")\n",
    "\n",
    "# ─── CREATE SUMMARY TABLES ──────────────────\n",
    "friedman_df = pd.DataFrame(friedman_results)\n",
    "posthoc_df = pd.DataFrame(posthoc_results)\n",
    "\n",
    "# Save main results\n",
    "friedman_csv = os.path.join(OUT_DIR, \"friedman_test_results.csv\")\n",
    "friedman_df.to_csv(friedman_csv, index=False)\n",
    "\n",
    "if len(posthoc_df) > 0:\n",
    "    posthoc_csv = os.path.join(OUT_DIR, \"nemenyi_posthoc_results.csv\")\n",
    "    posthoc_df.to_csv(posthoc_csv, index=False)\n",
    "\n",
    "# ─── CREATE RANKS SUMMARY TABLE ──────────────────\n",
    "ranks_data = []\n",
    "for _, row in friedman_df.iterrows():\n",
    "    rank_row = {\n",
    "        'Model': row['Model'],\n",
    "        'Dataset': row['Dataset'],\n",
    "        'Significant': 'Yes' if row['Significant'] else 'No',\n",
    "        '0-shot': f\"{row['0_shot_rank']:.2f}\",\n",
    "        '1-shot': f\"{row['1_shot_rank']:.2f}\",\n",
    "        '3-shot': f\"{row['3_shot_rank']:.2f}\",\n",
    "        '5-shot': f\"{row['5_shot_rank']:.2f}\",\n",
    "        '7-shot': f\"{row['7_shot_rank']:.2f}\",\n",
    "        'Best_Config': row['Best_Config']\n",
    "    }\n",
    "    ranks_data.append(rank_row)\n",
    "\n",
    "ranks_df = pd.DataFrame(ranks_data)\n",
    "ranks_csv = os.path.join(OUT_DIR, \"friedman_ranks_summary.csv\")\n",
    "ranks_df.to_csv(ranks_csv, index=False)\n",
    "\n",
    "# ─── CREATE EXCEL FILES WITH FORMATTING ──────────────────\n",
    "excel_file = os.path.join(OUT_DIR, \"friedman_analysis_complete.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "    # Main Friedman results\n",
    "    friedman_df.to_excel(writer, sheet_name='Friedman Test', index=False)\n",
    "    \n",
    "    # Ranks summary\n",
    "    ranks_df.to_excel(writer, sheet_name='Ranks Summary', index=False)\n",
    "    \n",
    "    # Post-hoc results (if any)\n",
    "    if len(posthoc_df) > 0:\n",
    "        posthoc_df.to_excel(writer, sheet_name='Nemenyi Post-hoc', index=False)\n",
    "    \n",
    "    # Format sheets\n",
    "    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "    \n",
    "    header_font = Font(bold=True, color=\"FFFFFF\")\n",
    "    header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
    "    center_alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "    thin_border = Border(\n",
    "        left=Side(style='thin'), right=Side(style='thin'),\n",
    "        top=Side(style='thin'), bottom=Side(style='thin')\n",
    "    )\n",
    "    \n",
    "    for sheet_name in writer.sheets:\n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "        \n",
    "        # Format headers\n",
    "        for cell in worksheet[1]:\n",
    "            cell.font = header_font\n",
    "            cell.fill = header_fill\n",
    "            cell.alignment = center_alignment\n",
    "            cell.border = thin_border\n",
    "        \n",
    "        # Format data cells\n",
    "        for row in worksheet.iter_rows(min_row=2):\n",
    "            for cell in row:\n",
    "                cell.alignment = center_alignment\n",
    "                cell.border = thin_border\n",
    "        \n",
    "        # Auto-adjust column widths\n",
    "        for column in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 2, 25)\n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "# ─── PRINT RESULTS ──────────────────\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FRIEDMAN TEST ANALYSIS COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"Main results: {friedman_csv}\")\n",
    "print(f\"Ranks summary: {ranks_csv}\")\n",
    "if len(posthoc_df) > 0:\n",
    "    print(f\"Post-hoc tests: {posthoc_csv}\")\n",
    "print(f\"Excel summary: {excel_file}\")\n",
    "\n",
    "print(f\"\\nOVERALL SUMMARY:\")\n",
    "total_tests = len(friedman_df)\n",
    "significant_tests = sum(friedman_df['Significant'])\n",
    "print(f\"Total model-dataset combinations tested: {total_tests}\")\n",
    "print(f\"Significant differences found: {significant_tests}\")\n",
    "print(f\"Percentage with significant differences: {significant_tests/total_tests*100:.1f}%\")\n",
    "\n",
    "if significant_tests > 0:\n",
    "    print(f\"\\nBEST CONFIGURATIONS BY FREQUENCY:\")\n",
    "    best_configs = friedman_df[friedman_df['Significant']]['Best_Config'].value_counts()\n",
    "    for config, count in best_configs.items():\n",
    "        print(f\"  {config}: {count} cases ({count/significant_tests*100:.1f}%)\")\n",
    "\n",
    "    print(f\"\\nSIGNIFICANT CASES:\")\n",
    "    sig_cases = friedman_df[friedman_df['Significant']]\n",
    "    for _, row in sig_cases.iterrows():\n",
    "        print(f\"  {row['Model']} - {row['Dataset']}: {row['Best_Config']} \"\n",
    "              f\"(p={row['P_Value']:.4f})\")\n",
    "\n",
    "print(f\"\\nThe Friedman test ranks configurations from 1 (best) to 5 (worst) based on performance.\")\n",
    "print(f\"Lower rank = better performance. Post-hoc tests show which specific pairs differ significantly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "157fa8de-e555-4a24-9a8b-70c071d09705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running McNemar tests for 5-shot model vs model comparisons...\n",
      "Comparing llama3_8b vs llama3_70b\n",
      "Comparing llama3_8b vs mistral_7b\n",
      "Comparing llama3_8b vs gemma3_4b\n",
      "Comparing llama3_8b vs wizardlm2_7b\n",
      "Comparing llama3_70b vs mistral_7b\n",
      "Comparing llama3_70b vs gemma3_4b\n",
      "Comparing llama3_70b vs wizardlm2_7b\n",
      "Comparing mistral_7b vs gemma3_4b\n",
      "Comparing mistral_7b vs wizardlm2_7b\n",
      "Comparing gemma3_4b vs wizardlm2_7b\n",
      "\n",
      "Files saved:\n",
      "CSV: mcnemar_results/mcnemar_5shot_model_comparison.csv\n",
      "Structured Matrix CSV: mcnemar_results/mcnemar_5shot_structured_matrix.csv\n",
      "Excel: mcnemar_results/mcnemar_5shot_model_comparison.xlsx\n",
      "\n",
      "🏆 WINNER ANALYSIS - 5-Shot Performance:\n",
      "==================================================\n",
      "🥇 BEST MODEL: gemma3_4b\n",
      "   Average Accuracy: 0.5928\n",
      "   Significant Wins: 4\n",
      "   Significant Losses: 0\n",
      "   Win Rate: 1.000\n",
      "\n",
      "🥈 SECOND BEST: llama3_70b\n",
      "   Average Accuracy: 0.5612\n",
      "   Significant Wins: 3\n",
      "   Significant Losses: 1\n",
      "   Win Rate: 0.750\n",
      "\n",
      "📊 ALL MODEL RANKINGS:\n",
      "----------------------------------------\n",
      "1. gemma3_4b       | Acc: 0.5928 | W/L: 4/0 | Win Rate: 1.000\n",
      "2. llama3_70b      | Acc: 0.5612 | W/L: 3/1 | Win Rate: 0.750\n",
      "3. wizardlm2_7b    | Acc: 0.5183 | W/L: 1/2 | Win Rate: 0.333\n",
      "4. mistral_7b      | Acc: 0.5110 | W/L: 1/2 | Win Rate: 0.333\n",
      "5. llama3_8b       | Acc: 0.4877 | W/L: 0/4 | Win Rate: 0.000\n",
      "\n",
      "Summary of 5-shot model comparisons:\n",
      "Total comparisons: 10\n",
      "Significant differences (p < 0.05): 9\n",
      "\n",
      "Most significant differences:\n",
      "🔥 llama3_70b > llama3_8b: p = 0.000000, Acc diff = 0.0735\n",
      "🔥 gemma3_4b > llama3_8b: p = 0.000000, Acc diff = 0.1052\n",
      "🔥 wizardlm2_7b > llama3_8b: p = 0.000000, Acc diff = 0.0307\n",
      "🔥 llama3_70b > mistral_7b: p = 0.000000, Acc diff = 0.0502\n",
      "🔥 llama3_70b > wizardlm2_7b: p = 0.000000, Acc diff = 0.0428\n",
      "\n",
      "Structured matrix format saved as: mcnemar_results/mcnemar_5shot_structured_matrix.csv\n",
      "This matches the format shown in your screenshot with:\n",
      "- Model names in first column\n",
      "- Shot type (5 shot) in second column\n",
      "- (Chi-square/P-value) format in remaining columns\n",
      "- Each row represents one model's 5-shot performance vs all others\n",
      "✅ Files saved:\n",
      " - mcnemar_results/focused_llama3_70b_vs_gemma_wizard.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────\n",
    "FS_PREFIX = \"few_shot_folds_\"\n",
    "DATASETS = [\"pan\", \"maalej\", \"scalabrino\"]\n",
    "MODELS = [\"llama3_8b\", \"llama3_70b\", \"mistral_7b\", \"gemma3_4b\", \"wizardlm2_7b\"]\n",
    "SHOT_COUNT = 5  # Focus on 5-shot comparisons\n",
    "FOLDS = range(10)\n",
    "OUT_CSV = \"mcnemar_results/mcnemar_5shot_model_comparison.csv\"\n",
    "OUT_EXCEL = \"mcnemar_results/mcnemar_5shot_model_comparison.xlsx\"\n",
    "os.makedirs(\"mcnemar_results\", exist_ok=True)\n",
    "\n",
    "# ─── LOAD PREDICTIONS ──────────────────\n",
    "def load_preds(model_name, dataset, fold, shot=5):\n",
    "    path = os.path.join(f\"{FS_PREFIX}{model_name}_{dataset}\", \"preds\", f\"{dataset}_fold{fold}_{shot}shot_preds.csv\")\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Missing file: {path}\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    return df[[\"text\", \"gold\", \"pred\"]]\n",
    "\n",
    "# ─── RUN MCNEMAR TEST ──────────────────\n",
    "all_results = []\n",
    "\n",
    "print(\"Running McNemar tests for 5-shot model vs model comparisons...\")\n",
    "\n",
    "# Generate all pairwise model comparisons\n",
    "for i, model1 in enumerate(MODELS):\n",
    "    for model2 in MODELS[i+1:]:  # Only upper triangular comparisons\n",
    "        print(f\"Comparing {model1} vs {model2}\")\n",
    "        \n",
    "        p1_all, p2_all = [], []\n",
    "        \n",
    "        for dataset in DATASETS:\n",
    "            for fold in FOLDS:\n",
    "                df1 = load_preds(model1, dataset, fold, SHOT_COUNT)\n",
    "                df2 = load_preds(model2, dataset, fold, SHOT_COUNT)\n",
    "                \n",
    "                if df1 is None or df2 is None:\n",
    "                    continue\n",
    "                \n",
    "                # Use inner join to handle mismatched samples\n",
    "                merged = pd.merge(df1, df2, on=\"text\", suffixes=(\"_1\", \"_2\"), how=\"inner\")\n",
    "                \n",
    "                gold = merged[\"gold_1\"].str.lower().str.strip()\n",
    "                pred1 = merged[\"pred_1\"].str.lower().str.strip()\n",
    "                pred2 = merged[\"pred_2\"].str.lower().str.strip()\n",
    "                \n",
    "                for y, p1, p2 in zip(gold, pred1, pred2):\n",
    "                    p1_all.append(p1 == y)\n",
    "                    p2_all.append(p2 == y)\n",
    "        \n",
    "        if len(p1_all) == 0:\n",
    "            print(f\"No data found for {model1} vs {model2}\")\n",
    "            continue\n",
    "        \n",
    "        # McNemar contingency table\n",
    "        both_correct = sum(p1 and p2 for p1, p2 in zip(p1_all, p2_all))\n",
    "        only_model1 = sum(p1 and not p2 for p1, p2 in zip(p1_all, p2_all))\n",
    "        only_model2 = sum(p2 and not p1 for p1, p2 in zip(p1_all, p2_all))\n",
    "        both_wrong = sum(not p1 and not p2 for p1, p2 in zip(p1_all, p2_all))\n",
    "        \n",
    "        table = [[both_correct, only_model1], [only_model2, both_wrong]]\n",
    "        \n",
    "        # Run McNemar test\n",
    "        result = mcnemar(table, exact=False, correction=True)\n",
    "        \n",
    "        # Calculate accuracies\n",
    "        acc1 = sum(p1_all) / len(p1_all)\n",
    "        acc2 = sum(p2_all) / len(p2_all)\n",
    "        \n",
    "        all_results.append({\n",
    "            \"Model_1\": model1,\n",
    "            \"Model_2\": model2,\n",
    "            \"Model_1_Accuracy\": acc1,\n",
    "            \"Model_2_Accuracy\": acc2,\n",
    "            \"Accuracy_Diff\": acc2 - acc1,\n",
    "            \"Both_Correct\": both_correct,\n",
    "            \"Only_Model_1\": only_model1,\n",
    "            \"Only_Model_2\": only_model2,\n",
    "            \"Both_Wrong\": both_wrong,\n",
    "            \"Total_Samples\": len(p1_all),\n",
    "            \"Chi_Square\": result.statistic,\n",
    "            \"P_Value\": result.pvalue,\n",
    "            \"Significant\": result.pvalue < 0.05\n",
    "        })\n",
    "\n",
    "# ─── CREATE RESULTS TABLE ──────────────────\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Round numerical columns for better display\n",
    "results_df[\"Model_1_Accuracy\"] = results_df[\"Model_1_Accuracy\"].round(4)\n",
    "results_df[\"Model_2_Accuracy\"] = results_df[\"Model_2_Accuracy\"].round(4)\n",
    "results_df[\"Accuracy_Diff\"] = results_df[\"Accuracy_Diff\"].round(4)\n",
    "results_df[\"Chi_Square\"] = results_df[\"Chi_Square\"].round(4)\n",
    "results_df[\"P_Value\"] = results_df[\"P_Value\"].round(6)\n",
    "\n",
    "# Sort by p-value for easier interpretation\n",
    "results_df = results_df.sort_values(\"P_Value\")\n",
    "\n",
    "# Save CSV\n",
    "results_df.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "# ─── CREATE MATRIX VIEW ──────────────────\n",
    "# Create a matrix showing p-values for all pairwise comparisons\n",
    "matrix_data = []\n",
    "\n",
    "for model1 in MODELS:\n",
    "    row = [model1]  # Start with model name\n",
    "    \n",
    "    for model2 in MODELS:\n",
    "        if model1 == model2:\n",
    "            row.append(\"-\")  # Diagonal\n",
    "        else:\n",
    "            # Find the comparison (could be either direction)\n",
    "            comparison = next((r for r in all_results \n",
    "                             if (r['Model_1'] == model1 and r['Model_2'] == model2) or\n",
    "                                (r['Model_1'] == model2 and r['Model_2'] == model1)), None)\n",
    "            \n",
    "            if comparison:\n",
    "                p_val = comparison['P_Value']\n",
    "                significance = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"\"\n",
    "                row.append(f\"{p_val:.4f}{significance}\")\n",
    "            else:\n",
    "                row.append(\"\")\n",
    "    \n",
    "    matrix_data.append(row)\n",
    "\n",
    "# Create matrix DataFrame\n",
    "matrix_columns = [\"Model\"] + MODELS\n",
    "matrix_df = pd.DataFrame(matrix_data, columns=matrix_columns)\n",
    "\n",
    "# ─── CREATE STRUCTURED MATRIX LIKE YOUR SCREENSHOT ──────────────────\n",
    "# This creates the format you showed: Model rows with shot type sub-rows\n",
    "structured_matrix_data = []\n",
    "\n",
    "for model in MODELS:\n",
    "    # Create a row for this model showing comparisons with all other models\n",
    "    row = [model, \"5 shot\"]  # Model name and shot type\n",
    "    \n",
    "    # Add comparisons with each other model\n",
    "    for other_model in MODELS:\n",
    "        if model == other_model:\n",
    "            row.append(\"-\")  # Same model\n",
    "        else:\n",
    "            # Find comparison between this model and other_model\n",
    "            comparison = next((r for r in all_results \n",
    "                             if (r['Model_1'] == model and r['Model_2'] == other_model) or\n",
    "                                (r['Model_1'] == other_model and r['Model_2'] == model)), None)\n",
    "            \n",
    "            if comparison:\n",
    "                chi_val = comparison['Chi_Square']\n",
    "                p_val = comparison['P_Value']\n",
    "                row.append(f\"({chi_val:.3f}/{p_val:.3f})\")\n",
    "            else:\n",
    "                row.append(\"\")\n",
    "    \n",
    "    structured_matrix_data.append(row)\n",
    "\n",
    "# Create structured matrix DataFrame (like your screenshot)\n",
    "structured_columns = [\"Model\", \"Shot Type\"] + MODELS\n",
    "structured_matrix_df = pd.DataFrame(structured_matrix_data, columns=structured_columns)\n",
    "\n",
    "# Save additional structured matrix CSV\n",
    "structured_csv = \"mcnemar_results/mcnemar_5shot_structured_matrix.csv\"\n",
    "structured_matrix_df.to_csv(structured_csv, index=False)\n",
    "\n",
    "# ─── DETERMINE WINNER MODEL ──────────────────\n",
    "# Calculate overall performance metrics for each model\n",
    "model_performance = {}\n",
    "\n",
    "for model in MODELS:\n",
    "    # Get all accuracy values for this model (both as Model_1 and Model_2)\n",
    "    model1_results = results_df[results_df['Model_1'] == model]['Model_1_Accuracy'].tolist()\n",
    "    model2_results = results_df[results_df['Model_2'] == model]['Model_2_Accuracy'].tolist()\n",
    "    \n",
    "    all_accuracies = model1_results + model2_results\n",
    "    \n",
    "    if all_accuracies:\n",
    "        avg_accuracy = sum(all_accuracies) / len(all_accuracies)\n",
    "    else:\n",
    "        avg_accuracy = 0\n",
    "    \n",
    "    # Count wins (significantly better performance)\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    \n",
    "    for _, row in results_df.iterrows():\n",
    "        if row['Significant']:\n",
    "            if row['Model_1'] == model and row['Accuracy_Diff'] < 0:  # Model_1 (this model) is better\n",
    "                wins += 1\n",
    "            elif row['Model_2'] == model and row['Accuracy_Diff'] > 0:  # Model_2 (this model) is better\n",
    "                wins += 1\n",
    "            elif row['Model_1'] == model and row['Accuracy_Diff'] > 0:  # Model_1 (this model) is worse\n",
    "                losses += 1\n",
    "            elif row['Model_2'] == model and row['Accuracy_Diff'] < 0:  # Model_2 (this model) is worse\n",
    "                losses += 1\n",
    "    \n",
    "    model_performance[model] = {\n",
    "        'avg_accuracy': avg_accuracy,\n",
    "        'wins': wins,\n",
    "        'losses': losses,\n",
    "        'win_rate': wins / (wins + losses) if (wins + losses) > 0 else 0\n",
    "    }\n",
    "\n",
    "# Find the winner\n",
    "best_model = max(model_performance.keys(), \n",
    "                key=lambda x: (model_performance[x]['avg_accuracy'], \n",
    "                              model_performance[x]['win_rate']))\n",
    "\n",
    "second_best = sorted(model_performance.keys(), \n",
    "                    key=lambda x: (model_performance[x]['avg_accuracy'], \n",
    "                                  model_performance[x]['win_rate']), \n",
    "                    reverse=True)[1]\n",
    "\n",
    "# ─── SAVE EXCEL WITH MULTIPLE SHEETS ──────────────────\n",
    "# Save as Excel with multiple sheets\n",
    "with pd.ExcelWriter(OUT_EXCEL, engine='openpyxl') as writer:\n",
    "    # Sheet 1: Detailed results\n",
    "    results_df.to_excel(writer, sheet_name='Detailed Results', index=False)\n",
    "    \n",
    "    # Sheet 2: P-value matrix\n",
    "    matrix_df.to_excel(writer, sheet_name='P-Value Matrix', index=False)\n",
    "    \n",
    "    # Sheet 3: Structured matrix (like your screenshot)\n",
    "    structured_matrix_df.to_excel(writer, sheet_name='Structured Matrix', index=False)\n",
    "    \n",
    "    # Format the sheets\n",
    "    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "    \n",
    "    # Define styles\n",
    "    header_font = Font(bold=True, color=\"FFFFFF\")\n",
    "    header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
    "    model_font = Font(bold=True)\n",
    "    model_fill = PatternFill(start_color=\"D9D9D9\", end_color=\"D9D9D9\", fill_type=\"solid\")\n",
    "    significant_fill = PatternFill(start_color=\"FFE6E6\", end_color=\"FFE6E6\", fill_type=\"solid\")\n",
    "    center_alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "    thin_border = Border(\n",
    "        left=Side(style='thin'), right=Side(style='thin'),\n",
    "        top=Side(style='thin'), bottom=Side(style='thin')\n",
    "    )\n",
    "    \n",
    "    # Format detailed results sheet\n",
    "    ws1 = writer.sheets['Detailed Results']\n",
    "    for cell in ws1[1]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "        cell.alignment = center_alignment\n",
    "        cell.border = thin_border\n",
    "    \n",
    "    # Highlight significant results\n",
    "    for row in range(2, ws1.max_row + 1):\n",
    "        p_val_cell = ws1[f'L{row}']  # P_Value column\n",
    "        significant_cell = ws1[f'M{row}']  # Significant column\n",
    "        \n",
    "        if significant_cell.value:\n",
    "            for col in range(1, ws1.max_column + 1):\n",
    "                ws1.cell(row=row, column=col).fill = significant_fill\n",
    "    \n",
    "    # Format matrix sheet\n",
    "    ws2 = writer.sheets['P-Value Matrix']\n",
    "    for cell in ws2[1]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "        cell.alignment = center_alignment\n",
    "        cell.border = thin_border\n",
    "    \n",
    "    # Format structured matrix sheet (like your screenshot)\n",
    "    ws3 = writer.sheets['Structured Matrix']\n",
    "    \n",
    "    # Format header row\n",
    "    for cell in ws3[1]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "        cell.alignment = center_alignment\n",
    "        cell.border = thin_border\n",
    "    \n",
    "    # Format data rows with model name styling\n",
    "    for row in range(2, ws3.max_row + 1):\n",
    "        model_cell = ws3[f'A{row}']\n",
    "        model_cell.font = model_font\n",
    "        model_cell.fill = model_fill\n",
    "        model_cell.alignment = center_alignment\n",
    "        model_cell.border = thin_border\n",
    "        \n",
    "        # Format other cells in the row\n",
    "        for col in range(2, ws3.max_column + 1):\n",
    "            cell = ws3.cell(row=row, column=col)\n",
    "            cell.alignment = center_alignment\n",
    "            cell.border = thin_border\n",
    "    \n",
    "    # Auto-adjust column widths for all sheets\n",
    "    for worksheet in [ws1, ws2, ws3]:\n",
    "        for column in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 2, 25)\n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "# ─── PRINT RESULTS ──────────────────\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"CSV: {OUT_CSV}\")\n",
    "print(f\"Structured Matrix CSV: {structured_csv}\")\n",
    "print(f\"Excel: {OUT_EXCEL}\")\n",
    "\n",
    "print(f\"\\n🏆 WINNER ANALYSIS - 5-Shot Performance:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"🥇 BEST MODEL: {best_model}\")\n",
    "print(f\"   Average Accuracy: {model_performance[best_model]['avg_accuracy']:.4f}\")\n",
    "print(f\"   Significant Wins: {model_performance[best_model]['wins']}\")\n",
    "print(f\"   Significant Losses: {model_performance[best_model]['losses']}\")\n",
    "print(f\"   Win Rate: {model_performance[best_model]['win_rate']:.3f}\")\n",
    "\n",
    "print(f\"\\n🥈 SECOND BEST: {second_best}\")\n",
    "print(f\"   Average Accuracy: {model_performance[second_best]['avg_accuracy']:.4f}\")\n",
    "print(f\"   Significant Wins: {model_performance[second_best]['wins']}\")\n",
    "print(f\"   Significant Losses: {model_performance[second_best]['losses']}\")\n",
    "print(f\"   Win Rate: {model_performance[second_best]['win_rate']:.3f}\")\n",
    "\n",
    "print(f\"\\n📊 ALL MODEL RANKINGS:\")\n",
    "print(\"-\" * 40)\n",
    "sorted_models = sorted(model_performance.items(), \n",
    "                      key=lambda x: (x[1]['avg_accuracy'], x[1]['win_rate']), \n",
    "                      reverse=True)\n",
    "\n",
    "for i, (model, stats) in enumerate(sorted_models, 1):\n",
    "    print(f\"{i}. {model:<15} | Acc: {stats['avg_accuracy']:.4f} | \"\n",
    "          f\"W/L: {stats['wins']}/{stats['losses']} | \"\n",
    "          f\"Win Rate: {stats['win_rate']:.3f}\")\n",
    "\n",
    "print(f\"\\nSummary of 5-shot model comparisons:\")\n",
    "print(f\"Total comparisons: {len(results_df)}\")\n",
    "print(f\"Significant differences (p < 0.05): {sum(results_df['Significant'])}\")\n",
    "\n",
    "# Print top significant differences\n",
    "print(\"\\nMost significant differences:\")\n",
    "significant_results = results_df[results_df['Significant']].head(5)\n",
    "for _, row in significant_results.iterrows():\n",
    "    winner = row['Model_1'] if row['Accuracy_Diff'] < 0 else row['Model_2']\n",
    "    loser = row['Model_2'] if row['Accuracy_Diff'] < 0 else row['Model_1']\n",
    "    print(f\"🔥 {winner} > {loser}: p = {row['P_Value']:.6f}, \"\n",
    "          f\"Acc diff = {abs(row['Accuracy_Diff']):.4f}\")\n",
    "\n",
    "print(f\"\\nStructured matrix format saved as: {structured_csv}\")\n",
    "print(\"This matches the format shown in your screenshot with:\")\n",
    "print(\"- Model names in first column\")\n",
    "print(\"- Shot type (5 shot) in second column\") \n",
    "print(\"- (Chi-square/P-value) format in remaining columns\")\n",
    "print(\"- Each row represents one model's 5-shot performance vs all others\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac897f7d-3de6-48d3-9381-3f0aa6a0fbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Structured pivot table with chi2 saved to:\n",
      "→ mcnemar_results/focused_llama70b_vs_gemma_wizard_chi2.csv\n",
      "✅ Structured winner table saved to:\n",
      "→ mcnemar_results/focused_llama70b_vs_gemma_wizard_winner.csv\n",
      "✅ Excel file with both sheets saved to:\n",
      "→ mcnemar_results/focused_llama70b_vs_gemma_wizard.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────\n",
    "IN_CSV = \"mcnemar_results/mcnemar_5shot_model_comparison.csv\"\n",
    "OUT_DIR = \"mcnemar_results\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_MODEL = \"llama3_70b\"\n",
    "COMPARE_MODELS = [\"gemma3_4b\", \"wizardlm2_7b\"]\n",
    "MODELS = COMPARE_MODELS + [TARGET_MODEL]\n",
    "\n",
    "# ─── LOAD FULL MCNEMAR RESULTS ─────────\n",
    "df = pd.read_csv(IN_CSV)\n",
    "\n",
    "# ─── STRUCTURED CHI2/PIVALUE TABLE ─────\n",
    "structured_chi2 = []\n",
    "for model in MODELS:\n",
    "    row = [model, \"5 shot\"]\n",
    "    for other in MODELS:\n",
    "        if model == other:\n",
    "            row.append(\"-\")\n",
    "        else:\n",
    "            comp = df[((df[\"Model_1\"] == model) & (df[\"Model_2\"] == other)) |\n",
    "                      ((df[\"Model_1\"] == other) & (df[\"Model_2\"] == model))]\n",
    "            if not comp.empty:\n",
    "                chi = comp[\"Chi_Square\"].values[0]\n",
    "                p = comp[\"P_Value\"].values[0]\n",
    "                row.append(f\"({chi:.3f}/{p:.3f})\")\n",
    "            else:\n",
    "                row.append(\"\")\n",
    "    structured_chi2.append(row)\n",
    "\n",
    "columns = [\"Model\", \"Shot Type\"] + MODELS\n",
    "df_chi2 = pd.DataFrame(structured_chi2, columns=columns)\n",
    "chi2_csv = os.path.join(OUT_DIR, \"focused_llama70b_vs_gemma_wizard_chi2.csv\")\n",
    "df_chi2.to_csv(chi2_csv, index=False)\n",
    "\n",
    "# ─── STRUCTURED WINNER TABLE ───────────\n",
    "structured_winner = []\n",
    "for model in MODELS:\n",
    "    row = [model, \"5 shot\"]\n",
    "    for other in MODELS:\n",
    "        if model == other:\n",
    "            row.append(\"-\")\n",
    "        else:\n",
    "            comp = df[((df[\"Model_1\"] == model) & (df[\"Model_2\"] == other)) |\n",
    "                      ((df[\"Model_1\"] == other) & (df[\"Model_2\"] == model))]\n",
    "            if not comp.empty:\n",
    "                acc1 = comp[\"Model_1_Accuracy\"].values[0]\n",
    "                acc2 = comp[\"Model_2_Accuracy\"].values[0]\n",
    "                m1 = comp[\"Model_1\"].values[0]\n",
    "                m2 = comp[\"Model_2\"].values[0]\n",
    "                winner = m1 if acc1 > acc2 else m2\n",
    "                row.append(winner)\n",
    "            else:\n",
    "                row.append(\"\")\n",
    "    structured_winner.append(row)\n",
    "\n",
    "df_winner = pd.DataFrame(structured_winner, columns=columns)\n",
    "winner_csv = os.path.join(OUT_DIR, \"focused_llama70b_vs_gemma_wizard_winner.csv\")\n",
    "df_winner.to_csv(winner_csv, index=False)\n",
    "\n",
    "# ─── SAVE AS EXCEL ─────────────────────\n",
    "excel_out = os.path.join(OUT_DIR, \"focused_llama70b_vs_gemma_wizard.xlsx\")\n",
    "with pd.ExcelWriter(excel_out, engine=\"openpyxl\") as writer:\n",
    "    df_chi2.to_excel(writer, sheet_name=\"Chi2_Pvalue\", index=False)\n",
    "    df_winner.to_excel(writer, sheet_name=\"Winner\", index=False)\n",
    "\n",
    "# ─── FORMAT EXCEL ──────────────────────\n",
    "wb = load_workbook(excel_out)\n",
    "for sheet_name in wb.sheetnames:\n",
    "    ws = wb[sheet_name]\n",
    "    # Style header\n",
    "    for cell in ws[1]:\n",
    "        cell.font = Font(bold=True, color=\"FFFFFF\")\n",
    "        cell.fill = PatternFill(start_color=\"4F81BD\", end_color=\"4F81BD\", fill_type=\"solid\")\n",
    "        cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "        cell.border = Border(\n",
    "            left=Side(style='thin'), right=Side(style='thin'),\n",
    "            top=Side(style='thin'), bottom=Side(style='thin')\n",
    "        )\n",
    "    # Style data\n",
    "    for row in ws.iter_rows(min_row=2):\n",
    "        for cell in row:\n",
    "            cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "            cell.border = Border(\n",
    "                left=Side(style='thin'), right=Side(style='thin'),\n",
    "                top=Side(style='thin'), bottom=Side(style='thin')\n",
    "            )\n",
    "# Adjust column width\n",
    "for ws in wb.worksheets:\n",
    "    for col in ws.columns:\n",
    "        max_len = max((len(str(cell.value)) for cell in col if cell.value), default=0)\n",
    "        ws.column_dimensions[col[0].column_letter].width = min(max_len + 2, 30)\n",
    "\n",
    "wb.save(excel_out)\n",
    "\n",
    "# ─── DONE ──────────────────────────────\n",
    "print(f\"✅ Structured pivot table with chi2 saved to:\\n→ {chi2_csv}\")\n",
    "print(f\"✅ Structured winner table saved to:\\n→ {winner_csv}\")\n",
    "print(f\"✅ Excel file with both sheets saved to:\\n→ {excel_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5480b28-dc85-404c-994f-c844cdd8990b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Comparing llama3_70b vs llama3_8b\n",
      "\n",
      "🔍 Comparing llama3_70b vs mistral_7b\n",
      "\n",
      "🔍 Comparing llama3_70b vs gemma3_4b\n",
      "\n",
      "🔍 Comparing llama3_70b vs wizardlm2_7b\n",
      "\n",
      "🔍 Comparing llama3_8b vs mistral_7b\n",
      "\n",
      "🔍 Comparing llama3_8b vs gemma3_4b\n",
      "\n",
      "🔍 Comparing llama3_8b vs wizardlm2_7b\n",
      "\n",
      "🔍 Comparing mistral_7b vs gemma3_4b\n",
      "\n",
      "🔍 Comparing mistral_7b vs wizardlm2_7b\n",
      "\n",
      "🔍 Comparing gemma3_4b vs wizardlm2_7b\n",
      "\n",
      "🏆 McNemar Win Count Summary (5-shot):\n",
      "gemma3_4b: 4 wins\n",
      "llama3_70b: 3 wins\n",
      "wizardlm2_7b: 2 wins\n",
      "mistral_7b: 1 wins\n",
      "\n",
      "🎯 Final Best Model (5-shot, pairwise wins): **gemma3_4b**\n",
      "\n",
      "📄 Detailed results saved to: mcnemar_results_modelvsmodel_gpt/mcnemar_5shot_all_model_pairs.csv\n"
     ]
    }
   ],
   "source": [
    "#gpt\n",
    "import os\n",
    "import pandas as pd\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from collections import defaultdict\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────\n",
    "FS_PREFIX = \"few_shot_folds_\"\n",
    "MODELS = [\"llama3_70b\", \"llama3_8b\", \"mistral_7b\", \"gemma3_4b\", \"wizardlm2_7b\"]\n",
    "DATASETS = [\"pan\", \"maalej\", \"scalabrino\"]\n",
    "FOLDS = range(10)\n",
    "SHOT = 5\n",
    "\n",
    "OUT_DIR = \"mcnemar_results_modelvsmodel_gpt\"\n",
    "OUT_CSV = os.path.join(OUT_DIR, \"mcnemar_5shot_all_model_pairs.csv\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─── LOAD PREDICTIONS ──────────────────\n",
    "def load_preds(model, dataset, fold):\n",
    "    path = os.path.join(f\"{FS_PREFIX}{model}_{dataset}\", \"preds\", f\"{dataset}_fold{fold}_{SHOT}shot_preds.csv\")\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"⚠️ Missing: {path}\")\n",
    "        return None\n",
    "    df = pd.read_csv(path)\n",
    "    return df[[\"text\", \"gold\", \"pred\"]]\n",
    "\n",
    "# ─── RUN MCNEMAR TEST ──────────────────\n",
    "results = []\n",
    "wins = defaultdict(int)\n",
    "\n",
    "for i, model1 in enumerate(MODELS):\n",
    "    for model2 in MODELS[i+1:]:\n",
    "        print(f\"\\n🔍 Comparing {model1} vs {model2}\")\n",
    "        all_m1, all_m2 = [], []\n",
    "\n",
    "        for dataset in DATASETS:\n",
    "            for fold in FOLDS:\n",
    "                df1 = load_preds(model1, dataset, fold)\n",
    "                df2 = load_preds(model2, dataset, fold)\n",
    "                if df1 is None or df2 is None:\n",
    "                    continue\n",
    "                merged = pd.merge(df1, df2, on=\"text\", suffixes=(\"_1\", \"_2\"))\n",
    "                gold = merged[\"gold_1\"].str.lower().str.strip()\n",
    "                p1 = merged[\"pred_1\"].str.lower().str.strip()\n",
    "                p2 = merged[\"pred_2\"].str.lower().str.strip()\n",
    "                for y, pred1, pred2 in zip(gold, p1, p2):\n",
    "                    all_m1.append(pred1 == y)\n",
    "                    all_m2.append(pred2 == y)\n",
    "\n",
    "        if not all_m1:\n",
    "            print(f\"⚠️ No data for {model1} vs {model2}\")\n",
    "            continue\n",
    "\n",
    "        # Contingency table\n",
    "        both_correct = sum(m1 and m2 for m1, m2 in zip(all_m1, all_m2))\n",
    "        only_m1 = sum(m1 and not m2 for m1, m2 in zip(all_m1, all_m2))\n",
    "        only_m2 = sum(m2 and not m1 for m1, m2 in zip(all_m1, all_m2))\n",
    "        both_wrong = sum(not m1 and not m2 for m1, m2 in zip(all_m1, all_m2))\n",
    "        table = [[both_correct, only_m1], [only_m2, both_wrong]]\n",
    "        test_result = mcnemar(table, exact=False, correction=True)\n",
    "\n",
    "        # Decide winner\n",
    "        if only_m1 > only_m2:\n",
    "            winner = model1\n",
    "        elif only_m2 > only_m1:\n",
    "            winner = model2\n",
    "        else:\n",
    "            winner = \"Tie\"\n",
    "\n",
    "        if winner in MODELS:\n",
    "            wins[winner] += 1\n",
    "\n",
    "        results.append({\n",
    "            \"Model_1\": model1,\n",
    "            \"Model_2\": model2,\n",
    "            \"Only_Model_1_Correct\": only_m1,\n",
    "            \"Only_Model_2_Correct\": only_m2,\n",
    "            \"Chi2_Stat\": test_result.statistic,\n",
    "            \"P_Value\": test_result.pvalue,\n",
    "            \"Significant\": test_result.pvalue < 0.05,\n",
    "            \"Winner\": winner,\n",
    "            \"Total_Samples\": len(all_m1)\n",
    "        })\n",
    "\n",
    "# ─── SAVE RESULTS ──────────────────────\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "# ─── RANKING SUMMARY ───────────────────\n",
    "ranking = sorted(wins.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\n🏆 McNemar Win Count Summary (5-shot):\")\n",
    "for model, count in ranking:\n",
    "    print(f\"{model}: {count} wins\")\n",
    "\n",
    "if ranking:\n",
    "    print(f\"\\n🎯 Final Best Model (5-shot, pairwise wins): **{ranking[0][0]}**\")\n",
    "else:\n",
    "    print(\"❌ No valid comparisons available.\")\n",
    "\n",
    "print(f\"\\n📄 Detailed results saved to: {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d03c7fcd-a61a-40b0-9f2f-c466670c42d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model-vs-Model McNemar test completed.\n",
      "📁 CSV:   mcnemar_results_benchmark/mcnemar_model_vs_model.csv\n",
      "📊 Excel: mcnemar_results_benchmark/mcnemar_model_vs_model.xlsx\n",
      "✅ Winner matrix saved:\n",
      " - mcnemar_results_benchmark/mcnemar_model_vs_model_winner.csv\n",
      " - mcnemar_results_benchmark/mcnemar_model_vs_model_winner.xlsx\n",
      "📄 Detailed results saved:\n",
      " - mcnemar_results_benchmark/mcnemar_model_comparison_detailed.csv\n",
      " - mcnemar_results_benchmark/mcnemar_model_comparison_detailed.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Benchmark\n",
    "import os\n",
    "import pandas as pd\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from itertools import combinations\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────\n",
    "INPUT_DIR = \"all_preds_export\"\n",
    "OUT_DIR = \"mcnemar_results_benchmark\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "DATASETS = [\"pan\", \"maalej\", \"scalabrino\"]\n",
    "MODELS = [\"bert\", \"albert\", \"sbert\", \"roberta\"]\n",
    "FOLDS = range(10)\n",
    "\n",
    "# ─── FUNCTION: Load and Merge All Folds ─────────────\n",
    "def load_model_preds(model, dataset):\n",
    "    dfs = []\n",
    "    for fold in FOLDS:\n",
    "        fname = f\"{dataset}_{model}_fold{fold}_test_preds.csv\"\n",
    "        path = os.path.join(INPUT_DIR, fname)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"⚠️ Missing: {fname}\")\n",
    "            continue\n",
    "        df = pd.read_csv(path)\n",
    "        df = df.rename(columns={\"y_true\": \"gold\", \"y_pred\": \"pred\"})\n",
    "        df[\"fold\"] = fold\n",
    "        df[\"dataset\"] = dataset\n",
    "        df[\"id\"] = df.index + fold * 100000  # Ensure uniqueness across folds\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else None\n",
    "\n",
    "# ─── STEP 1: Collect predictions for each model ──────\n",
    "model_preds = {}\n",
    "for model in MODELS:\n",
    "    all_df = []\n",
    "    for dataset in DATASETS:\n",
    "        df = load_model_preds(model, dataset)\n",
    "        if df is not None:\n",
    "            all_df.append(df)\n",
    "    if all_df:\n",
    "        model_preds[model] = pd.concat(all_df, ignore_index=True)\n",
    "\n",
    "# ─── STEP 2: McNemar Test (model vs model) ───────────\n",
    "results = []\n",
    "model_pairs = list(combinations(MODELS, 2))\n",
    "\n",
    "for m1, m2 in model_pairs:\n",
    "    df1 = model_preds.get(m1)\n",
    "    df2 = model_preds.get(m2)\n",
    "    if df1 is None or df2 is None:\n",
    "        continue\n",
    "\n",
    "    # Align on same row order (same test set assumption)\n",
    "    merged = pd.merge(df1, df2, on=[\"dataset\", \"fold\", \"id\", \"gold\"], suffixes=(f\"_{m1}\", f\"_{m2}\"))\n",
    "    correct1 = merged[f\"pred_{m1}\"] == merged[\"gold\"]\n",
    "    correct2 = merged[f\"pred_{m2}\"] == merged[\"gold\"]\n",
    "\n",
    "    both_correct = ((correct1) & (correct2)).sum()\n",
    "    only_m1 = ((correct1) & (~correct2)).sum()\n",
    "    only_m2 = ((~correct1) & (correct2)).sum()\n",
    "    both_wrong = ((~correct1) & (~correct2)).sum()\n",
    "\n",
    "    table = [[both_correct, only_m1],\n",
    "             [only_m2, both_wrong]]\n",
    "\n",
    "    result = mcnemar(table, exact=False, correction=True)\n",
    "    results.append({\n",
    "        \"Model_1\": m1.upper(),\n",
    "        \"Model_2\": m2.upper(),\n",
    "        \"Chi_Square\": result.statistic,\n",
    "        \"P_Value\": result.pvalue\n",
    "    })\n",
    "\n",
    "# ─── STEP 3: Output as Matrix ───────────────────────\n",
    "matrix_models = [m.upper() for m in MODELS]\n",
    "matrix_data = []\n",
    "\n",
    "for row_model in matrix_models:\n",
    "    row = [row_model]\n",
    "    for col_model in matrix_models:\n",
    "        if row_model == col_model:\n",
    "            row.append(\"-\")\n",
    "        else:\n",
    "            res = next((r for r in results if (r[\"Model_1\"], r[\"Model_2\"]) == (row_model, col_model) or \n",
    "                                                (r[\"Model_2\"], r[\"Model_1\"]) == (row_model, col_model)), None)\n",
    "            if res:\n",
    "                val = f\"{res['Chi_Square']:.3f}/{res['P_Value']:.3f}\"\n",
    "            else:\n",
    "                val = \"\"\n",
    "            row.append(val)\n",
    "    matrix_data.append(row)\n",
    "\n",
    "# ─── STEP 4: Save CSV & Excel ───────────────────────\n",
    "csv_path = os.path.join(OUT_DIR, \"mcnemar_model_vs_model.csv\")\n",
    "xlsx_path = os.path.join(OUT_DIR, \"mcnemar_model_vs_model.xlsx\")\n",
    "\n",
    "df_matrix = pd.DataFrame(matrix_data, columns=[\"\"] + matrix_models)\n",
    "df_matrix.to_csv(csv_path, index=False)\n",
    "\n",
    "with pd.ExcelWriter(xlsx_path, engine=\"openpyxl\") as writer:\n",
    "    df_matrix.to_excel(writer, sheet_name=\"Model Comparison\", index=False)\n",
    "    ws = writer.sheets[\"Model Comparison\"]\n",
    "\n",
    "    # Header style\n",
    "    header_font = Font(bold=True, color=\"FFFFFF\")\n",
    "    header_fill = PatternFill(\"solid\", fgColor=\"366092\")\n",
    "    center_align = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "    thin_border = Border(left=Side(style='thin'), right=Side(style='thin'),\n",
    "                         top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "\n",
    "    # Format header\n",
    "    for cell in ws[1]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "        cell.alignment = center_align\n",
    "        cell.border = thin_border\n",
    "\n",
    "    # Format data rows\n",
    "    for row in ws.iter_rows(min_row=2):\n",
    "        for cell in row:\n",
    "            cell.alignment = center_align\n",
    "            cell.border = thin_border\n",
    "\n",
    "    # Auto-size columns\n",
    "    for col in ws.columns:\n",
    "        max_len = max(len(str(cell.value)) for cell in col)\n",
    "        ws.column_dimensions[col[0].column_letter].width = min(max_len + 2, 25)\n",
    "\n",
    "print(\"✅ Model-vs-Model McNemar test completed.\")\n",
    "print(f\"📁 CSV:   {csv_path}\")\n",
    "print(f\"📊 Excel: {xlsx_path}\")\n",
    "\n",
    "  \n",
    "# ─── STEP 2B: Winner Matrix ───────────────\n",
    "winner_matrix = []\n",
    "\n",
    "for row_model in matrix_models:\n",
    "    row = [row_model]\n",
    "    for col_model in matrix_models:\n",
    "        if row_model == col_model:\n",
    "            row.append(\"-\")\n",
    "        else:\n",
    "            res = next((r for r in detailed_results if \n",
    "                        (r[\"Model_1\"], r[\"Model_2\"]) == (row_model, col_model) or\n",
    "                        (r[\"Model_2\"], r[\"Model_1\"]) == (row_model, col_model)), None)\n",
    "            row.append(res[\"Winner\"] if res else \"\")\n",
    "    winner_matrix.append(row)\n",
    "\n",
    "\n",
    "df_winner = pd.DataFrame(winner_matrix, columns=[\"\"] + matrix_models)\n",
    "\n",
    "# Save\n",
    "winner_csv = os.path.join(OUT_DIR, \"mcnemar_model_vs_model_winner.csv\")\n",
    "winner_xlsx = os.path.join(OUT_DIR, \"mcnemar_model_vs_model_winner.xlsx\")\n",
    "df_winner.to_csv(winner_csv, index=False)\n",
    "df_winner.to_excel(winner_xlsx, index=False)\n",
    "\n",
    "print(f\"✅ Winner matrix saved:\\n - {winner_csv}\\n - {winner_xlsx}\")\n",
    "detailed_results = []\n",
    "\n",
    "for m1, m2 in model_pairs:\n",
    "    df1 = model_preds.get(m1)\n",
    "    df2 = model_preds.get(m2)\n",
    "    if df1 is None or df2 is None:\n",
    "        continue\n",
    "\n",
    "    merged = pd.merge(df1, df2, on=[\"dataset\", \"fold\", \"id\", \"gold\"], suffixes=(f\"_{m1}\", f\"_{m2}\"))\n",
    "    correct1 = merged[f\"pred_{m1}\"] == merged[\"gold\"]\n",
    "    correct2 = merged[f\"pred_{m2}\"] == merged[\"gold\"]\n",
    "\n",
    "    both_correct = ((correct1) & (correct2)).sum()\n",
    "    only_m1 = ((correct1) & (~correct2)).sum()\n",
    "    only_m2 = ((~correct1) & (correct2)).sum()\n",
    "    both_wrong = ((~correct1) & (~correct2)).sum()\n",
    "\n",
    "    table = [[both_correct, only_m1],\n",
    "             [only_m2, both_wrong]]\n",
    "\n",
    "    result = mcnemar(table, exact=False, correction=True)\n",
    "\n",
    "    acc1 = correct1.mean()\n",
    "    acc2 = correct2.mean()\n",
    "    acc_diff = acc1 - acc2\n",
    "\n",
    "    if acc1 > acc2:\n",
    "        winner = m1.upper()\n",
    "    elif acc2 > acc1:\n",
    "        winner = m2.upper()\n",
    "    else:\n",
    "        winner = \"TIE\"\n",
    "\n",
    "    detailed_results.append({\n",
    "        \"Model_1\": m1.upper(),\n",
    "        \"Model_2\": m2.upper(),\n",
    "        \"Model_1_Accuracy\": round(acc1, 4),\n",
    "        \"Model_2_Accuracy\": round(acc2, 4),\n",
    "        \"Accuracy_Diff\": round(acc_diff, 4),\n",
    "        \"Both_Correct\": int(both_correct),\n",
    "        \"Only_Model1\": int(only_m1),\n",
    "        \"Only_Model2\": int(only_m2),\n",
    "        \"Both_Wrong\": int(both_wrong),\n",
    "        \"Chi_Square\": round(result.statistic, 3),\n",
    "        \"P_Value\": round(result.pvalue, 3),\n",
    "        \"Winner\": winner\n",
    "    })\n",
    "\n",
    "df_detailed = pd.DataFrame(detailed_results)\n",
    "\n",
    "# Save detailed file\n",
    "detailed_csv = os.path.join(OUT_DIR, \"mcnemar_model_comparison_detailed.csv\")\n",
    "detailed_xlsx = os.path.join(OUT_DIR, \"mcnemar_model_comparison_detailed.xlsx\")\n",
    "\n",
    "df_detailed.to_csv(detailed_csv, index=False)\n",
    "df_detailed.to_excel(detailed_xlsx, index=False)\n",
    "\n",
    "print(f\"📄 Detailed results saved:\\n - {detailed_csv}\\n - {detailed_xlsx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76a23bb8-1c4c-4f89-a776-3bd6c10b82ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ McNemar test complete.\n",
      "📁 Matrix CSV:     mcnemar_llama_vs_qlora/mcnemar_model_vs_model.csv\n",
      "📊 Matrix Excel:   mcnemar_llama_vs_qlora/mcnemar_model_vs_model.xlsx\n",
      "🏆 Winner Matrix:  mcnemar_llama_vs_qlora/mcnemar_model_vs_model_winner.csv\n",
      "📄 Detailed File:  mcnemar_llama_vs_qlora/mcnemar_model_comparison_detailed.csv\n"
     ]
    }
   ],
   "source": [
    "#llama3:70b vs qlora\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────\n",
    "OUT_DIR = \"mcnemar_llama_vs_qlora\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "DATASETS = [\"pan\", \"maalej\", \"scalabrino\"]\n",
    "MODELS = [\"llama3_70b\", \"qlora\"]\n",
    "MODEL_DIRS = {\n",
    "    \"llama3_70b\": \"llama3_70b\",\n",
    "    \"qlora\": \"qlora\"\n",
    "}\n",
    "FOLDS = range(10)\n",
    "\n",
    "# ─── FUNCTION: Load Predictions ────────\n",
    "def load_model_preds(model, dataset):\n",
    "    dfs = []\n",
    "    model_dir = MODEL_DIRS[model]\n",
    "    for fold in FOLDS:\n",
    "        fname = f\"{dataset}_fold{fold}_test_preds.csv\"\n",
    "        path = os.path.join(model_dir, fname)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"⚠️ Missing: {fname}\")\n",
    "            continue\n",
    "        df = pd.read_csv(path)\n",
    "        df = df.rename(columns={\"y_true\": \"gold\", \"y_pred\": \"pred\"})\n",
    "        df[\"fold\"] = fold\n",
    "        df[\"dataset\"] = dataset\n",
    "        df[\"id\"] = df.index + fold * 100000  # Ensure uniqueness across folds\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else None\n",
    "\n",
    "# ─── STEP 1: Collect predictions ───────\n",
    "model_preds = {}\n",
    "for model in MODELS:\n",
    "    all_df = []\n",
    "    for dataset in DATASETS:\n",
    "        df = load_model_preds(model, dataset)\n",
    "        if df is not None:\n",
    "            all_df.append(df)\n",
    "    if all_df:\n",
    "        model_preds[model] = pd.concat(all_df, ignore_index=True)\n",
    "\n",
    "# ─── STEP 2: McNemar Test ──────────────\n",
    "results = []\n",
    "detailed_results = []\n",
    "model_pairs = list(combinations(MODELS, 2))\n",
    "\n",
    "for m1, m2 in model_pairs:\n",
    "    df1 = model_preds.get(m1)\n",
    "    df2 = model_preds.get(m2)\n",
    "    if df1 is None or df2 is None:\n",
    "        continue\n",
    "\n",
    "    merged = pd.merge(df1, df2, on=[\"dataset\", \"fold\", \"id\", \"gold\"], suffixes=(f\"_{m1}\", f\"_{m2}\"))\n",
    "    correct1 = merged[f\"pred_{m1}\"] == merged[\"gold\"]\n",
    "    correct2 = merged[f\"pred_{m2}\"] == merged[\"gold\"]\n",
    "\n",
    "    both_correct = ((correct1) & (correct2)).sum()\n",
    "    only_m1 = ((correct1) & (~correct2)).sum()\n",
    "    only_m2 = ((~correct1) & (correct2)).sum()\n",
    "    both_wrong = ((~correct1) & (~correct2)).sum()\n",
    "\n",
    "    table = [[both_correct, only_m1],\n",
    "             [only_m2, both_wrong]]\n",
    "\n",
    "    result = mcnemar(table, exact=False, correction=True)\n",
    "\n",
    "    acc1 = correct1.mean()\n",
    "    acc2 = correct2.mean()\n",
    "    acc_diff = acc1 - acc2\n",
    "\n",
    "    if acc1 > acc2:\n",
    "        winner = m1.upper()\n",
    "    elif acc2 > acc1:\n",
    "        winner = m2.upper()\n",
    "    else:\n",
    "        winner = \"TIE\"\n",
    "\n",
    "    results.append({\n",
    "        \"Model_1\": m1.upper(),\n",
    "        \"Model_2\": m2.upper(),\n",
    "        \"Chi_Square\": result.statistic,\n",
    "        \"P_Value\": result.pvalue\n",
    "    })\n",
    "\n",
    "    detailed_results.append({\n",
    "        \"Model_1\": m1.upper(),\n",
    "        \"Model_2\": m2.upper(),\n",
    "        \"Model_1_Accuracy\": round(acc1, 4),\n",
    "        \"Model_2_Accuracy\": round(acc2, 4),\n",
    "        \"Accuracy_Diff\": round(acc_diff, 4),\n",
    "        \"Both_Correct\": int(both_correct),\n",
    "        \"Only_Model1\": int(only_m1),\n",
    "        \"Only_Model2\": int(only_m2),\n",
    "        \"Both_Wrong\": int(both_wrong),\n",
    "        \"Chi_Square\": round(result.statistic, 3),\n",
    "        \"P_Value\": round(result.pvalue, 3),\n",
    "        \"Winner\": winner\n",
    "    })\n",
    "\n",
    "# ─── STEP 3: McNemar Matrix ─────────────\n",
    "matrix_models = [m.upper() for m in MODELS]\n",
    "matrix_data = []\n",
    "\n",
    "for row_model in matrix_models:\n",
    "    row = [row_model]\n",
    "    for col_model in matrix_models:\n",
    "        if row_model == col_model:\n",
    "            row.append(\"-\")\n",
    "        else:\n",
    "            res = next((r for r in results if \n",
    "                        (r[\"Model_1\"], r[\"Model_2\"]) == (row_model, col_model) or \n",
    "                        (r[\"Model_2\"], r[\"Model_1\"]) == (row_model, col_model)), None)\n",
    "            val = f\"{res['Chi_Square']:.3f}/{res['P_Value']:.3f}\" if res else \"\"\n",
    "            row.append(val)\n",
    "    matrix_data.append(row)\n",
    "\n",
    "df_matrix = pd.DataFrame(matrix_data, columns=[\"\"] + matrix_models)\n",
    "\n",
    "# Save matrix\n",
    "matrix_csv = os.path.join(OUT_DIR, \"mcnemar_model_vs_model.csv\")\n",
    "matrix_xlsx = os.path.join(OUT_DIR, \"mcnemar_model_vs_model.xlsx\")\n",
    "df_matrix.to_csv(matrix_csv, index=False)\n",
    "\n",
    "# Excel styling\n",
    "with pd.ExcelWriter(matrix_xlsx, engine=\"openpyxl\") as writer:\n",
    "    df_matrix.to_excel(writer, sheet_name=\"Model Comparison\", index=False)\n",
    "    ws = writer.sheets[\"Model Comparison\"]\n",
    "\n",
    "    header_font = Font(bold=True, color=\"FFFFFF\")\n",
    "    header_fill = PatternFill(\"solid\", fgColor=\"366092\")\n",
    "    center_align = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "    thin_border = Border(left=Side(style='thin'), right=Side(style='thin'),\n",
    "                         top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "\n",
    "    for cell in ws[1]:\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "        cell.alignment = center_align\n",
    "        cell.border = thin_border\n",
    "\n",
    "    for row in ws.iter_rows(min_row=2):\n",
    "        for cell in row:\n",
    "            cell.alignment = center_align\n",
    "            cell.border = thin_border\n",
    "\n",
    "    for col in ws.columns:\n",
    "        max_len = max(len(str(cell.value)) for cell in col)\n",
    "        ws.column_dimensions[col[0].column_letter].width = min(max_len + 2, 25)\n",
    "\n",
    "# ─── STEP 4: Winner Matrix ───────────────\n",
    "winner_matrix = []\n",
    "for row_model in matrix_models:\n",
    "    row = [row_model]\n",
    "    for col_model in matrix_models:\n",
    "        if row_model == col_model:\n",
    "            row.append(\"-\")\n",
    "        else:\n",
    "            res = next((r for r in detailed_results if \n",
    "                        (r[\"Model_1\"], r[\"Model_2\"]) == (row_model, col_model) or \n",
    "                        (r[\"Model_2\"], r[\"Model_1\"]) == (row_model, col_model)), None)\n",
    "            row.append(res[\"Winner\"] if res else \"\")\n",
    "    winner_matrix.append(row)\n",
    "\n",
    "df_winner = pd.DataFrame(winner_matrix, columns=[\"\"] + matrix_models)\n",
    "winner_csv = os.path.join(OUT_DIR, \"mcnemar_model_vs_model_winner.csv\")\n",
    "winner_xlsx = os.path.join(OUT_DIR, \"mcnemar_model_vs_model_winner.xlsx\")\n",
    "df_winner.to_csv(winner_csv, index=False)\n",
    "df_winner.to_excel(winner_xlsx, index=False)\n",
    "\n",
    "# ─── STEP 5: Detailed Results ─────────────\n",
    "df_detailed = pd.DataFrame(detailed_results)\n",
    "detailed_csv = os.path.join(OUT_DIR, \"mcnemar_model_comparison_detailed.csv\")\n",
    "detailed_xlsx = os.path.join(OUT_DIR, \"mcnemar_model_comparison_detailed.xlsx\")\n",
    "df_detailed.to_csv(detailed_csv, index=False)\n",
    "df_detailed.to_excel(detailed_xlsx, index=False)\n",
    "\n",
    "# ─── DONE ────────────────────────────────\n",
    "print(\"✅ McNemar test complete.\")\n",
    "print(f\"📁 Matrix CSV:     {matrix_csv}\")\n",
    "print(f\"📊 Matrix Excel:   {matrix_xlsx}\")\n",
    "print(f\"🏆 Winner Matrix:  {winner_csv}\")\n",
    "print(f\"📄 Detailed File:  {detailed_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdf244af-d80b-468a-8c5a-b3c89d124b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ QLoRA vs RoBERTa McNemar test complete.\n"
     ]
    }
   ],
   "source": [
    "#gen vs nongen\n",
    "import os\n",
    "import pandas as pd\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────\n",
    "FOLDS = range(10)\n",
    "DATASETS = [\"pan\", \"maalej\", \"scalabrino\"]\n",
    "BASE_DIR = \"\"\n",
    "MODELS = [\"qlora\", \"roberta\"]\n",
    "OUT_DIR = \"mcnemar_qlora_vs_roberta\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─── LOAD & MERGE ───────────────────────\n",
    "def load_preds(model, dataset):\n",
    "    dfs = []\n",
    "    for fold in FOLDS:\n",
    "        file = f\"{dataset}_fold{fold}_test_preds.csv\"\n",
    "        path = os.path.join(BASE_DIR, model, file)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"⚠️ Missing: {path}\")\n",
    "            continue\n",
    "        df = pd.read_csv(path)\n",
    "        df = df[[\"id\", \"gold\", \"pred\"]].copy()\n",
    "        df[\"fold\"] = fold\n",
    "        df[\"dataset\"] = dataset\n",
    "        df[\"model\"] = model\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else None\n",
    "\n",
    "df_q = []\n",
    "df_r = []\n",
    "\n",
    "for d in DATASETS:\n",
    "    q_df = load_preds(\"qlora\", d)\n",
    "    r_df = load_preds(\"roberta\", d)\n",
    "    if q_df is not None and r_df is not None:\n",
    "        df_q.append(q_df)\n",
    "        df_r.append(r_df)\n",
    "\n",
    "df_qlora = pd.concat(df_q, ignore_index=True)\n",
    "df_roberta = pd.concat(df_r, ignore_index=True)\n",
    "\n",
    "# ─── ALIGN ROWS ─────────────────────────\n",
    "merged = pd.merge(\n",
    "    df_qlora,\n",
    "    df_roberta,\n",
    "    on=[\"dataset\", \"fold\", \"id\", \"gold\"],\n",
    "    suffixes=(\"_qlora\", \"_roberta\")\n",
    ")\n",
    "\n",
    "# ─── RUN MCNEMAR TEST ───────────────────\n",
    "correct_q = merged[\"pred_qlora\"] == merged[\"gold\"]\n",
    "correct_r = merged[\"pred_roberta\"] == merged[\"gold\"]\n",
    "\n",
    "both_correct = ((correct_q) & (correct_r)).sum()\n",
    "only_q = ((correct_q) & (~correct_r)).sum()\n",
    "only_r = ((~correct_q) & (correct_r)).sum()\n",
    "both_wrong = ((~correct_q) & (~correct_r)).sum()\n",
    "\n",
    "table = [[both_correct, only_q],\n",
    "         [only_r, both_wrong]]\n",
    "\n",
    "test = mcnemar(table, exact=False, correction=True)\n",
    "\n",
    "# ─── STRUCTURE RESULTS ──────────────────\n",
    "acc_q = correct_q.mean()\n",
    "acc_r = correct_r.mean()\n",
    "\n",
    "\n",
    "if test.pvalue < 0.05:\n",
    "    if acc_q > acc_r:\n",
    "        winner = \"QLORA\"\n",
    "    elif acc_r > acc_q:\n",
    "        winner = \"ROBERTA\"\n",
    "    else:\n",
    "        winner = \"TIE\"\n",
    "else:\n",
    "    winner = \"TIE\"\n",
    "\n",
    "\n",
    "#winner = \"QLORA\" if acc_q > acc_r else \"ROBERTA\" if acc_r > acc_q else \"TIE\"\n",
    "\n",
    "detailed = pd.DataFrame([{\n",
    "    \"Model_1\": \"QLORA\",\n",
    "    \"Model_2\": \"ROBERTA\",\n",
    "    \"Accuracy_QLORA\": round(acc_q, 4),\n",
    "    \"Accuracy_ROBERTA\": round(acc_r, 4),\n",
    "    \"Accuracy_Diff\": round(acc_q - acc_r, 4),\n",
    "    \"Both_Correct\": int(both_correct),\n",
    "    \"Only_QLORA_Correct\": int(only_q),\n",
    "    \"Only_ROBERTA_Correct\": int(only_r),\n",
    "    \"Both_Wrong\": int(both_wrong),\n",
    "    \"Chi_Square\": round(test.statistic, 3),\n",
    "    \"P_Value\": round(test.pvalue, 3),\n",
    "    \"Winner\": winner\n",
    "}])\n",
    "\n",
    "# ─── OUTPUTS ────────────────────────────\n",
    "csv_detailed = os.path.join(OUT_DIR, \"qlora_vs_roberta_detailed.csv\")\n",
    "xlsx_detailed = os.path.join(OUT_DIR, \"qlora_vs_roberta_detailed.xlsx\")\n",
    "\n",
    "detailed.to_csv(csv_detailed, index=False)\n",
    "detailed.to_excel(xlsx_detailed, index=False)\n",
    "\n",
    "# ─── CHI / P MATRIX ─────────────────────\n",
    "matrix = pd.DataFrame([\n",
    "    [\"\", \"QLORA\", \"ROBERTA\"],\n",
    "    [\"QLORA\", \"-\", f\"{test.statistic:.3f}/{test.pvalue:.3f}\"],\n",
    "    [\"ROBERTA\", f\"{test.statistic:.3f}/{test.pvalue:.3f}\", \"-\"]\n",
    "])\n",
    "matrix.columns = matrix.iloc[0]\n",
    "matrix = matrix[1:]\n",
    "matrix.to_csv(os.path.join(OUT_DIR, \"chi_p_matrix.csv\"), index=False)\n",
    "\n",
    "# ─── WINNER MATRIX ──────────────────────\n",
    "win_matrix = pd.DataFrame([\n",
    "    [\"\", \"QLORA\", \"ROBERTA\"],\n",
    "    [\"QLORA\", \"-\", winner],\n",
    "    [\"ROBERTA\", winner, \"-\"]\n",
    "])\n",
    "\n",
    "win_matrix.columns = win_matrix.iloc[0]\n",
    "win_matrix = win_matrix[1:]\n",
    "win_matrix.to_csv(os.path.join(OUT_DIR, \"winner_matrix.csv\"), index=False)\n",
    "\n",
    "print(\"✅ QLoRA vs RoBERTa McNemar test complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe65f40d-524b-46aa-850c-75bf96e47577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total aligned samples: 3000\n",
      "Both correct: 2581\n",
      "Only QLora correct: 102\n",
      "Only RoBERTa correct: 104\n",
      "Both wrong: 213\n",
      "Discordant pairs: 206\n",
      "\n",
      "McNemar Contingency Table:\n",
      "                RoBERTa\n",
      "              Correct  Wrong\n",
      "QLora Correct    2581    102\n",
      "      Wrong       104    213\n",
      "\n",
      "Using chi-square test with continuity correction (discordant pairs = 206)\n",
      "\n",
      "Results:\n",
      "QLora Accuracy: 0.8943\n",
      "RoBERTa Accuracy: 0.8950\n",
      "Difference: -0.0007\n",
      "Chi-square statistic: 0.005\n",
      "P-value: 0.944\n",
      "Significant at α=0.05: False\n",
      "Winner: No significant difference (p=0.944)\n",
      "\n",
      "✅ McNemar test complete. Results saved to mcnemar_qlora_vs_roberta_with_claude/\n",
      "Key insight: No significant difference (p=0.944)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "import numpy as np\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────\n",
    "FOLDS = range(10)\n",
    "DATASETS = [\"pan\", \"maalej\", \"scalabrino\"]\n",
    "BASE_DIR = \"\"\n",
    "MODELS = [\"qlora\", \"roberta\"]\n",
    "OUT_DIR = \"mcnemar_qlora_vs_roberta_with_claude\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─── LOAD & MERGE ───────────────────────\n",
    "def load_preds(model, dataset):\n",
    "    dfs = []\n",
    "    for fold in FOLDS:\n",
    "        file = f\"{dataset}_fold{fold}_test_preds.csv\"\n",
    "        path = os.path.join(BASE_DIR, model, file)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"⚠️ Missing: {path}\")\n",
    "            continue\n",
    "        df = pd.read_csv(path)\n",
    "        df = df[[\"id\", \"gold\", \"pred\"]].copy()\n",
    "        df[\"fold\"] = fold\n",
    "        df[\"dataset\"] = dataset\n",
    "        df[\"model\"] = model\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else None\n",
    "\n",
    "# Load data for both models\n",
    "df_q = []\n",
    "df_r = []\n",
    "for d in DATASETS:\n",
    "    q_df = load_preds(\"qlora\", d)\n",
    "    r_df = load_preds(\"roberta\", d)\n",
    "    if q_df is not None and r_df is not None:\n",
    "        df_q.append(q_df)\n",
    "        df_r.append(r_df)\n",
    "\n",
    "df_qlora = pd.concat(df_q, ignore_index=True)\n",
    "df_roberta = pd.concat(df_r, ignore_index=True)\n",
    "\n",
    "# ─── ALIGN ROWS ─────────────────────────\n",
    "merged = pd.merge(\n",
    "    df_qlora,\n",
    "    df_roberta,\n",
    "    on=[\"dataset\", \"fold\", \"id\", \"gold\"],\n",
    "    suffixes=(\"_qlora\", \"_roberta\")\n",
    ")\n",
    "\n",
    "print(f\"Total aligned samples: {len(merged)}\")\n",
    "\n",
    "# ─── COMPUTE CORRECTNESS ────────────────\n",
    "correct_q = merged[\"pred_qlora\"] == merged[\"gold\"]\n",
    "correct_r = merged[\"pred_roberta\"] == merged[\"gold\"]\n",
    "\n",
    "# ─── BUILD CONTINGENCY TABLE ────────────\n",
    "both_correct = ((correct_q) & (correct_r)).sum()\n",
    "only_q = ((correct_q) & (~correct_r)).sum()  # QLora correct, RoBERTa wrong\n",
    "only_r = ((~correct_q) & (correct_r)).sum()  # QLora wrong, RoBERTa correct\n",
    "both_wrong = ((~correct_q) & (~correct_r)).sum()\n",
    "\n",
    "# Validate counts\n",
    "total_samples = len(merged)\n",
    "assert both_correct + only_q + only_r + both_wrong == total_samples, \"Counts don't sum to total!\"\n",
    "\n",
    "print(f\"Both correct: {both_correct}\")\n",
    "print(f\"Only QLora correct: {only_q}\")\n",
    "print(f\"Only RoBERTa correct: {only_r}\")\n",
    "print(f\"Both wrong: {both_wrong}\")\n",
    "print(f\"Discordant pairs: {only_q + only_r}\")\n",
    "\n",
    "# ─── MCNEMAR CONTINGENCY TABLE ──────────\n",
    "# Structure: [[both_correct, only_model1_correct],\n",
    "#             [only_model2_correct, both_wrong]]\n",
    "table = np.array([[both_correct, only_q],\n",
    "                  [only_r, both_wrong]])\n",
    "\n",
    "print(\"\\nMcNemar Contingency Table:\")\n",
    "print(\"                RoBERTa\")\n",
    "print(\"              Correct  Wrong\")\n",
    "print(f\"QLora Correct    {both_correct:4d}   {only_q:4d}\")\n",
    "print(f\"      Wrong      {only_r:4d}   {both_wrong:4d}\")\n",
    "\n",
    "# ─── RUN MCNEMAR TEST ───────────────────\n",
    "n_discordant = only_q + only_r\n",
    "\n",
    "# Use exact test for small discordant pairs, otherwise continuity correction\n",
    "if n_discordant < 25:\n",
    "    print(f\"\\nUsing exact test (discordant pairs = {n_discordant} < 25)\")\n",
    "    test = mcnemar(table, exact=True)\n",
    "else:\n",
    "    print(f\"\\nUsing chi-square test with continuity correction (discordant pairs = {n_discordant})\")\n",
    "    test = mcnemar(table, exact=False, correction=True)\n",
    "\n",
    "# ─── COMPUTE METRICS ────────────────────\n",
    "acc_q = correct_q.mean()\n",
    "acc_r = correct_r.mean()\n",
    "acc_diff = acc_q - acc_r\n",
    "\n",
    "# Statistical significance\n",
    "alpha = 0.05\n",
    "is_significant = test.pvalue < alpha\n",
    "\n",
    "if is_significant:\n",
    "    if acc_diff > 0:\n",
    "        winner = \"QLORA (significant)\"\n",
    "    else:\n",
    "        winner = \"ROBERTA (significant)\"\n",
    "else:\n",
    "    winner = f\"No significant difference (p={test.pvalue:.3f})\"\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"QLora Accuracy: {acc_q:.4f}\")\n",
    "print(f\"RoBERTa Accuracy: {acc_r:.4f}\")\n",
    "print(f\"Difference: {acc_diff:+.4f}\")\n",
    "print(f\"Chi-square statistic: {test.statistic:.3f}\")\n",
    "print(f\"P-value: {test.pvalue:.3f}\")\n",
    "print(f\"Significant at α=0.05: {is_significant}\")\n",
    "print(f\"Winner: {winner}\")\n",
    "\n",
    "# ─── STRUCTURE DETAILED RESULTS ─────────\n",
    "detailed = pd.DataFrame([{\n",
    "    \"Model_1\": \"QLORA\",\n",
    "    \"Model_2\": \"ROBERTA\",\n",
    "    \"Accuracy_QLORA\": round(acc_q, 4),\n",
    "    \"Accuracy_ROBERTA\": round(acc_r, 4),\n",
    "    \"Accuracy_Diff\": round(acc_diff, 4),\n",
    "    \"Both_Correct\": int(both_correct),\n",
    "    \"Only_QLORA_Correct\": int(only_q),\n",
    "    \"Only_ROBERTA_Correct\": int(only_r),\n",
    "    \"Both_Wrong\": int(both_wrong),\n",
    "    \"Total_Samples\": int(total_samples),\n",
    "    \"Discordant_Pairs\": int(n_discordant),\n",
    "    \"Chi_Square\": round(test.statistic, 3),\n",
    "    \"P_Value\": round(test.pvalue, 3),\n",
    "    \"Significant\": is_significant,\n",
    "    \"Winner\": winner,\n",
    "    \"Test_Type\": \"Exact\" if n_discordant < 25 else \"Chi-square\"\n",
    "}])\n",
    "\n",
    "# ─── OUTPUTS ────────────────────────────\n",
    "csv_detailed = os.path.join(OUT_DIR, \"qlora_vs_roberta_detailed.csv\")\n",
    "xlsx_detailed = os.path.join(OUT_DIR, \"qlora_vs_roberta_detailed.xlsx\")\n",
    "\n",
    "detailed.to_csv(csv_detailed, index=False)\n",
    "detailed.to_excel(xlsx_detailed, index=False)\n",
    "\n",
    "# Save contingency table\n",
    "contingency_df = pd.DataFrame(table, \n",
    "                            index=['QLora_Correct', 'QLora_Wrong'],\n",
    "                            columns=['RoBERTa_Correct', 'RoBERTa_Wrong'])\n",
    "contingency_df.to_csv(os.path.join(OUT_DIR, \"mcnemar_contingency_table.csv\"))\n",
    "\n",
    "print(f\"\\n✅ McNemar test complete. Results saved to {OUT_DIR}/\")\n",
    "print(f\"Key insight: {winner}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv310)",
   "language": "python",
   "name": "myenv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
